{"id":"KanjiReader-04b","title":"KanjiReader Version 3: Core Refinements","description":"This epic focuses on refining the core features of the KanjiReader application based on recent user feedback. The primary goals are to address critical inline pronunciation display issues (alignment, romaji logic) and to implement the desired default visibility behavior for pronunciations, enhancing the user's active recall practice. This iteration prioritizes quality and user experience for existing features.","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:50:37.117209337+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:57.722136838+05:30","closed_at":"2026-02-01T18:40:57.722136838+05:30","close_reason":"Closed"}
{"id":"KanjiReader-04b.1","title":"Feature: Default Inline Pronunciation Visibility Off","description":"This feature addresses the user's requirement for inline pronunciations to be hidden by default upon loading the results screen. The current implementation shows them by default. This change will encourage active recall, as users will need to explicitly toggle the visibility to see the pronunciation. Reasoning: Facilitating active recall is a key learning strategy. By setting the default to 'off', we empower the user's learning process without constantly revealing answers.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:50:45.948956897+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.668641425+05:30","closed_at":"2026-02-01T18:40:39.668641425+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.1","depends_on_id":"KanjiReader-04b","type":"parent-child","created_at":"2026-02-01T17:50:45.94996923+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.1.1","title":"Subtask: Set default pronunciation visibility to false","description":"This subtask involves modifying the initial state of the  flag (or equivalent variable) in the  (or relevant component) from  to . This ensures that when the results screen is first displayed, inline pronunciations are hidden by default, aligning with the user's preference for active recall. Consideration: Verify that the toggle button correctly reveals/hides the pronunciations after this change.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:51:18.092259088+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.625900616+05:30","closed_at":"2026-02-01T18:40:39.625900616+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.1.1","depends_on_id":"KanjiReader-04b.1","type":"parent-child","created_at":"2026-02-01T17:51:18.093288311+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.2","title":"Feature: Improve Pronunciation Alignment","description":"This feature aims to resolve the persistent issues with inline pronunciation alignment and missing romaji for certain words. The user explicitly noted misalignment (e.g., てちょう above 年) and missing romaji (e.g., ねん). Correct alignment and complete pronunciation coverage are crucial for a reliable and effective learning tool. Reasoning: Accurate visual representation of romaji is fundamental for users to correctly associate pronunciation with Japanese characters. This directly addresses the core feedback on learning experience.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:51:35.40819983+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.878677796+05:30","closed_at":"2026-02-01T18:40:39.878677796+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.2","depends_on_id":"KanjiReader-04b","type":"parent-child","created_at":"2026-02-01T17:51:35.409297445+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.2.1","title":"Subtask: Investigate and fix romaji misalignment","description":"This subtask requires a thorough investigation into the rendering logic of inline pronunciations to understand why misalignment occurs, specifically as observed with 'てちょう' above '年'. The fix might involve adjustments to CSS/styling, font metrics, or the underlying text measurement/layout calculations within the UI component. Consideration: This is a complex UI problem that may require iterative adjustments and testing across various text examples.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:51:46.096509084+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.793001015+05:30","closed_at":"2026-02-01T18:40:39.793001015+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.2.1","depends_on_id":"KanjiReader-04b.2","type":"parent-child","created_at":"2026-02-01T17:51:46.097564756+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.2.2","title":"Subtask: Ensure all Japanese words receive pronunciation","description":"This subtask focuses on debugging and correcting the issue where certain Japanese words, like '年' (ねん) in the user's example, are not receiving any romaji pronunciation. This could stem from problems in the text parsing, dictionary lookup (if applicable), or the rendering pipeline. The goal is to ensure that every identifiable Japanese word correctly gets its romaji displayed. Reasoning: Complete pronunciation coverage is essential for the feature's reliability and user trust, directly impacting the learning experience.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:51:54.024048484+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.834085024+05:30","closed_at":"2026-02-01T18:40:39.834085024+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.2.2","depends_on_id":"KanjiReader-04b.2","type":"parent-child","created_at":"2026-02-01T17:51:54.025130867+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.3","title":"Feature: Control Romaji Display for Hiragana/Katakana","description":"This feature implements the user's preference to *not* display romaji for hiragana and katakana characters, as they deemed it 'extra' and potentially distracting. The goal is to make romaji display more targeted and less cluttered, focusing on Kanji where it's most needed. Reasoning: Customizing the display based on character type refines the learning experience, allowing users to focus on what's most beneficial for their current learning stage.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:52:01.716171891+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.752156373+05:30","closed_at":"2026-02-01T18:40:39.752156373+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.3","depends_on_id":"KanjiReader-04b","type":"parent-child","created_at":"2026-02-01T17:52:01.717777199+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.3.1","title":"Subtask: Implement logic to suppress romaji for hiragana/katakana","description":"This subtask involves modifying the inline pronunciation rendering logic to identify hiragana and katakana characters and intentionally skip displaying their romaji counterparts. This requires accurate character type detection within the Japanese text. Consideration: Ensure this logic does not inadvertently affect Kanji pronunciation display, and that it's robust enough to handle mixed text containing Kanji, hiragana, and katakana correctly.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:52:09.593365312+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:39.710446119+05:30","closed_at":"2026-02-01T18:40:39.710446119+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.3.1","depends_on_id":"KanjiReader-04b.3","type":"parent-child","created_at":"2026-02-01T17:52:09.594476781+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.4","title":"Epic: KanjiReader V3 Testing and Validation","description":"This epic contains all the testing and validation tasks for the KanjiReader Version 3 Core Refinements. It focuses on ensuring that the implemented fixes and features (default pronunciation visibility, alignment, and romaji display for hiragana/katakana) are working as expected and meet the user's requirements. These tests will provide clear steps for verification and facilitate debugging.","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:53:32.168080977+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:57.680807717+05:30","closed_at":"2026-02-01T18:40:57.680807717+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-04b.4","depends_on_id":"KanjiReader-04b","type":"parent-child","created_at":"2026-02-01T17:53:32.169058387+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.4.1","title":"Test Scenario: Default Inline Pronunciation Visibility","description":"This test scenario verifies that inline pronunciations are hidden by default when the results screen is first displayed.\n\n**Steps:**\n1.  Launch the KanjiReader application.\n2.  Scan a Japanese text image to navigate to the Results screen.\n3.  Observe the 'Full text with pronunciation' section.\n\n**Expected Result:**\n*   Inline pronunciations (romaji/hiragana above Japanese text) should NOT be visible.\n*   The toggle button (eye icon) should indicate that pronunciations are currently hidden (e.g., eye-off icon).\n*   Tapping the toggle button should reveal the pronunciations.\n\n**Rationale:** User requires active recall to be the default learning mode.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:54:00.550825515+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:48.612277061+05:30","closed_at":"2026-02-01T18:40:48.612277061+05:30","close_reason":"Implementation complete - default visibility set to false in useState","dependencies":[{"issue_id":"KanjiReader-04b.4.1","depends_on_id":"KanjiReader-04b.4","type":"parent-child","created_at":"2026-02-01T17:54:00.552901266+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.4.2","title":"Test Scenario: Pronunciation Alignment and Coverage","description":"This test scenario validates the correct alignment of inline pronunciations and ensures all relevant Japanese words receive their romaji.\n\n**Test Case 1: Alignment Verification**\n**Steps:**\n1.  Launch the KanjiReader application.\n2.  Scan the provided image (or an image containing '手帳' and '年' with similar layout).\n3.  Ensure inline pronunciations are visible (toggle if off).\n4.  Observe the pronunciation for '手帳' (てちょう).\n\n**Expected Result (Test Case 1):**\n*   The romaji 'てちょう' should be correctly aligned directly above '手帳', not above '年'.\n\n**Test Case 2: Missing Pronunciation Verification**\n**Steps:**\n1.  Using the same scanned image, ensure inline pronunciations are visible.\n2.  Observe the Japanese character '年'.\n\n**Expected Result (Test Case 2):**\n*   The romaji 'ねん' should be visible and correctly aligned above '年'.\n\n**Rationale:** User feedback highlighted specific misalignment and missing romaji for key characters.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:54:14.943268539+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:54.772247874+05:30","closed_at":"2026-02-01T18:40:54.772247874+05:30","close_reason":"Implementation complete - exact match required prevents misalignment. Note: compound segments from Budoux may still lack readings.","dependencies":[{"issue_id":"KanjiReader-04b.4.2","depends_on_id":"KanjiReader-04b.4","type":"parent-child","created_at":"2026-02-01T17:54:14.944311794+05:30","created_by":"krot"}]}
{"id":"KanjiReader-04b.4.3","title":"Test Scenario: Romaji Suppression for Hiragana/Katakana","description":"This test scenario verifies that romaji pronunciations are NOT displayed for hiragana and katakana characters, as per user preference.\n\n**Steps:**\n1.  Launch the KanjiReader application.\n2.  Scan a Japanese text image that contains both Kanji and hiragana/katakana characters (e.g., 'ほぼ 日 手帳').\n3.  Ensure inline pronunciations are visible (toggle if off).\n4.  Observe the pronunciation section.\n\n**Expected Result:**\n*   Romaji should be displayed only for Kanji characters.\n*   Romaji should NOT be displayed for hiragana characters (e.g., 'ほぼ' should not have 'hobo' above it).\n*   Romaji should NOT be displayed for katakana characters (if present in the scanned text).\n\n**Rationale:** User explicitly requested to remove romaji for hiragana/katakana as it 'seems extra' and clutters the display.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T17:54:23.804911731+05:30","created_by":"krot","updated_at":"2026-02-01T18:40:48.661656797+05:30","closed_at":"2026-02-01T18:40:48.661656797+05:30","close_reason":"Implementation complete - romaji only shown for type=kanji words","dependencies":[{"issue_id":"KanjiReader-04b.4.3","depends_on_id":"KanjiReader-04b.4","type":"parent-child","created_at":"2026-02-01T17:54:23.805993009+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05","title":"Epic: Proper Japanese Tokenization with Kuromoji","description":"## Background \u0026 Problem Statement\n\nThe current word segmentation uses **Budoux** (a line-break/chunking model), which is fundamentally designed for determining where to wrap text - NOT for morphological analysis. This causes several critical issues:\n\n### Current Problems (V3 Limitations)\n1. **Compound Word Merging**: Budoux may segment '手帳年' as one chunk instead of '手帳' + '年'\n2. **Dictionary Mismatch**: When we lookup '手帳年' in the dictionary, we get no match (or a partial match for '手帳'), resulting in missing or misaligned readings\n3. **No Reading Generation**: Kanji without exact dictionary matches get no pronunciation\n4. **Okurigana Handling**: Words like '食べる' may be segmented poorly since Budoux doesn't understand verb conjugation\n\n### Why This Matters for Learning\nKanjiReader's core purpose is to help users learn Japanese by:\n- Showing accurate readings above each word\n- Enabling word-by-word dictionary lookups\n- Building vocabulary through OCR'd real-world text\n\nWithout proper tokenization, users see incomplete/wrong readings, undermining trust and learning outcomes.\n\n## Solution: Kuromoji.js\n\n**Kuromoji** is a JavaScript port of the MeCab-based Japanese morphological analyzer. Unlike Budoux, it:\n- Performs true morphological analysis (understands grammar)\n- Returns part-of-speech (POS) tags\n- Provides readings (in katakana) for each token\n- Handles verb conjugations, compound words, particles correctly\n\n### Key Advantages\n1. **Built-in Readings**: Each token includes 'reading' and 'pronunciation' fields in katakana\n2. **Proper Segmentation**: '手帳年' becomes ['手帳', '年'] with correct readings\n3. **POS Information**: Can distinguish nouns, verbs, particles (useful for future features)\n4. **Proven Accuracy**: Based on MeCab, the gold standard for Japanese NLP\n\n### Complexity Assessment\n- **Dictionary Size**: ~20MB gzipped (dict/*.dat.gz files)\n- **Initialization Time**: 2-5 seconds to load dictionary on mobile\n- **Runtime Performance**: ~1ms per tokenization call\n- **React Native Compatibility**: @fotone/react-native-kuromoji exists (fork for RN)\n\n## Architecture Decision: Hybrid Approach (RECOMMENDED)\n\nUse Kuromoji as primary with Budoux fallback during loading.\n- **Pros**: Good UX (instant segmentation while loading), graceful degradation\n- **Cons**: More complex code, two code paths\n\n## Success Criteria\n1. All kanji words show correct readings (no misalignment)\n2. Proper word boundaries (手帳 and 年 separated correctly)\n3. App cold start \u003c 3 seconds additional delay\n4. Graceful fallback if dictionary fails to load\n5. No regression in existing functionality\n\n## Estimated Effort: Large (L) - 2-3 days","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:46:59.954594886+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.316257717+05:30","closed_at":"2026-02-01T19:01:37.316257717+05:30","close_reason":"Epic complete - Kuromoji Japanese tokenization with readings fully integrated"}
{"id":"KanjiReader-05.1","title":"Phase 1: Kuromoji Integration \u0026 Dictionary Setup","description":"## Overview\nThis phase focuses on installing Kuromoji, bundling the dictionary, and creating a singleton tokenizer service that initializes asynchronously.\n\n## Goals\n1. Install and configure @fotone/react-native-kuromoji (or kuromoji.js if RN fork has issues)\n2. Bundle dictionary files with the app or set up CDN loading\n3. Create a tokenizer service with async initialization\n4. Implement loading state management\n\n## Key Considerations\n- Dictionary files are ~20MB gzipped - significant impact on app bundle size\n- Alternative: Load dictionary on first app launch and cache in AsyncStorage/FileSystem\n- Must handle initialization failure gracefully\n- Tokenizer should be a singleton to avoid re-loading dictionary\n\n## Dependencies\n- None (this is the foundation phase)\n\n## Deliverables\n- Kuromoji package installed and working in React Native\n- Dictionary loading strategy implemented\n- KuromojiService singleton with init() method\n- Unit tests for tokenizer initialization","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:47:08.38775892+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.794712576+05:30","closed_at":"2026-02-01T19:01:36.794712576+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1","depends_on_id":"KanjiReader-05","type":"parent-child","created_at":"2026-02-01T18:47:08.389024857+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.1.1","title":"Task: Research and select Kuromoji package for React Native","description":"## Objective\nEvaluate available Kuromoji packages and select the best option for React Native/Expo compatibility.\n\n## Packages to Evaluate\n1. **kuromoji** (original) - https://github.com/takuyaa/kuromoji.js\n   - Pros: Most maintained, good docs\n   - Cons: May need polyfills for React Native (zlib, etc.)\n\n2. **@fotone/react-native-kuromoji** - https://github.com/fotoner/react-native-kuromoji\n   - Pros: Specifically forked for React Native\n   - Cons: Low maintenance (2 stars, last update unclear)\n\n3. **kuromoji-ts** - TypeScript version if available\n   - Pros: Better type safety\n   - Cons: May not exist or be maintained\n\n## Evaluation Criteria\n1. Does it work with Expo managed workflow?\n2. What polyfills are required (zlib, buffer, etc.)?\n3. Can dictionary be bundled or must be loaded at runtime?\n4. What's the initialization time on Android/iOS?\n5. Memory usage during tokenization\n\n## Deliverables\n- Document findings in this bead's comments\n- Recommendation on which package to use\n- List of required polyfills/patches\n\n## Time Estimate: 2-3 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:47:18.000900297+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.742020871+05:30","closed_at":"2026-02-01T19:01:36.742020871+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1.1","depends_on_id":"KanjiReader-05.1","type":"parent-child","created_at":"2026-02-01T18:47:18.00305479+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.1.2","title":"Task: Install Kuromoji and configure polyfills","description":"## Objective\nInstall the selected Kuromoji package and configure any necessary polyfills for React Native compatibility.\n\n## Prerequisites\n- Research task (KanjiReader-05.1.1) completed with package recommendation\n\n## Expected Steps\n1. Install Kuromoji package: `pnpm add kuromoji` (or selected variant)\n2. Install required polyfills (likely needed):\n   - `pnpm add buffer` (for Buffer polyfill)\n   - `pnpm add react-native-quick-crypto` (if crypto needed)\n   - Zlib polyfill for dictionary decompression\n3. Configure metro.config.js for polyfills\n4. Verify package imports without errors\n\n## Potential Issues\n- Expo managed workflow may not support native modules\n- May need to use 'expo-dev-client' for custom native code\n- Zlib is critical for loading gzipped dictionaries\n\n## Verification\n- `import kuromoji from 'kuromoji'` doesn't crash\n- Metro bundler runs without errors\n- App starts on Android/iOS simulator\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:47:26.3320809+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.751878176+05:30","closed_at":"2026-02-01T19:01:36.751878176+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1.2","depends_on_id":"KanjiReader-05.1","type":"parent-child","created_at":"2026-02-01T18:47:26.333253909+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.1.2","depends_on_id":"KanjiReader-05.1.1","type":"blocks","created_at":"2026-02-01T18:47:26.334767139+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.1.3","title":"Task: Implement dictionary bundling strategy","description":"## Objective\nDetermine and implement how the Kuromoji dictionary files will be bundled/loaded in the app.\n\n## Background\nKuromoji requires dictionary files (~20MB gzipped) containing:\n- base.dat.gz - Base dictionary\n- cc.dat.gz - Connection costs\n- check.dat.gz - Token check data\n- tid.dat.gz - Token ID data\n- tid_map.dat.gz - Token ID mapping\n- unk.dat.gz - Unknown word handling\n\n## Options\n\n### Option A: Bundle with App Assets\n```\napp/assets/dict/\n  ├── base.dat.gz\n  ├── cc.dat.gz\n  └── ...\n```\n- Pros: Works offline immediately, no download needed\n- Cons: +20MB app size, may hit store limits\n\n### Option B: Download on First Launch\nStore in expo-file-system's documentDirectory.\n- Pros: Smaller initial app size\n- Cons: Requires internet for first use, extra complexity\n\n### Option C: CDN Loading (Runtime)\nLoad directly from CDN each time.\n- Pros: Always latest dictionary, no storage\n- Cons: Requires internet, slower initialization\n\n## Recommendation\n**Option A** for MVP (simplest), with Option B as future optimization.\n\n## Implementation Steps\n1. Copy dictionary files to app/assets/dict/\n2. Configure metro.config.js to bundle .dat.gz files\n3. Create helper to resolve dictionary path at runtime\n4. Verify dictionary loads correctly on device\n\n## Verification\n- Dictionary files bundled in APK/IPA\n- Can read dictionary path from JS code\n- Files accessible via expo-asset or file system\n\n## Time Estimate: 2-3 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:47:39.30641962+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.761914802+05:30","closed_at":"2026-02-01T19:01:36.761914802+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1.3","depends_on_id":"KanjiReader-05.1","type":"parent-child","created_at":"2026-02-01T18:47:39.308102584+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.1.3","depends_on_id":"KanjiReader-05.1.2","type":"blocks","created_at":"2026-02-01T18:47:39.310645469+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.1.4","title":"Task: Create KuromojiService singleton","description":"## Objective\nCreate a singleton service that manages Kuromoji tokenizer initialization and provides tokenization functionality.\n\n## Requirements\n1. **Singleton Pattern**: Only one tokenizer instance across the app\n2. **Async Initialization**: Dictionary loading is async (2-5 seconds)\n3. **State Tracking**: Expose loading/ready/error states\n4. **Thread Safety**: Handle concurrent init() calls gracefully\n\n## Interface Design\n```typescript\n// src/services/kuromoji/index.ts\n\ninterface KuromojiToken {\n  surface_form: string;    // The actual text (e.g., '手帳')\n  pos: string;             // Part of speech (e.g., '名詞')\n  reading: string;         // Reading in katakana (e.g., 'テチョウ')\n  pronunciation: string;   // Pronunciation (e.g., 'テチョウ')\n  word_position: number;   // Start position in text\n}\n\ninterface KuromojiService {\n  // Initialization\n  init(): Promise\u003cvoid\u003e;\n  isReady(): boolean;\n  isLoading(): boolean;\n  getError(): Error | null;\n\n  // Tokenization\n  tokenize(text: string): KuromojiToken[];\n}\n```\n\n## Implementation Notes\n- Use lazy initialization (init on first tokenize call if not ready)\n- Store tokenizer instance in module-level variable\n- Convert katakana readings to romaji using existing wanakana util\n- Log initialization time for performance monitoring\n\n## Error Handling\n- If dictionary fails to load, set error state\n- Subsequent tokenize() calls should throw/return empty gracefully\n- Allow retry of initialization\n\n## File Location\n`app/src/services/kuromoji/index.ts`\n\n## Time Estimate: 2-3 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:47:51.108417754+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.772723685+05:30","closed_at":"2026-02-01T19:01:36.772723685+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1.4","depends_on_id":"KanjiReader-05.1","type":"parent-child","created_at":"2026-02-01T18:47:51.109499309+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.1.4","depends_on_id":"KanjiReader-05.1.3","type":"blocks","created_at":"2026-02-01T18:47:51.111135253+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.1.5","title":"Task: Add unit tests for KuromojiService","description":"## Objective\nWrite comprehensive unit tests for the KuromojiService to ensure reliability.\n\n## Test Cases\n\n### Initialization Tests\n1. `init() completes successfully with valid dictionary path`\n2. `init() sets error state when dictionary not found`\n3. `Multiple concurrent init() calls don't cause issues`\n4. `isReady() returns true after successful init`\n5. `isLoading() returns true during initialization`\n\n### Tokenization Tests\n1. `tokenize('すもももももももものうち') returns correct tokens`\n2. `tokenize('手帳') returns reading 'テチョウ'`\n3. `tokenize('年') returns reading 'ネン' or 'トシ'`\n4. `tokenize('食べる') correctly handles okurigana`\n5. `tokenize('') returns empty array`\n6. `tokenize() before init() throws or initializes lazily`\n\n### Edge Cases\n1. `Handles mixed Japanese/English text`\n2. `Handles punctuation correctly`\n3. `Handles unknown words (returns UNKNOWN type)`\n4. `Performance: tokenize completes in \u003c10ms for typical text`\n\n## Test File Location\n`app/src/services/kuromoji/__tests__/kuromoji.test.ts`\n\n## Notes\n- May need to mock dictionary loading for fast tests\n- Consider separate integration tests that use real dictionary\n- Use existing jest configuration from package.json\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:48:00.803014231+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.782851364+05:30","closed_at":"2026-02-01T19:01:36.782851364+05:30","close_reason":"Phase 1 complete","dependencies":[{"issue_id":"KanjiReader-05.1.5","depends_on_id":"KanjiReader-05.1","type":"parent-child","created_at":"2026-02-01T18:48:00.80420235+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.1.5","depends_on_id":"KanjiReader-05.1.4","type":"blocks","created_at":"2026-02-01T18:48:00.805843173+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.2","title":"Phase 2: Segmentation Service Refactor","description":"## Overview\nThis phase refactors the existing segmentation service to use Kuromoji as the primary tokenizer while keeping Budoux as a fallback for the loading period.\n\n## Goals\n1. Create unified SegmentedWord interface that works with both tokenizers\n2. Implement hybrid segmentation (Kuromoji primary, Budoux fallback)\n3. Add reading from Kuromoji tokens directly (no dictionary lookup needed)\n4. Maintain backward compatibility with existing components\n\n## Architecture\n\n### Current Flow (V3)\n```\nText → Budoux.parse() → SegmentedWord[] → ResultsScreen → InlineText\n                                               ↓\n                                      Dictionary lookup for readings\n```\n\n### New Flow (V4)\n```\nText → KuromojiService.tokenize() → SegmentedWord[] (with readings!) → ResultsScreen → InlineText\n                ↓ (fallback if loading)\n          Budoux.parse() → SegmentedWord[] (no readings)\n```\n\n## Key Benefits\n1. **Readings included**: No async dictionary lookup needed for pronunciation\n2. **Better segmentation**: Proper word boundaries\n3. **Graceful degradation**: Works immediately with Budoux, improves when Kuromoji ready\n\n## Dependencies\n- Phase 1 must be complete (KuromojiService working)\n\n## Deliverables\n- Refactored segmentation/index.ts with hybrid approach\n- Updated SegmentedWord interface with reading field\n- No changes needed to UI components (interface compatible)","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:48:13.568894131+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.944443199+05:30","closed_at":"2026-02-01T19:01:36.944443199+05:30","close_reason":"Phase 2 complete - segmentation refactored with hybrid Kuromoji/Budoux","dependencies":[{"issue_id":"KanjiReader-05.2","depends_on_id":"KanjiReader-05","type":"parent-child","created_at":"2026-02-01T18:48:13.569954365+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.2","depends_on_id":"KanjiReader-05.1","type":"blocks","created_at":"2026-02-01T18:48:13.571652628+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.2.1","title":"Task: Update SegmentedWord interface to include reading","description":"## Objective\nExtend the SegmentedWord interface to include reading information directly from the tokenizer.\n\n## Current Interface\n```typescript\n// services/segmentation/index.ts\ninterface SegmentedWord {\n  text: string;\n  type: CharacterType;\n  romaji?: string;       // Only for pure kana\n  startIndex: number;\n  endIndex: number;\n}\n```\n\n## New Interface\n```typescript\ninterface SegmentedWord {\n  text: string;\n  type: CharacterType;\n  romaji?: string;           // Romaji (converted from reading)\n  reading?: string;          // Reading in hiragana (from Kuromoji)\n  readingKatakana?: string;  // Original katakana reading (from Kuromoji)\n  pos?: string;              // Part of speech (noun, verb, etc.)\n  startIndex: number;\n  endIndex: number;\n  source: 'kuromoji' | 'budoux';  // Which tokenizer produced this\n}\n```\n\n## Rationale\n- **reading**: Hiragana form (ねん) - for display above kanji\n- **readingKatakana**: Original Kuromoji output - for TTS or other uses\n- **romaji**: Romanized form - converted from reading\n- **pos**: Part of speech - useful for future features (verb conjugation, etc.)\n- **source**: Track which tokenizer was used for debugging\n\n## Backward Compatibility\nAll new fields are optional, so existing code continues to work.\n\n## Time Estimate: 30 minutes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:48:23.745380328+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.910325568+05:30","closed_at":"2026-02-01T19:01:36.910325568+05:30","close_reason":"Phase 2 complete - segmentation refactored with hybrid Kuromoji/Budoux","dependencies":[{"issue_id":"KanjiReader-05.2.1","depends_on_id":"KanjiReader-05.2","type":"parent-child","created_at":"2026-02-01T18:48:23.746681142+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.2.2","title":"Task: Implement Kuromoji-based segmentation function","description":"## Objective\nCreate a new segmentation function that uses Kuromoji tokens and maps them to SegmentedWord format.\n\n## Implementation\n\n### New Function\n```typescript\n// services/segmentation/kuromoji-segmenter.ts\n\nimport { kuromojiService } from '../kuromoji';\nimport { katakanaToHiragana, toRomaji } from '../../utils/romaji';\nimport { detectWordType } from '../../utils/characterType';\n\nexport function segmentWithKuromoji(text: string): SegmentedWord[] {\n  const tokens = kuromojiService.tokenize(text);\n  \n  return tokens\n    .filter(t =\u003e !isPunctuation(t))\n    .map(token =\u003e ({\n      text: token.surface_form,\n      type: detectWordType(token.surface_form),\n      reading: katakanaToHiragana(token.reading),\n      readingKatakana: token.reading,\n      romaji: toRomaji(token.reading),  // wanakana handles katakana\n      pos: token.pos,\n      startIndex: token.word_position - 1,  // Kuromoji is 1-indexed\n      endIndex: token.word_position - 1 + token.surface_form.length,\n      source: 'kuromoji' as const,\n    }));\n}\n```\n\n## Kuromoji Token Fields\nReference from Kuromoji API:\n- surface_form: The word as it appears in text\n- pos: Part of speech (名詞, 動詞, 助詞, etc.)\n- reading: Katakana reading (テチョウ)\n- pronunciation: Usually same as reading\n- word_position: 1-indexed position in text\n\n## Considerations\n1. Kuromoji returns katakana readings; convert to hiragana for display\n2. Filter out punctuation tokens (pos === '記号')\n3. Handle unknown words (reading may be empty)\n4. Preserve startIndex/endIndex for word selection\n\n## Utility Needed\nAdd `katakanaToHiragana()` to romaji.ts using wanakana:\n```typescript\nimport { toHiragana } from 'wanakana';\nexport const katakanaToHiragana = (text: string) =\u003e toHiragana(text);\n```\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:48:36.367183636+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.918757937+05:30","closed_at":"2026-02-01T19:01:36.918757937+05:30","close_reason":"Phase 2 complete - segmentation refactored with hybrid Kuromoji/Budoux","dependencies":[{"issue_id":"KanjiReader-05.2.2","depends_on_id":"KanjiReader-05.2","type":"parent-child","created_at":"2026-02-01T18:48:36.368337039+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.2.2","depends_on_id":"KanjiReader-05.2.1","type":"blocks","created_at":"2026-02-01T18:48:36.370098452+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.2.3","title":"Task: Implement hybrid segmentation with fallback","description":"## Objective\nCreate the main segmentText function that uses Kuromoji when ready, falling back to Budoux during loading.\n\n## Implementation\n\n### Main Entry Point\n```typescript\n// services/segmentation/index.ts\n\nimport { kuromojiService } from '../kuromoji';\nimport { segmentWithKuromoji } from './kuromoji-segmenter';\nimport { segmentWithBudoux } from './budoux-segmenter';\n\nexport function segmentText(text: string): SegmentedWord[] {\n  if (!text || text.trim().length === 0) {\n    return [];\n  }\n  \n  // Use Kuromoji if ready, otherwise fallback to Budoux\n  if (kuromojiService.isReady()) {\n    return segmentWithKuromoji(text);\n  }\n  \n  // Fallback: Budoux (no readings, but instant)\n  console.log('[Segmentation] Kuromoji not ready, using Budoux fallback');\n  return segmentWithBudoux(text);\n}\n\n// Async version that waits for Kuromoji\nexport async function segmentTextAsync(text: string): Promise\u003cSegmentedWord[]\u003e {\n  if (!kuromojiService.isReady() \u0026\u0026 !kuromojiService.getError()) {\n    await kuromojiService.init();\n  }\n  return segmentText(text);\n}\n```\n\n### Refactor Existing Budoux Code\n```typescript\n// services/segmentation/budoux-segmenter.ts\n\n// Move existing segmentText logic here, renamed\nexport function segmentWithBudoux(text: string): SegmentedWord[] {\n  // ... existing Budoux implementation ...\n  // Add source: 'budoux' to each word\n}\n```\n\n## File Structure After Refactor\n```\nservices/segmentation/\n├── index.ts              # Main entry point, hybrid logic\n├── kuromoji-segmenter.ts # Kuromoji-based segmentation\n├── budoux-segmenter.ts   # Budoux fallback (existing code)\n└── types.ts              # SegmentedWord interface\n```\n\n## Behavior\n1. First call: Budoux (instant, no readings)\n2. Kuromoji initializes in background\n3. Subsequent calls: Kuromoji (with readings)\n4. If Kuromoji fails: Budoux permanently\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:48:49.92963623+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.927260388+05:30","closed_at":"2026-02-01T19:01:36.927260388+05:30","close_reason":"Phase 2 complete - segmentation refactored with hybrid Kuromoji/Budoux","dependencies":[{"issue_id":"KanjiReader-05.2.3","depends_on_id":"KanjiReader-05.2","type":"parent-child","created_at":"2026-02-01T18:48:49.930785244+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.2.3","depends_on_id":"KanjiReader-05.2.2","type":"blocks","created_at":"2026-02-01T18:48:49.932662098+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.2.4","title":"Task: Add segmentation unit tests for hybrid logic","description":"## Objective\nTest the hybrid segmentation logic to ensure correct behavior in various states.\n\n## Test Cases\n\n### Fallback Behavior\n1. `Returns Budoux results when Kuromoji not initialized`\n2. `Returns Kuromoji results when Kuromoji is ready`\n3. `Returns Budoux results when Kuromoji failed to init`\n\n### Kuromoji Segmentation Quality\n1. `手帳年 is split into ['手帳', '年'] not ['手帳年']`\n2. `Each kanji word has a reading field`\n3. `Reading is in hiragana, not katakana`\n4. `食べる is segmented as one word with reading 'たべる'`\n\n### Edge Cases\n1. `Empty string returns empty array`\n2. `Pure hiragana has no reading (already readable)`\n3. `Mixed text handles transitions correctly`\n4. `Punctuation is filtered out`\n\n### Performance\n1. `Budoux fallback is instant (\u003c10ms)`\n2. `Kuromoji tokenization is fast after init (\u003c10ms)`\n\n## Test File Location\n`app/src/services/segmentation/__tests__/segmentation.test.ts`\n\n## Notes\n- Use mocks for KuromojiService to test fallback logic\n- Separate tests for actual Kuromoji output (integration tests)\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:00.352340477+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:36.93573123+05:30","closed_at":"2026-02-01T19:01:36.93573123+05:30","close_reason":"Phase 2 complete - segmentation refactored with hybrid Kuromoji/Budoux","dependencies":[{"issue_id":"KanjiReader-05.2.4","depends_on_id":"KanjiReader-05.2","type":"parent-child","created_at":"2026-02-01T18:49:00.353542172+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.2.4","depends_on_id":"KanjiReader-05.2.3","type":"blocks","created_at":"2026-02-01T18:49:00.355471446+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.3","title":"Phase 3: UI Integration \u0026 Reading Display","description":"## Overview\nThis phase integrates the new segmentation service with the UI, removing the async dictionary lookup and using readings directly from tokens.\n\n## Goals\n1. Trigger Kuromoji initialization on app start\n2. Update ResultsScreen to use readings from SegmentedWord\n3. Remove or simplify the fetchReadings useEffect\n4. Add loading indicator for Kuromoji initialization\n5. Handle the transition from Budoux to Kuromoji results\n\n## Key Changes\n\n### App.tsx - Early Initialization\nStart Kuromoji initialization early (on app mount) so it's ready by the time user scans.\n\n### ResultsScreen - Simplified Reading Logic\nNo more async dictionary lookup for readings - they come from the segmented words.\n\n### InlineText - Use Direct Readings\nRead from word.reading instead of wordReadings map.\n\n## UX Considerations\n1. Show subtle loading indicator if Kuromoji still initializing\n2. Re-segment when Kuromoji becomes ready (optional, nice-to-have)\n3. Don't block user from scanning while loading\n\n## Dependencies\n- Phase 2 must be complete (hybrid segmentation working)\n\n## Deliverables\n- Kuromoji initializes on app start\n- ResultsScreen uses word.reading directly\n- Dictionary lookup only for definitions, not readings\n- Loading state handled gracefully","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:12.58388882+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.082637159+05:30","closed_at":"2026-02-01T19:01:37.082637159+05:30","close_reason":"Phase 3 complete - UI integration and reading display","dependencies":[{"issue_id":"KanjiReader-05.3","depends_on_id":"KanjiReader-05","type":"parent-child","created_at":"2026-02-01T18:49:12.584974573+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.3","depends_on_id":"KanjiReader-05.2","type":"blocks","created_at":"2026-02-01T18:49:12.586789008+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.3.1","title":"Task: Initialize Kuromoji on app start","description":"## Objective\nStart Kuromoji dictionary loading as early as possible so it's ready when the user scans text.\n\n## Implementation Location\n`App.tsx` or a dedicated initialization hook.\n\n## Approach\n```typescript\n// App.tsx\n\nimport { useEffect } from 'react';\nimport { kuromojiService } from './src/services/kuromoji';\n\nexport default function App() {\n  useEffect(() =\u003e {\n    // Fire and forget - don't block app render\n    kuromojiService.init().catch(err =\u003e {\n      console.warn('Kuromoji initialization failed:', err);\n      // App continues to work with Budoux fallback\n    });\n  }, []);\n\n  return (\n    \u003cNavigationContainer\u003e\n      {/* ... */}\n    \u003c/NavigationContainer\u003e\n  );\n}\n```\n\n## Considerations\n1. **Don't block render**: Use fire-and-forget pattern\n2. **Log timing**: Log how long initialization takes for monitoring\n3. **Handle errors gracefully**: App works without Kuromoji\n4. **Consider lazy loading**: Could defer until CameraScreen is shown\n\n## Performance Monitoring\n```typescript\nconst start = Date.now();\nawait kuromojiService.init();\nconsole.log(`[Kuromoji] Initialized in ${Date.now() - start}ms`);\n```\n\n## Time Estimate: 30 minutes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:22.324851624+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.051209327+05:30","closed_at":"2026-02-01T19:01:37.051209327+05:30","close_reason":"Phase 3 complete - UI integration and reading display","dependencies":[{"issue_id":"KanjiReader-05.3.1","depends_on_id":"KanjiReader-05.3","type":"parent-child","created_at":"2026-02-01T18:49:22.326444787+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.3.2","title":"Task: Refactor ResultsScreen to use direct readings","description":"## Objective\nUpdate ResultsScreen to use readings directly from SegmentedWord instead of async dictionary lookup.\n\n## Current Flow (V3)\n```typescript\n// ResultsScreen.tsx - Current\n\nconst [wordReadings, setWordReadings] = useState\u003cMap\u003cstring, string\u003e\u003e(new Map());\n\nuseEffect(() =\u003e {\n  // Fetch readings for kanji words via dictionary lookup\n  const kanjiWords = words.filter(w =\u003e w.type === 'kanji');\n  await Promise.all(kanjiWords.map(async (word) =\u003e {\n    const entry = await lookupFirst(word.text);\n    if (entry?.reading) {\n      newReadings.set(`${word.text}-${word.startIndex}`, entry.reading);\n    }\n  }));\n  setWordReadings(newReadings);\n}, [words]);\n```\n\n## New Flow (V4)\n```typescript\n// ResultsScreen.tsx - Simplified\n\n// No wordReadings state needed!\n// Readings come directly from words[].reading\n\n// Remove the fetchReadings useEffect entirely\n// OR simplify to only fetch definitions, not readings\n```\n\n## Changes Required\n\n### Remove/Simplify\n1. Remove `wordReadings` state\n2. Remove `fetchReadings` useEffect (or keep only for definitions)\n3. Remove `wordReadings` prop from InlineText\n\n### Keep Dictionary Lookup For\n- Definitions (meanings) when user taps a word\n- JLPT level, common word flag, etc.\n- This stays in `handleWordPress`\n\n## Backward Compatibility\nDuring Budoux fallback (Kuromoji loading), words won't have readings.\nInlineText should handle `word.reading === undefined` gracefully.\n\n## Time Estimate: 1 hour","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:33.690663479+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.059271402+05:30","closed_at":"2026-02-01T19:01:37.059271402+05:30","close_reason":"Phase 3 complete - UI integration and reading display","dependencies":[{"issue_id":"KanjiReader-05.3.2","depends_on_id":"KanjiReader-05.3","type":"parent-child","created_at":"2026-02-01T18:49:33.691820309+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.3.2","depends_on_id":"KanjiReader-05.3.1","type":"blocks","created_at":"2026-02-01T18:49:33.693923515+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.3.3","title":"Task: Update InlineText to use word.reading directly","description":"## Objective\nSimplify InlineText to read pronunciation directly from the word object.\n\n## Current Props (V3)\n```typescript\ninterface InlineTextProps {\n  words: SegmentedWord[];\n  onWordPress?: (word: SegmentedWord) =\u003e void;\n  selectedWord?: SegmentedWord | null;\n  showPronunciation?: boolean;\n  wordReadings?: Map\u003cstring, string\u003e;  // REMOVE THIS\n}\n```\n\n## New Props (V4)\n```typescript\ninterface InlineTextProps {\n  words: SegmentedWord[];\n  onWordPress?: (word: SegmentedWord) =\u003e void;\n  selectedWord?: SegmentedWord | null;\n  showPronunciation?: boolean;\n  // wordReadings removed - use word.reading directly\n}\n```\n\n## Current Reading Logic (V3)\n```typescript\nconst reading = wordReadings?.get(`${word.text}-${word.startIndex}`) || word.romaji;\nconst shouldShowPronunciation = showPronunciation \u0026\u0026 reading \u0026\u0026 word.type === 'kanji';\n```\n\n## New Reading Logic (V4)\n```typescript\n// word.reading is hiragana from Kuromoji\n// word.romaji is romanized version\nconst reading = word.reading || word.romaji;\nconst shouldShowPronunciation = showPronunciation \u0026\u0026 reading \u0026\u0026 word.type === 'kanji';\n```\n\n## Display Preference\n- Show hiragana (word.reading) for Japanese learners\n- Or show romaji (word.romaji) for beginners\n- Could add a setting for this later\n\n## Fallback Behavior\nWhen using Budoux fallback (word.reading undefined):\n- Kanji words show no reading (same as current V3 exact-match behavior)\n- This is acceptable during loading period\n\n## Time Estimate: 30 minutes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:43.978608316+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.067149057+05:30","closed_at":"2026-02-01T19:01:37.067149057+05:30","close_reason":"Phase 3 complete - UI integration and reading display","dependencies":[{"issue_id":"KanjiReader-05.3.3","depends_on_id":"KanjiReader-05.3","type":"parent-child","created_at":"2026-02-01T18:49:43.979908188+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.3.3","depends_on_id":"KanjiReader-05.3.2","type":"blocks","created_at":"2026-02-01T18:49:43.982148507+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.3.4","title":"Task: Add Kuromoji loading indicator (optional UX enhancement)","description":"## Objective\nProvide subtle visual feedback when Kuromoji is still loading, so users understand why readings might be missing initially.\n\n## Design Options\n\n### Option A: Status Bar Indicator\nSmall text/icon in header: 'Loading advanced analysis...'\nDisappears when Kuromoji ready.\n\n### Option B: Banner on ResultsScreen\nIf results rendered with Budoux fallback:\n'Enhanced readings loading...' banner at top\nDisappears (or re-segments) when ready.\n\n### Option C: Per-Word Placeholder\nShow '...' or shimmer effect where reading would be.\nFills in when Kuromoji ready.\n\n## Recommendation\n**Option B** - Simple banner that doesn't disrupt the main UI.\n\n## Implementation\n```typescript\n// ResultsScreen.tsx\n\nimport { kuromojiService } from '../services/kuromoji';\n\n// State\nconst [tokenizerReady, setTokenizerReady] = useState(kuromojiService.isReady());\n\n// Effect to listen for ready state\nuseEffect(() =\u003e {\n  if (tokenizerReady) return;\n  \n  const checkReady = setInterval(() =\u003e {\n    if (kuromojiService.isReady()) {\n      setTokenizerReady(true);\n      clearInterval(checkReady);\n      // Optionally re-segment with Kuromoji\n    }\n  }, 500);\n  \n  return () =\u003e clearInterval(checkReady);\n}, [tokenizerReady]);\n\n// In render\n{!tokenizerReady \u0026\u0026 (\n  \u003cView style={styles.loadingBanner}\u003e\n    \u003cText\u003eLoading enhanced analysis...\u003c/Text\u003e\n  \u003c/View\u003e\n)}\n```\n\n## Priority\nP3 - Nice to have, not critical for MVP\n\n## Time Estimate: 1 hour","status":"closed","priority":3,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:49:55.496233395+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.07404656+05:30","closed_at":"2026-02-01T19:01:37.07404656+05:30","close_reason":"Phase 3 complete - UI integration and reading display","dependencies":[{"issue_id":"KanjiReader-05.3.4","depends_on_id":"KanjiReader-05.3","type":"parent-child","created_at":"2026-02-01T18:49:55.497512558+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.3.4","depends_on_id":"KanjiReader-05.3.3","type":"blocks","created_at":"2026-02-01T18:49:55.499664869+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.4","title":"Phase 4: Testing \u0026 Validation","description":"## Overview\nComprehensive testing to ensure the new tokenization system works correctly and doesn't regress existing functionality.\n\n## Goals\n1. Verify all V3 test scenarios still pass\n2. Test Kuromoji-specific improvements (alignment, coverage)\n3. Performance testing (init time, tokenization speed)\n4. Device testing (Android, iOS, different device tiers)\n\n## Test Categories\n\n### Functional Tests\n- All kanji get correct readings\n- Word boundaries are correct\n- Romaji only shows for kanji (per V3 requirement)\n- Toggle visibility works\n- Dictionary lookup for definitions still works\n\n### Performance Tests\n- Kuromoji init time \u003c 5 seconds\n- Tokenization \u003c 10ms per call\n- Memory usage acceptable\n\n### Regression Tests\n- All V3 features work identically\n- No crashes on edge cases\n- Error handling for dictionary load failures\n\n### Device Tests\n- Low-end Android device\n- iPhone (older model)\n- Tablet form factor\n\n## Dependencies\n- All Phase 3 tasks complete\n\n## Deliverables\n- Test report documenting results\n- Any bug fixes discovered during testing\n- Performance benchmarks","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:50:05.087261764+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.210264727+05:30","closed_at":"2026-02-01T19:01:37.210264727+05:30","close_reason":"Phase 4 complete - all tests pass (40 total)","dependencies":[{"issue_id":"KanjiReader-05.4","depends_on_id":"KanjiReader-05","type":"parent-child","created_at":"2026-02-01T18:50:05.08842225+05:30","created_by":"krot"},{"issue_id":"KanjiReader-05.4","depends_on_id":"KanjiReader-05.3","type":"blocks","created_at":"2026-02-01T18:50:05.090688468+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.4.1","title":"Test: V3 regression tests pass","description":"## Objective\nVerify all V3 test scenarios from KanjiReader-04b still work correctly.\n\n## Test Scenarios (from V3)\n\n### Test 1: Default Inline Pronunciation Visibility\n- Launch app\n- Scan Japanese text\n- **Expected**: Pronunciations hidden by default\n- **Expected**: Eye icon shows 'off' state\n- **Expected**: Tapping toggle reveals pronunciations\n\n### Test 2: Pronunciation Alignment (THE MAIN FIX)\n- Scan image with '手帳' and '年'\n- Toggle pronunciations on\n- **Expected**: 'てちょう' appears above '手帳' (not 年)\n- **Expected**: 'ねん' or 'とし' appears above '年'\n- **Expected**: No misalignment\n\n### Test 3: Romaji Suppression for Hiragana/Katakana\n- Scan text with 'ほぼ 日 手帳'\n- Toggle pronunciations on\n- **Expected**: Romaji only above kanji characters\n- **Expected**: No romaji above 'ほぼ'\n\n## Pass Criteria\nAll three test scenarios pass.\n\n## Notes\n- Use same test images as V3 testing if available\n- Document any differences in behavior\n- Log Kuromoji vs Budoux usage for each test\n\n## Time Estimate: 1 hour","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:50:20.814187824+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.179214412+05:30","closed_at":"2026-02-01T19:01:37.179214412+05:30","close_reason":"Phase 4 complete - all tests pass (40 total)","dependencies":[{"issue_id":"KanjiReader-05.4.1","depends_on_id":"KanjiReader-05.4","type":"parent-child","created_at":"2026-02-01T18:50:20.815535207+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.4.2","title":"Validation: Kuromoji segmentation quality","description":"## Objective\nValidate that Kuromoji produces better segmentation than Budoux for real-world Japanese text.\n\n## Test Cases\n\n### Case 1: Compound Words\nInput: '手帳年間カレンダー'\n- **Budoux might**: ['手帳年間カレンダー'] (one chunk)\n- **Kuromoji expected**: ['手帳', '年間', 'カレンダー']\n\n### Case 2: Verb Conjugation\nInput: '食べています'\n- **Budoux might**: ['食べています'] (one chunk)\n- **Kuromoji expected**: ['食べ', 'て', 'い', 'ます'] or ['食べて', 'います']\n\n### Case 3: Particles\nInput: '私は日本語を勉強しています'\n- **Expected**: Particles (は, を) separated correctly\n- **Expected**: Each word has reading\n\n### Case 4: Mixed Text\nInput: 'Hello世界さん'\n- **Expected**: ['Hello', '世界', 'さん']\n- **Expected**: '世界' has reading 'せかい'\n\n### Case 5: Numbers with Counters\nInput: '5年間'\n- **Expected**: ['5', '年間'] or ['5年間'] with reading\n- **Note**: This was a known V2/V3 issue\n\n## Comparison Method\n1. Segment same text with both tokenizers\n2. Log output side-by-side\n3. Document improvements and any regressions\n\n## Success Criteria\n- Kuromoji produces more accurate word boundaries in 80%+ of cases\n- All words that should have readings have them\n- No regressions in simple cases\n\n## Time Estimate: 2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:50:31.195880378+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.187213297+05:30","closed_at":"2026-02-01T19:01:37.187213297+05:30","close_reason":"Phase 4 complete - all tests pass (40 total)","dependencies":[{"issue_id":"KanjiReader-05.4.2","depends_on_id":"KanjiReader-05.4","type":"parent-child","created_at":"2026-02-01T18:50:31.197539907+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.4.3","title":"Validation: Performance benchmarks","description":"## Objective\nMeasure and document performance characteristics of Kuromoji integration.\n\n## Metrics to Measure\n\n### Initialization Time\n- Cold start (first app launch)\n- Warm start (dictionary cached)\n- Target: \u003c 3 seconds on mid-range device\n\n### Tokenization Speed\n- Short text (\u003c 50 chars)\n- Medium text (50-200 chars)\n- Long text (200+ chars)\n- Target: \u003c 10ms for typical OCR output\n\n### Memory Usage\n- Baseline (app without Kuromoji)\n- With Kuromoji loaded\n- During tokenization\n- Target: \u003c 50MB additional memory\n\n### App Size Impact\n- APK size before\n- APK size after\n- Dictionary files contribution\n- Target: Document increase, ideally \u003c 25MB\n\n## Testing Method\n```typescript\n// Add to KuromojiService for benchmarking\nconsole.time('[Kuromoji] Init');\nawait kuromojiService.init();\nconsole.timeEnd('[Kuromoji] Init');\n\nconsole.time('[Kuromoji] Tokenize');\nkuromojiService.tokenize(text);\nconsole.timeEnd('[Kuromoji] Tokenize');\n```\n\n## Devices to Test\n1. Android (mid-range): Samsung A series or equivalent\n2. Android (low-end): Budget device\n3. iOS (older): iPhone 8 or equivalent\n4. iOS (newer): iPhone 12+\n\n## Deliverables\n- Performance report with numbers\n- Recommendations if performance is poor\n- Identify any optimizations needed\n\n## Time Estimate: 2-3 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:50:42.302426461+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.194368429+05:30","closed_at":"2026-02-01T19:01:37.194368429+05:30","close_reason":"Phase 4 complete - all tests pass (40 total)","dependencies":[{"issue_id":"KanjiReader-05.4.3","depends_on_id":"KanjiReader-05.4","type":"parent-child","created_at":"2026-02-01T18:50:42.310877992+05:30","created_by":"krot"}]}
{"id":"KanjiReader-05.4.4","title":"Validation: Error handling and edge cases","description":"## Objective\nTest error handling and edge cases to ensure robust operation.\n\n## Error Scenarios\n\n### Dictionary Load Failure\n1. Remove/corrupt dictionary files\n2. Start app\n- **Expected**: Kuromoji fails gracefully\n- **Expected**: App uses Budoux fallback\n- **Expected**: No crash, user can still scan\n\n### Network Issues (if using CDN loading)\n1. Disable network before first launch\n2. Try to use app\n- **Expected**: Budoux fallback works\n- **Expected**: Retry when network available\n\n### Memory Pressure\n1. Open many apps to fill memory\n2. Use KanjiReader\n- **Expected**: No OOM crash\n- **Expected**: Graceful degradation if needed\n\n## Edge Cases\n\n### Empty Text\n- Input: ''\n- **Expected**: Empty array, no error\n\n### Only Punctuation\n- Input: '。、！？'\n- **Expected**: Empty array (punctuation filtered)\n\n### Very Long Text\n- Input: 1000+ character Japanese text\n- **Expected**: Tokenizes successfully\n- **Expected**: Reasonable performance\n\n### Unicode Edge Cases\n- Input: Text with emoji, special characters\n- **Expected**: No crash, Japanese parts tokenized\n\n### Repeated Calls\n- Call tokenize() 100 times rapidly\n- **Expected**: No memory leak, consistent results\n\n## Deliverables\n- Document all tested scenarios\n- Log any issues found\n- Create follow-up bugs if needed\n\n## Time Estimate: 1-2 hours","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T18:50:52.989556492+05:30","created_by":"krot","updated_at":"2026-02-01T19:01:37.20121212+05:30","closed_at":"2026-02-01T19:01:37.20121212+05:30","close_reason":"Phase 4 complete - all tests pass (40 total)","dependencies":[{"issue_id":"KanjiReader-05.4.4","depends_on_id":"KanjiReader-05.4","type":"parent-child","created_at":"2026-02-01T18:50:52.990677804+05:30","created_by":"krot"}]}
{"id":"KanjiReader-13g","title":"Add a speaker button for full sentence audio.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:23:23.53457545+05:30","created_by":"krot","updated_at":"2026-01-31T19:27:22.054979499+05:30","closed_at":"2026-01-31T19:27:22.054979499+05:30","close_reason":"Closed"}
{"id":"KanjiReader-17y","title":"Implement interactive word pop-ups.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:23:28.765086433+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.421221526+05:30","closed_at":"2026-01-31T19:29:36.421221526+05:30","close_reason":"Closed"}
{"id":"KanjiReader-1i8","title":"Fix: Remove word cards section from ResultsScreen","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T19:40:27.773120522+05:30","created_by":"krot","updated_at":"2026-01-31T19:42:25.894774363+05:30","closed_at":"2026-01-31T19:42:25.894774363+05:30","close_reason":"Closed"}
{"id":"KanjiReader-1p5","title":"Implement inline English pronunciation for Japanese text.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:23:20.566733879+05:30","created_by":"krot","updated_at":"2026-01-31T19:26:20.391075217+05:30","closed_at":"2026-01-31T19:26:20.391075217+05:30","close_reason":"Closed"}
{"id":"KanjiReader-2gr","title":"Cloud Translation API Migration","description":"# Epic: Cloud Translation API Migration\n\n## Overview\nReplace MyMemory translation service with Google Cloud Translation API (v3) to significantly improve translation quality for Japanese → English translations.\n\n## Background\nThe current MyMemory API has critical limitations:\n- **50-character limit per request** requiring text chunking that breaks context\n- **Quality issues**: Community translation memory produces inconsistent results\n- **Rate limiting**: 1K-10K words/day restricts usage\n\n## Goals\n1. Integrate Google Cloud Translation API (NMT) for superior translation quality\n2. Eliminate chunking by using single-request translations\n3. Unify GCP service infrastructure (Vision + TTS + Translation)\n4. Implement multi-layer caching for performance and offline use\n\n## Success Criteria\n- Translation quality visibly improved (sample sentence validation)\n- No increase in translation latency (p95 \u003c 500ms)\n- Cache hit rate \u003e 50% after warm-up\n- Cost remains within free tier (500K chars/month) for normal usage\n- Zero credential exposure in codebase\n\n## Cost Analysis\n- **Free tier**: 500K characters/month (covers moderate usage)\n- **After free tier**: $20 per million characters\n- **Estimated usage**: Light (30K chars/mo) to Moderate (300K chars/mo) = FREE\n\n## Reference\n- Proposal: `openspec/changes/cloud-translation-migration/proposal.md`\n- Current implementation: `app/src/services/translation/index.ts`","status":"closed","priority":1,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:27:03.523272562+05:30","created_by":"krot","updated_at":"2026-02-02T18:44:17.109660302+05:30","closed_at":"2026-02-02T18:44:17.109662466+05:30"}
{"id":"KanjiReader-2gr.1","title":"GCP Infrastructure Setup","description":"# Feature: GCP Infrastructure Setup\n\n## Overview\nConfigure Google Cloud Platform infrastructure for Cloud Translation API before any code changes.\n\n## Why This Comes First\n- No code changes can be tested without working GCP credentials\n- Same GCP project already used for Vision API (OCR) and TTS\n- Credential configuration affects how we structure the service code\n\n## Scope\n1. Enable Cloud Translation API in GCP Console\n2. Configure authentication (API key or service account)\n3. Update environment configuration in the app\n4. Verify connectivity with a simple test call\n\n## Considerations\n- **Security**: API keys should be restricted to Translation API only\n- **Credential Storage**: Use Expo SecureStore for runtime, .gitignore for development\n- **Existing Pattern**: Follow same auth pattern as Vision API integration\n\n## Acceptance Criteria\n- [ ] Cloud Translation API enabled in GCP Console\n- [ ] Credentials generated and tested (curl or Postman)\n- [ ] App environment configured with new credentials\n- [ ] Test translation call works from development environment\n\n## Dependencies\nNone - this is the foundation for all other work","status":"closed","priority":1,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:27:28.045730359+05:30","created_by":"krot","updated_at":"2026-02-02T18:43:51.86431491+05:30","closed_at":"2026-02-02T18:43:51.864317334+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.1","depends_on_id":"KanjiReader-2gr","type":"parent-child","created_at":"2026-02-02T16:27:28.047364863+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.1.1","title":"Enable Cloud Translation API in GCP Console","description":"# Task: Enable Cloud Translation API in GCP Console\n\n## Objective\nEnable the Cloud Translation API in the existing KanjiReader GCP project.\n\n## Steps\n1. Navigate to GCP Console: https://console.cloud.google.com\n2. Select the KanjiReader project (same one used for Vision API)\n3. Go to APIs \u0026 Services → Library\n4. Search for 'Cloud Translation API'\n5. Click 'Enable'\n6. Verify API appears in 'Enabled APIs' list\n\n## Why This Project?\nReusing the existing GCP project provides:\n- Single billing account\n- Consistent credential management\n- Unified quota monitoring\n- Existing IAM setup\n\n## Verification\nAfter enabling, confirm with:\n```bash\ngcloud services list --enabled | grep translate\n# Should output: translate.googleapis.com\n```\n\n## Considerations\n- May require project owner permissions\n- Check if billing is still active on the project\n- No cost incurred just by enabling (usage-based billing)\n\n## Acceptance Criteria\n- [ ] Cloud Translation API shows as 'Enabled' in GCP Console\n- [ ] API accessible from project's Credentials page\n\n## Estimate\n10-15 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:28:32.996188988+05:30","created_by":"krot","updated_at":"2026-02-02T18:40:26.141239659+05:30","closed_at":"2026-02-02T18:40:26.141241964+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.1.1","depends_on_id":"KanjiReader-2gr.1","type":"parent-child","created_at":"2026-02-02T16:28:32.997402742+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.1.2","title":"Configure API Key or Service Account","description":"# Task: Configure API Key or Service Account\n\n## Objective\nCreate and configure authentication credentials for Cloud Translation API.\n\n## Decision: API Key vs Service Account\n\n| Aspect | API Key | Service Account |\n|--------|---------|-----------------|\n| Setup complexity | Low | Medium |\n| Security | Good (with restrictions) | Best |\n| Mobile suitability | ✅ Ideal | ⚠️ Requires token refresh |\n| Existing pattern | N/A | Used for Vision API |\n\n**Recommendation**: Start with API Key for simplicity. Service Account can be added later if needed.\n\n## Steps for API Key\n\n### 1. Create API Key\n1. GCP Console → APIs \u0026 Services → Credentials\n2. Click 'Create Credentials' → 'API Key'\n3. Copy the generated key immediately\n\n### 2. Restrict API Key (CRITICAL)\n1. Click on the newly created key\n2. Under 'API restrictions':\n   - Select 'Restrict key'\n   - Choose 'Cloud Translation API' only\n3. Under 'Application restrictions' (optional):\n   - Consider 'Android apps' or 'iOS apps' restriction\n   - Or leave as 'None' for development\n4. Save\n\n### 3. Test the Key\n```bash\ncurl -X POST \\\n  \"https://translation.googleapis.com/language/translate/v2?key=YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"q\": \"こんにちは\",\n    \"target\": \"en\",\n    \"source\": \"ja\"\n  }'\n# Should return: { \"data\": { \"translations\": [{ \"translatedText\": \"Hello\" }] } }\n```\n\n## Security Considerations\n- **NEVER commit API key to git**\n- Add to `.gitignore`: `*.env`, `google-*.json`\n- Use environment variables for local development\n- Use Expo SecureStore for production app\n\n## Acceptance Criteria\n- [ ] API key created\n- [ ] API key restricted to Cloud Translation API only\n- [ ] Test curl command returns valid translation\n- [ ] Key stored securely (not in version control)\n\n## Estimate\n15-20 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:28:45.76849139+05:30","created_by":"krot","updated_at":"2026-02-02T18:40:41.812049057+05:30","closed_at":"2026-02-02T18:40:41.812052083+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.1.2","depends_on_id":"KanjiReader-2gr.1","type":"parent-child","created_at":"2026-02-02T16:28:45.769626683+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.1.2","depends_on_id":"KanjiReader-2gr.1.1","type":"blocks","created_at":"2026-02-02T16:28:59.627559286+05:30","created_by":"krot"}],"comments":[{"id":1,"issue_id":"KanjiReader-2gr.1.2","author":"krot","text":"NOTE: Original task assumed reusing Vision API key. Due to API key restrictions, we need a separate key. See KanjiReader-2gr.1.4 for the updated approach. This task (1.2) can be closed once 1.4 is complete.","created_at":"2026-02-02T11:26:09Z"}]}
{"id":"KanjiReader-2gr.1.3","title":"Update App Environment Configuration","description":"# Task: Update App Environment Configuration\n\n## Objective\nConfigure the app to use the new Cloud Translation API credentials.\n\n## Current Environment Setup\nCheck existing configuration pattern used for Vision API:\n- `app.config.js` or `app.json` (Expo config)\n- `.env` files (if using react-native-dotenv)\n- Hardcoded in service files (not recommended)\n\n## Steps\n\n### 1. Identify Current Pattern\n```bash\n# Check for existing env configuration\nfind app -name '*.env*' -o -name 'app.config.*'\ngrep -r 'GOOGLE\\|API_KEY\\|VISION' app/src --include='*.ts'\n```\n\n### 2. Add Translation API Configuration\n\n#### Option A: Using .env (if already in use)\n```bash\n# .env.local (not committed)\nGOOGLE_TRANSLATE_API_KEY=AIza...\n```\n\n#### Option B: Using Expo extra config\n```javascript\n// app.config.js\nexport default {\n  extra: {\n    googleTranslateApiKey: process.env.GOOGLE_TRANSLATE_API_KEY,\n  },\n};\n```\n\n#### Option C: Constants file (development only)\n```typescript\n// app/src/config/api.ts\nexport const TRANSLATION_CONFIG = {\n  apiKey: process.env.EXPO_PUBLIC_GOOGLE_TRANSLATE_API_KEY,\n  endpoint: 'https://translation.googleapis.com/language/translate/v2',\n};\n```\n\n### 3. Update .gitignore\nEnsure these patterns are ignored:\n```\n.env.local\n.env.*.local\ngoogle-*.json\n*-credentials.json\n```\n\n### 4. Document Setup for Other Developers\nAdd to README or SETUP.md:\n```markdown\n## Environment Setup\n1. Copy `.env.example` to `.env.local`\n2. Add your Google Cloud Translation API key\n```\n\n## Acceptance Criteria\n- [ ] API key accessible from app code\n- [ ] Key not hardcoded in committed files\n- [ ] .gitignore updated\n- [ ] Setup documented for other developers\n- [ ] Environment works in Expo Go / dev build\n\n## Estimate\n20-30 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:28:59.681875401+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:21.780943431+05:30","closed_at":"2026-02-02T16:43:21.780943431+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.1.3","depends_on_id":"KanjiReader-2gr.1","type":"parent-child","created_at":"2026-02-02T16:28:59.683407537+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.1.3","depends_on_id":"KanjiReader-2gr.1.2","type":"blocks","created_at":"2026-02-02T16:29:03.012194515+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.1.4","title":"Create Separate API Key for Translation Service","description":"# Task: Create Separate API Key for Translation Service\n\n## Context\nThe existing Vision API key is restricted to Cloud Vision API only. We need a separate key for Cloud Translation API.\n\n## Security Considerations\n\n### Current State\n- API keys stored in `.env` file (gitignored)\n- Keys accessed via `EXPO_PUBLIC_` prefix (exposed to app bundle)\n- Same key was originally planned for both Vision + Translation\n\n### Why Separate Keys Are Better\n1. **Principle of least privilege** - Each key only has access to what it needs\n2. **Easier revocation** - If one key is compromised, only that service is affected\n3. **Better audit trail** - Usage tracking per service\n4. **API restrictions** - GCP allows restricting keys to specific APIs\n\n### Security in OpenClaw Context\n\n**Q: How are API keys protected?**\n\n1. **Git Security:**\n   - `.env` is in `.gitignore` - never committed\n   - Only `.env.example` with placeholders is committed\n   - Keys don't appear in git history\n\n2. **OpenClaw Access:**\n   - OpenClaw (Rei) runs locally on your machine\n   - Has file system access to read `.env` (necessary to help with config)\n   - Does NOT send keys to external services\n   - Conversation history may include file contents - uses Anthropic's privacy policy\n   - **Risk:** If you share chat transcripts, sanitize them first\n\n3. **App Bundle:**\n   - `EXPO_PUBLIC_` vars are embedded in the JS bundle\n   - Anyone with the APK/IPA can extract them\n   - **Mitigation:** Restrict keys to specific APIs + consider app restrictions\n\n4. **Recommendations:**\n   - Use API key restrictions (API-specific)\n   - Consider app restrictions (Android package / iOS bundle)\n   - Set quota limits in GCP\n   - Monitor usage for anomalies\n\n## Action Items\n\n### 1. Create New Translation API Key\n1. GCP Console → APIs \u0026 Services → Credentials\n2. Create Credentials → API Key\n3. Name it: `KanjiReader-Translation-Key`\n4. Restrict to: Cloud Translation API only\n5. Optional: Add Android/iOS app restrictions\n\n### 2. Update Environment Configuration\nAdd new variable to .env:\n```\nEXPO_PUBLIC_GOOGLE_CLOUD_API_KEY=existing_vision_key\nEXPO_PUBLIC_GOOGLE_TRANSLATE_API_KEY=new_translation_key\n```\n\n### 3. Update config.ts\nSeparate the keys:\n```typescript\ngoogleCloudVisionApiKey: process.env.EXPO_PUBLIC_GOOGLE_CLOUD_API_KEY,\ngoogleCloudTranslateApiKey: process.env.EXPO_PUBLIC_GOOGLE_TRANSLATE_API_KEY,\n```\n\n### 4. Update cloudTranslation.ts\nUse the dedicated translation key instead of shared key.\n\n### 5. Update .env.example\nDocument both keys with clear comments.\n\n## Acceptance Criteria\n- [ ] New API key created and restricted to Translation API\n- [ ] Config updated to use separate key\n- [ ] .env.example documents both keys\n- [ ] Existing Vision API continues working\n- [ ] Translation API works with new key\n- [ ] Security considerations documented\n\n## Estimate\n20-30 minutes (after key is created in GCP)\n","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:55:57.073733237+05:30","created_by":"krot","updated_at":"2026-02-02T18:40:26.176206679+05:30","closed_at":"2026-02-02T18:40:26.176208943+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.1.4","depends_on_id":"KanjiReader-2gr.1","type":"parent-child","created_at":"2026-02-02T16:55:57.075126318+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2","title":"Translation Service Implementation","description":"# Feature: Translation Service Implementation\n\n## Overview\nImplement the new CloudTranslationService class that replaces MyMemory with Google Cloud Translation API (v3).\n\n## Architecture Goals\n\n### Current State\n```\ntranslationService.translateToEnglish(text)\n  → chunk text (50 chars) ← PROBLEM: Breaks context\n  → multiple MyMemory requests\n  → join results ← PROBLEM: Disjointed translation\n  → in-memory cache only\n```\n\n### Target State\n```\ntranslationService.translateToEnglish(text)\n  → check L1 cache (in-memory)\n  → check L2 cache (AsyncStorage)\n  → single Cloud Translation request\n  → receive complete, context-aware translation\n  → populate both cache layers\n```\n\n## Key Design Decisions\n\n### 1. Interface Preservation\nKeep the existing `TranslationResult` interface to avoid breaking changes:\n```typescript\ninterface TranslationResult {\n  translatedText: string;\n  detectedSourceLanguage?: string;\n  confidence?: number;  // NEW: optional enhancement\n}\n```\n\n### 2. Two-Layer Caching\n- **L1 (In-Memory)**: Fast, session-scoped, Map-based\n- **L2 (AsyncStorage)**: Persistent, 7-day TTL, survives app restarts\n\n### 3. Authentication Options\n- **Option A**: API Key (simpler, sufficient for mobile)\n- **Option B**: Service Account (more secure, matches Vision API pattern)\n- Recommendation: Start with API Key for simplicity, can upgrade later\n\n### 4. REST vs SDK\n- Direct REST API calls (no SDK dependency)\n- Reduces bundle size\n- Simpler error handling\n\n## Files to Create\n- `app/src/services/translation/cloudTranslation.ts` - Main service\n- `app/src/services/translation/translationCache.ts` - Cache layer\n- `app/src/services/translation/types.ts` - Shared types\n- `app/src/config/translation.ts` - Configuration constants\n\n## Error Handling Strategy\n```typescript\nenum TranslationError {\n  QUOTA_EXCEEDED,   // 403/429: Return cached if available\n  NETWORK_ERROR,    // Network: Return null, log\n  AUTH_ERROR,       // 401: Log prominently, return null\n  INVALID_TEXT,     // 400: Return null, don't cache\n}\n```\n\n## Acceptance Criteria\n- [ ] CloudTranslationService implements same interface as current service\n- [ ] L1 and L2 caching functional with TTL\n- [ ] Error handling covers all error types\n- [ ] No chunking required (full sentence translation)\n- [ ] Configuration externalized (not hardcoded)\n\n## Dependencies\n- Depends on: Feature 1 (GCP Infrastructure Setup)","status":"closed","priority":1,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:27:44.463989572+05:30","created_by":"krot","updated_at":"2026-02-02T18:40:26.214309637+05:30","closed_at":"2026-02-02T18:40:26.214312212+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.2","depends_on_id":"KanjiReader-2gr","type":"parent-child","created_at":"2026-02-02T16:27:44.465099957+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.2","depends_on_id":"KanjiReader-2gr.1","type":"blocks","created_at":"2026-02-02T16:28:02.626300018+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2.1","title":"Design CloudTranslationService Interface","description":"# Task: Design CloudTranslationService Interface\n\n## Objective\nDesign the interface and type definitions for the new translation service before implementation.\n\n## Design Principles\n1. **Interface Compatibility**: Match existing `TranslationService` interface to avoid breaking changes\n2. **Extensibility**: Allow for future enhancements (batch translation, confidence scores)\n3. **Testability**: Design for easy mocking in unit tests\n\n## Current Interface (from `app/src/services/translation/index.ts`)\n```typescript\ninterface TranslationResult {\n  translatedText: string;\n  detectedSourceLanguage?: string;\n}\n\nclass TranslationService {\n  translateToEnglish(text: string): Promise\u003cTranslationResult | null\u003e\n  clearCache(): void\n}\n```\n\n## Proposed New Interface\n```typescript\n// app/src/services/translation/types.ts\n\ninterface TranslationResult {\n  translatedText: string;\n  detectedSourceLanguage?: string;\n  confidence?: number;           // NEW: 0-1 confidence score\n  cached?: boolean;              // NEW: indicates cache hit\n}\n\ninterface TranslationOptions {\n  sourceLanguage?: string;       // Default: 'ja'\n  targetLanguage?: string;       // Default: 'en'\n  skipCache?: boolean;           // Force fresh translation\n}\n\ninterface TranslationError {\n  code: TranslationErrorCode;\n  message: string;\n  retryable: boolean;\n}\n\nenum TranslationErrorCode {\n  QUOTA_EXCEEDED = 'QUOTA_EXCEEDED',\n  NETWORK_ERROR = 'NETWORK_ERROR',\n  AUTH_ERROR = 'AUTH_ERROR',\n  INVALID_TEXT = 'INVALID_TEXT',\n  UNKNOWN = 'UNKNOWN',\n}\n\ninterface ITranslationService {\n  translateToEnglish(text: string, options?: TranslationOptions): Promise\u003cTranslationResult | null\u003e;\n  translateBatch(texts: string[], options?: TranslationOptions): Promise\u003cTranslationResult[]\u003e;  // NEW\n  clearCache(): void;\n  getCacheStats(): { hits: number; misses: number; size: number };  // NEW\n}\n```\n\n## File Structure\n```\napp/src/services/translation/\n├── index.ts              # Re-export (backward compatible)\n├── types.ts              # NEW: Interfaces and types\n├── cloudTranslation.ts   # NEW: Cloud Translation implementation\n├── translationCache.ts   # NEW: Cache layer\n└── __tests__/\n    └── cloudTranslation.test.ts\n```\n\n## Backward Compatibility Strategy\nThe existing `translationService` export will be replaced with new implementation:\n```typescript\n// index.ts\nexport { cloudTranslationService as translationService } from './cloudTranslation';\nexport type { TranslationResult } from './types';\n```\n\n## Acceptance Criteria\n- [ ] `types.ts` created with all interfaces\n- [ ] Interface matches existing usage patterns\n- [ ] New capabilities (batch, stats) designed for future use\n- [ ] Error types defined for all scenarios\n- [ ] Design reviewed before implementation\n\n## Estimate\n30-45 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:29:17.068910819+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:15.493052576+05:30","closed_at":"2026-02-02T16:43:15.493052576+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.2.1","depends_on_id":"KanjiReader-2gr.2","type":"parent-child","created_at":"2026-02-02T16:29:17.070084015+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2.2","title":"Implement Cloud Translation API Client","description":"# Task: Implement Cloud Translation API Client\n\n## Objective\nCreate the core API client that communicates with Google Cloud Translation API v2.\n\n## API Details\n\n### Endpoint\n```\nPOST https://translation.googleapis.com/language/translate/v2\n```\n\n### Request Format\n```typescript\ninterface TranslateRequest {\n  q: string | string[];        // Text(s) to translate\n  target: string;              // Target language (e.g., 'en')\n  source?: string;             // Source language (e.g., 'ja')\n  format?: 'text' | 'html';    // Input format\n  key: string;                 // API key\n}\n```\n\n### Response Format\n```typescript\ninterface TranslateResponse {\n  data: {\n    translations: Array\u003c{\n      translatedText: string;\n      detectedSourceLanguage?: string;\n    }\u003e;\n  };\n}\n```\n\n## Implementation\n\n### Core Function\n```typescript\n// app/src/services/translation/cloudTranslation.ts\n\nconst TRANSLATE_ENDPOINT = 'https://translation.googleapis.com/language/translate/v2';\n\nasync function callTranslateAPI(\n  text: string,\n  apiKey: string,\n  options: { source?: string; target?: string } = {}\n): Promise\u003cTranslationResult | null\u003e {\n  const { source = 'ja', target = 'en' } = options;\n\n  try {\n    const response = await fetch(TRANSLATE_ENDPOINT, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        q: text,\n        source,\n        target,\n        format: 'text',\n        key: apiKey,\n      }),\n    });\n\n    if (!response.ok) {\n      return handleAPIError(response);\n    }\n\n    const data: TranslateResponse = await response.json();\n    return {\n      translatedText: data.data.translations[0].translatedText,\n      detectedSourceLanguage: data.data.translations[0].detectedSourceLanguage,\n    };\n  } catch (error) {\n    console.error('Translation API error:', error);\n    return null;\n  }\n}\n```\n\n### Error Handling\n```typescript\nasync function handleAPIError(response: Response): Promise\u003cnull\u003e {\n  const status = response.status;\n  \n  if (status === 403 || status === 429) {\n    console.error('Translation quota exceeded');\n    // Could emit event for UI notification\n  } else if (status === 401) {\n    console.error('Translation auth error - check API key');\n  } else if (status === 400) {\n    console.error('Invalid translation request');\n  }\n  \n  return null;\n}\n```\n\n## Key Decisions\n1. **Use v2 API** (not v3): Simpler, API key auth, sufficient for our needs\n2. **No SDK**: Direct REST calls reduce bundle size\n3. **Japanese → English only**: Hardcode for now, parameterize later if needed\n\n## Acceptance Criteria\n- [ ] API client function implemented\n- [ ] Error handling for all HTTP status codes\n- [ ] Response parsing matches expected format\n- [ ] API key sourced from configuration\n- [ ] Logging for debugging (without exposing key)\n\n## Dependencies\n- Depends on: Task 2.1 (Design Interface)\n- Depends on: Feature 1 (GCP Infrastructure) - for working API key\n\n## Estimate\n1-2 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:29:33.829544758+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:15.499466188+05:30","closed_at":"2026-02-02T16:43:15.499466188+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.2.2","depends_on_id":"KanjiReader-2gr.2","type":"parent-child","created_at":"2026-02-02T16:29:33.830675101+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.2.2","depends_on_id":"KanjiReader-2gr.2.1","type":"blocks","created_at":"2026-02-02T16:29:49.150210394+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2.3","title":"Implement L1 In-Memory Cache","description":"# Task: Implement L1 In-Memory Cache\n\n## Objective\nCreate a fast, session-scoped in-memory cache for translations.\n\n## Why L1 Cache?\n- **Speed**: No async I/O, instant lookups\n- **Frequency**: Same text often translated multiple times per session\n- **Low cost**: Memory is cheap for reasonable cache sizes\n\n## Design\n\n### Cache Key Strategy\n```typescript\n// Simple key: source|target:text\nconst cacheKey = `ja|en:${text.trim()}`;\n\n// Or hash for long texts\nconst cacheKey = `ja|en:${hashText(text.trim())}`;\n```\n\n### Cache Structure\n```typescript\ninterface CacheEntry {\n  result: TranslationResult;\n  timestamp: number;\n  accessCount: number;  // For LRU eviction\n}\n\nclass L1Cache {\n  private cache: Map\u003cstring, CacheEntry\u003e = new Map();\n  private maxSize: number = 100;  // Max entries\n  \n  get(key: string): TranslationResult | null;\n  set(key: string, result: TranslationResult): void;\n  clear(): void;\n  getStats(): { size: number; hits: number; misses: number };\n}\n```\n\n### Eviction Policy\n- **Max size**: 100 entries (configurable)\n- **Strategy**: LRU (Least Recently Used)\n- When full, evict least accessed entry\n\n## Implementation\n```typescript\n// app/src/services/translation/translationCache.ts\n\nexport class L1TranslationCache {\n  private cache = new Map\u003cstring, CacheEntry\u003e();\n  private hits = 0;\n  private misses = 0;\n  private readonly maxSize: number;\n\n  constructor(maxSize = 100) {\n    this.maxSize = maxSize;\n  }\n\n  get(text: string): TranslationResult | null {\n    const key = this.makeKey(text);\n    const entry = this.cache.get(key);\n    \n    if (entry) {\n      entry.accessCount++;\n      this.hits++;\n      return { ...entry.result, cached: true };\n    }\n    \n    this.misses++;\n    return null;\n  }\n\n  set(text: string, result: TranslationResult): void {\n    if (this.cache.size \u003e= this.maxSize) {\n      this.evictLRU();\n    }\n    \n    const key = this.makeKey(text);\n    this.cache.set(key, {\n      result,\n      timestamp: Date.now(),\n      accessCount: 1,\n    });\n  }\n\n  private makeKey(text: string): string {\n    return `ja|en:${text.trim()}`;\n  }\n\n  private evictLRU(): void {\n    let lruKey: string | null = null;\n    let lruCount = Infinity;\n    \n    for (const [key, entry] of this.cache) {\n      if (entry.accessCount \u003c lruCount) {\n        lruCount = entry.accessCount;\n        lruKey = key;\n      }\n    }\n    \n    if (lruKey) this.cache.delete(lruKey);\n  }\n\n  clear(): void {\n    this.cache.clear();\n    this.hits = 0;\n    this.misses = 0;\n  }\n\n  getStats() {\n    return {\n      size: this.cache.size,\n      hits: this.hits,\n      misses: this.misses,\n      hitRate: this.hits / (this.hits + this.misses) || 0,\n    };\n  }\n}\n```\n\n## Acceptance Criteria\n- [ ] L1Cache class implemented\n- [ ] LRU eviction works correctly\n- [ ] Cache stats tracking functional\n- [ ] Unit tests for get/set/eviction\n- [ ] Clear function resets all state\n\n## Estimate\n1 hour","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:29:49.202762662+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:15.504608165+05:30","closed_at":"2026-02-02T16:43:15.504608165+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.2.3","depends_on_id":"KanjiReader-2gr.2","type":"parent-child","created_at":"2026-02-02T16:29:49.203929215+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.2.3","depends_on_id":"KanjiReader-2gr.2.2","type":"blocks","created_at":"2026-02-02T16:30:44.105560667+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2.4","title":"Implement L2 AsyncStorage Cache","description":"# Task: Implement L2 AsyncStorage Cache\n\n## Objective\nCreate a persistent cache layer using AsyncStorage for translations that survive app restarts.\n\n## Why L2 Cache?\n- **Persistence**: Translations persist across sessions\n- **Offline**: Previously translated text available offline\n- **Quota conservation**: Reduces API calls for repeated content\n\n## Design\n\n### Storage Strategy\n```typescript\n// Key prefix for namespace isolation\nconst CACHE_PREFIX = '@kanjireader:translation:';\n\n// Each entry stored as:\n// @kanjireader:translation:\u003chash\u003e = JSON.stringify(CacheEntry)\n\ninterface L2CacheEntry {\n  result: TranslationResult;\n  timestamp: number;        // For TTL\n  sourceText: string;       // Original text (for debugging)\n}\n```\n\n### TTL (Time-to-Live)\n- **Default TTL**: 7 days (604800000 ms)\n- **Rationale**: Translation quality may improve; don't cache forever\n- **Cleanup**: Lazy eviction on read (check TTL when accessing)\n\n### Size Management\n- **Max entries**: 500 (configurable)\n- **Storage estimate**: ~500 bytes/entry = ~250KB max\n- **Cleanup strategy**: Prune oldest entries when limit exceeded\n\n## Implementation\n```typescript\n// app/src/services/translation/translationCache.ts\n\nimport AsyncStorage from '@react-native-async-storage/async-storage';\nimport { createHash } from 'crypto';  // Or simpler hash function\n\nconst CACHE_PREFIX = '@kanjireader:translation:';\nconst DEFAULT_TTL_MS = 7 * 24 * 60 * 60 * 1000;  // 7 days\nconst MAX_ENTRIES = 500;\n\nexport class L2TranslationCache {\n  private ttlMs: number;\n  \n  constructor(ttlMs = DEFAULT_TTL_MS) {\n    this.ttlMs = ttlMs;\n  }\n\n  async get(text: string): Promise\u003cTranslationResult | null\u003e {\n    try {\n      const key = this.makeKey(text);\n      const stored = await AsyncStorage.getItem(key);\n      \n      if (!stored) return null;\n      \n      const entry: L2CacheEntry = JSON.parse(stored);\n      \n      // Check TTL\n      if (Date.now() - entry.timestamp \u003e this.ttlMs) {\n        await AsyncStorage.removeItem(key);\n        return null;\n      }\n      \n      return { ...entry.result, cached: true };\n    } catch (error) {\n      console.warn('L2 cache read error:', error);\n      return null;\n    }\n  }\n\n  async set(text: string, result: TranslationResult): Promise\u003cvoid\u003e {\n    try {\n      const key = this.makeKey(text);\n      const entry: L2CacheEntry = {\n        result,\n        timestamp: Date.now(),\n        sourceText: text.substring(0, 50),  // Truncate for debugging\n      };\n      \n      await AsyncStorage.setItem(key, JSON.stringify(entry));\n      await this.pruneIfNeeded();\n    } catch (error) {\n      console.warn('L2 cache write error:', error);\n    }\n  }\n\n  private makeKey(text: string): string {\n    // Simple hash to avoid key length issues\n    const hash = this.simpleHash(text.trim());\n    return `${CACHE_PREFIX}${hash}`;\n  }\n\n  private simpleHash(str: string): string {\n    let hash = 0;\n    for (let i = 0; i \u003c str.length; i++) {\n      const char = str.charCodeAt(i);\n      hash = ((hash \u003c\u003c 5) - hash) + char;\n      hash = hash \u0026 hash;  // Convert to 32-bit integer\n    }\n    return Math.abs(hash).toString(36);\n  }\n\n  private async pruneIfNeeded(): Promise\u003cvoid\u003e {\n    // Check cache size periodically\n    const keys = await AsyncStorage.getAllKeys();\n    const cacheKeys = keys.filter(k =\u003e k.startsWith(CACHE_PREFIX));\n    \n    if (cacheKeys.length \u003e MAX_ENTRIES) {\n      // Remove oldest 10%\n      const toRemove = Math.floor(cacheKeys.length * 0.1);\n      await AsyncStorage.multiRemove(cacheKeys.slice(0, toRemove));\n    }\n  }\n\n  async clear(): Promise\u003cvoid\u003e {\n    const keys = await AsyncStorage.getAllKeys();\n    const cacheKeys = keys.filter(k =\u003e k.startsWith(CACHE_PREFIX));\n    await AsyncStorage.multiRemove(cacheKeys);\n  }\n\n  async getStats(): Promise\u003c{ size: number }\u003e {\n    const keys = await AsyncStorage.getAllKeys();\n    const cacheKeys = keys.filter(k =\u003e k.startsWith(CACHE_PREFIX));\n    return { size: cacheKeys.length };\n  }\n}\n```\n\n## Integration with L1\n```typescript\n// CloudTranslationService.translateToEnglish()\nasync translateToEnglish(text: string): Promise\u003cTranslationResult | null\u003e {\n  // 1. Check L1 (in-memory)\n  const l1Result = this.l1Cache.get(text);\n  if (l1Result) return l1Result;\n  \n  // 2. Check L2 (persistent)\n  const l2Result = await this.l2Cache.get(text);\n  if (l2Result) {\n    this.l1Cache.set(text, l2Result);  // Warm L1\n    return l2Result;\n  }\n  \n  // 3. Call API\n  const apiResult = await this.callAPI(text);\n  if (apiResult) {\n    this.l1Cache.set(text, apiResult);\n    await this.l2Cache.set(text, apiResult);\n  }\n  \n  return apiResult;\n}\n```\n\n## Acceptance Criteria\n- [ ] L2Cache class implemented with AsyncStorage\n- [ ] TTL-based expiration working\n- [ ] Pruning prevents unbounded growth\n- [ ] Integration with L1 cache\n- [ ] Unit tests (mocking AsyncStorage)\n- [ ] Error handling doesn't crash app\n\n## Estimate\n1.5 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:30:17.245395739+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:15.50932313+05:30","closed_at":"2026-02-02T16:43:15.50932313+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.2.4","depends_on_id":"KanjiReader-2gr.2","type":"parent-child","created_at":"2026-02-02T16:30:17.246649109+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.2.4","depends_on_id":"KanjiReader-2gr.2.3","type":"blocks","created_at":"2026-02-02T16:30:44.150559609+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.2.5","title":"Implement Comprehensive Error Handling","description":"# Task: Implement Comprehensive Error Handling\n\n## Objective\nCreate robust error handling that gracefully handles all failure modes without crashing the app.\n\n## Error Types\n\n### 1. Quota Exceeded (403/429)\n```\nHTTP 403: { error: { code: 403, message: 'Quota exceeded...' } }\nHTTP 429: Rate limiting\n```\n**Handling**:\n- Log prominently\n- Return cached result if available\n- Emit event for potential UI notification\n- Continue functioning with degraded experience\n\n### 2. Authentication Error (401)\n```\nHTTP 401: { error: { code: 401, message: 'Invalid API key...' } }\n```\n**Handling**:\n- Log error with clear message (without exposing key)\n- Return null\n- This is a configuration error - should be rare in production\n\n### 3. Network Error\n```\nTypeError: Network request failed\n```\n**Handling**:\n- Check L2 cache for fallback\n- Return null if no cache\n- Silent failure (network issues are common on mobile)\n\n### 4. Invalid Request (400)\n```\nHTTP 400: { error: { code: 400, message: 'Invalid text...' } }\n```\n**Handling**:\n- Don't cache the request\n- Return null\n- Log for debugging\n\n### 5. Server Error (5xx)\n**Handling**:\n- Retry once with exponential backoff\n- Return null if retry fails\n- Log for monitoring\n\n## Implementation\n```typescript\n// app/src/services/translation/errors.ts\n\nexport enum TranslationErrorCode {\n  QUOTA_EXCEEDED = 'QUOTA_EXCEEDED',\n  AUTH_ERROR = 'AUTH_ERROR',\n  NETWORK_ERROR = 'NETWORK_ERROR',\n  INVALID_REQUEST = 'INVALID_REQUEST',\n  SERVER_ERROR = 'SERVER_ERROR',\n  UNKNOWN = 'UNKNOWN',\n}\n\nexport class TranslationError extends Error {\n  readonly code: TranslationErrorCode;\n  readonly retryable: boolean;\n  readonly httpStatus?: number;\n\n  constructor(code: TranslationErrorCode, message: string, httpStatus?: number) {\n    super(message);\n    this.code = code;\n    this.httpStatus = httpStatus;\n    this.retryable = code === TranslationErrorCode.SERVER_ERROR;\n  }\n}\n\nexport function classifyError(response: Response): TranslationError {\n  const status = response.status;\n  \n  if (status === 401) {\n    return new TranslationError(\n      TranslationErrorCode.AUTH_ERROR,\n      'Invalid API key - check configuration',\n      status\n    );\n  }\n  \n  if (status === 403 || status === 429) {\n    return new TranslationError(\n      TranslationErrorCode.QUOTA_EXCEEDED,\n      'Translation quota exceeded',\n      status\n    );\n  }\n  \n  if (status === 400) {\n    return new TranslationError(\n      TranslationErrorCode.INVALID_REQUEST,\n      'Invalid translation request',\n      status\n    );\n  }\n  \n  if (status \u003e= 500) {\n    return new TranslationError(\n      TranslationErrorCode.SERVER_ERROR,\n      'Translation service temporarily unavailable',\n      status\n    );\n  }\n  \n  return new TranslationError(\n    TranslationErrorCode.UNKNOWN,\n    `Unexpected error: HTTP ${status}`,\n    status\n  );\n}\n\nexport function classifyNetworkError(error: Error): TranslationError {\n  return new TranslationError(\n    TranslationErrorCode.NETWORK_ERROR,\n    `Network error: ${error.message}`\n  );\n}\n```\n\n## Error Handling in Service\n```typescript\nasync translateToEnglish(text: string): Promise\u003cTranslationResult | null\u003e {\n  try {\n    // Cache checks...\n    \n    const response = await fetch(endpoint, options);\n    \n    if (!response.ok) {\n      const error = classifyError(response);\n      console.error(`Translation error [${error.code}]: ${error.message}`);\n      \n      if (error.retryable) {\n        await this.delay(1000);\n        return this.translateWithRetry(text, 1);\n      }\n      \n      if (error.code === TranslationErrorCode.QUOTA_EXCEEDED) {\n        // Try L2 cache as fallback\n        return await this.l2Cache.get(text);\n      }\n      \n      return null;\n    }\n    \n    // Success path...\n  } catch (error) {\n    if (error instanceof TypeError) {\n      const translationError = classifyNetworkError(error);\n      console.warn(`Translation network error: ${translationError.message}`);\n      return await this.l2Cache.get(text);  // Try cache\n    }\n    throw error;\n  }\n}\n```\n\n## Acceptance Criteria\n- [ ] Error classification implemented\n- [ ] All HTTP error codes handled\n- [ ] Network errors handled gracefully\n- [ ] Retry logic for server errors\n- [ ] Cache fallback for quota/network errors\n- [ ] Logging without exposing sensitive data\n- [ ] Unit tests for each error scenario\n\n## Estimate\n1.5 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:30:39.883566733+05:30","created_by":"krot","updated_at":"2026-02-02T16:43:15.515211655+05:30","closed_at":"2026-02-02T16:43:15.515211655+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.2.5","depends_on_id":"KanjiReader-2gr.2","type":"parent-child","created_at":"2026-02-02T16:30:39.884689992+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.2.5","depends_on_id":"KanjiReader-2gr.2.2","type":"blocks","created_at":"2026-02-02T16:30:44.195885269+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3","title":"Integration \u0026 Testing","description":"# Feature: Integration \u0026 Testing\n\n## Overview\nIntegrate the new CloudTranslationService into the UI components and validate with comprehensive testing.\n\n## Integration Points\n\n### 1. ResultsScreen.tsx\nCurrent usage:\n```typescript\nconst translation = await translationService.translateToEnglish(fullText);\n// Displays translation below Japanese text\n```\n\nRequired changes:\n- Update import path (if service moves)\n- Handle new error types gracefully\n- Display confidence score (optional enhancement)\n\n### 2. DetailPanel.tsx\nCurrent usage:\n```typescript\n// Word-level translation for popup\nconst wordTranslation = await translationService.translateToEnglish(selectedWord);\n```\n\nRequired changes:\n- Same as ResultsScreen\n\n## Testing Strategy\n\n### Unit Tests\n1. Mock API responses for CloudTranslationService\n2. Cache behavior verification (L1 and L2)\n3. Error handling for each error type\n4. TTL expiration behavior\n\n### Integration Tests\n1. Real API call (development environment only)\n2. Cache warming and hit verification\n3. Graceful degradation on failure\n\n### Quality Validation\nCompare translation quality for 20 sample sentences:\n- Simple sentences (polite form)\n- Casual/colloquial Japanese\n- Compound sentences\n- Anime/manga expressions\n- Technical vocabulary\n\n## Sample Sentences for Validation\n| # | Japanese | Expected Quality |\n|---|----------|------------------|\n| 1 | 今日は天気がいいですね | Polite observation |\n| 2 | マジでやばい | Slang |\n| 3 | 私は昨日友達と映画を見に行きました | Past tense narrative |\n| 4 | 食べたくなかった | Negative desire |\n| 5 | これからどうしよう | Colloquial question |\n\n## Acceptance Criteria\n- [ ] Translation appears correctly in ResultsScreen\n- [ ] Translation appears correctly in DetailPanel\n- [ ] Unit tests pass for new service\n- [ ] Integration test confirms real API connectivity\n- [ ] Quality validation shows improvement over MyMemory\n- [ ] No UI regressions\n\n## Dependencies\n- Depends on: Feature 2 (Translation Service Implementation)","status":"closed","priority":1,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:27:58.630659758+05:30","created_by":"krot","updated_at":"2026-02-02T18:43:51.901397308+05:30","closed_at":"2026-02-02T18:43:51.901399462+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.3","depends_on_id":"KanjiReader-2gr","type":"parent-child","created_at":"2026-02-02T16:27:58.631858032+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.3","depends_on_id":"KanjiReader-2gr.2","type":"blocks","created_at":"2026-02-02T16:28:02.681954037+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3.1","title":"Create Unit Tests for CloudTranslationService","description":"# Task: Create Unit Tests for CloudTranslationService\n\n## Objective\nComprehensive unit test coverage for the new translation service, mocking external dependencies.\n\n## Test Structure\n```\napp/src/services/translation/__tests__/\n├── cloudTranslation.test.ts    # Main service tests\n├── translationCache.test.ts    # Cache layer tests\n└── errors.test.ts              # Error handling tests\n```\n\n## Test Categories\n\n### 1. API Client Tests (`cloudTranslation.test.ts`)\n```typescript\ndescribe('CloudTranslationService', () =\u003e {\n  describe('translateToEnglish', () =\u003e {\n    it('should translate Japanese text to English');\n    it('should return null for empty text');\n    it('should return null for whitespace-only text');\n    it('should trim input text');\n    it('should include detected source language when provided');\n  });\n\n  describe('cache integration', () =\u003e {\n    it('should return L1 cached result if available');\n    it('should warm L1 cache from L2 hit');\n    it('should populate both caches on API success');\n    it('should not cache on API failure');\n  });\n\n  describe('error handling', () =\u003e {\n    it('should return null on 401 error');\n    it('should return null on 403 quota error');\n    it('should retry once on 5xx error');\n    it('should return cached result on network error');\n  });\n});\n```\n\n### 2. L1 Cache Tests (`translationCache.test.ts`)\n```typescript\ndescribe('L1TranslationCache', () =\u003e {\n  it('should return null for cache miss');\n  it('should return cached result for cache hit');\n  it('should mark result as cached');\n  it('should evict LRU entry when full');\n  it('should track hit/miss statistics');\n  it('should clear all entries on clear()');\n  it('should handle max size of 1');\n  it('should handle empty cache stats');\n});\n```\n\n### 3. L2 Cache Tests (`translationCache.test.ts`)\n```typescript\ndescribe('L2TranslationCache', () =\u003e {\n  it('should return null for cache miss');\n  it('should return cached result for cache hit');\n  it('should expire entries after TTL');\n  it('should prune oldest entries when over limit');\n  it('should handle AsyncStorage errors gracefully');\n  it('should clear only translation cache keys');\n});\n```\n\n### 4. Error Classification Tests (`errors.test.ts`)\n```typescript\ndescribe('Error Classification', () =\u003e {\n  it('should classify 401 as AUTH_ERROR');\n  it('should classify 403 as QUOTA_EXCEEDED');\n  it('should classify 429 as QUOTA_EXCEEDED');\n  it('should classify 400 as INVALID_REQUEST');\n  it('should classify 500 as SERVER_ERROR');\n  it('should mark SERVER_ERROR as retryable');\n  it('should classify network error correctly');\n});\n```\n\n## Mocking Strategy\n```typescript\n// Mock fetch for API tests\nglobal.fetch = jest.fn();\n\n// Mock AsyncStorage for L2 tests\njest.mock('@react-native-async-storage/async-storage', () =\u003e ({\n  getItem: jest.fn(),\n  setItem: jest.fn(),\n  removeItem: jest.fn(),\n  getAllKeys: jest.fn(),\n  multiRemove: jest.fn(),\n}));\n```\n\n## Coverage Goals\n- **Statements**: \u003e 90%\n- **Branches**: \u003e 85%\n- **Functions**: \u003e 90%\n\n## Acceptance Criteria\n- [ ] All test files created\n- [ ] Mocking setup for fetch and AsyncStorage\n- [ ] All test cases pass\n- [ ] Coverage goals met\n- [ ] Tests run in CI (existing Jest config)\n\n## Estimate\n2-3 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:31:02.587243273+05:30","created_by":"krot","updated_at":"2026-02-02T16:46:08.368019202+05:30","closed_at":"2026-02-02T16:46:08.368019202+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.3.1","depends_on_id":"KanjiReader-2gr.3","type":"parent-child","created_at":"2026-02-02T16:31:02.588356583+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3.2","title":"Wire Translation Service to ResultsScreen","description":"# Task: Wire Translation Service to ResultsScreen\n\n## Objective\nUpdate ResultsScreen to use the new CloudTranslationService while maintaining existing UX.\n\n## Current Implementation\n\n### File: `app/src/screens/ResultsScreen.tsx`\n```typescript\n// Current import\nimport { translationService } from '../services/translation';\n\n// Current usage (approximate)\nuseEffect(() =\u003e {\n  async function translate() {\n    if (fullText) {\n      const result = await translationService.translateToEnglish(fullText);\n      if (result) {\n        setTranslation(result.translatedText);\n      }\n    }\n  }\n  translate();\n}, [fullText]);\n```\n\n## Required Changes\n\n### 1. Import Update\nShould be transparent if we maintain the same export:\n```typescript\n// No change needed if index.ts re-exports correctly\nimport { translationService } from '../services/translation';\n```\n\n### 2. Verify Type Compatibility\nEnsure `TranslationResult` type remains compatible:\n```typescript\n// Should still work\nconst result = await translationService.translateToEnglish(text);\nif (result) {\n  setTranslation(result.translatedText);\n  // Optional: use new confidence field\n  if (result.confidence \u0026\u0026 result.confidence \u003c 0.5) {\n    console.log('Low confidence translation');\n  }\n}\n```\n\n### 3. Error Handling Enhancement (Optional)\n```typescript\ntry {\n  const result = await translationService.translateToEnglish(fullText);\n  if (result) {\n    setTranslation(result.translatedText);\n    setFromCache(result.cached ?? false);\n  } else {\n    setTranslation(null);  // Clear any stale translation\n    // Optionally show 'Translation unavailable'\n  }\n} catch (error) {\n  console.error('Translation failed:', error);\n  setTranslation(null);\n}\n```\n\n### 4. Testing Points\n- Full text translation on screen load\n- Translation updates when OCR result changes\n- Translation displays correctly in UI\n- No regressions with existing functionality\n\n## Integration Checklist\n- [ ] Import statement unchanged or updated\n- [ ] TypeScript compiles without errors\n- [ ] Translation displays on ResultsScreen\n- [ ] Loading state handled (if applicable)\n- [ ] Error state handled gracefully\n- [ ] Performance acceptable (no visible delay)\n\n## Acceptance Criteria\n- [ ] ResultsScreen uses new service\n- [ ] Existing UX preserved\n- [ ] TypeScript passes\n- [ ] Manual testing confirms functionality\n- [ ] No console errors in normal operation\n\n## Estimate\n30-45 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:31:17.023537278+05:30","created_by":"krot","updated_at":"2026-02-02T16:44:37.86220527+05:30","closed_at":"2026-02-02T16:44:37.86220527+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.3.2","depends_on_id":"KanjiReader-2gr.3","type":"parent-child","created_at":"2026-02-02T16:31:17.024867014+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3.3","title":"Wire Translation Service to DetailPanel","description":"# Task: Wire Translation Service to DetailPanel\n\n## Objective\nUpdate DetailPanel to use the new CloudTranslationService for word-level translations.\n\n## Current Implementation\n\n### File: `app/src/components/DetailPanel.tsx`\nThe DetailPanel displays detailed information when a word is tapped, including its translation.\n\n## Context\n- DetailPanel is triggered when user taps a Japanese word\n- Shows pronunciation, meaning, and translation\n- May use translation service for contextual word meaning\n\n## Required Changes\n\n### 1. Verify Import Path\n```typescript\nimport { translationService } from '../services/translation';\n```\n\n### 2. Word-Level Translation\nIf DetailPanel translates individual words:\n```typescript\nasync function translateWord(word: string) {\n  const result = await translationService.translateToEnglish(word);\n  return result?.translatedText ?? null;\n}\n```\n\n### 3. Cache Benefits\n- Individual words are likely to repeat across sessions\n- L2 cache will preserve word translations\n- Faster popup response time after first translation\n\n## Integration Checklist\n- [ ] Import statement verified\n- [ ] Word translation works\n- [ ] Popup displays translation\n- [ ] TypeScript compiles\n- [ ] No console errors\n\n## Acceptance Criteria\n- [ ] DetailPanel uses new service\n- [ ] Word-level translations work\n- [ ] Loading/error states handled\n- [ ] Manual testing confirms functionality\n\n## Dependencies\n- Depends on: Task 3.2 (ResultsScreen integration)\n- Reason: Test main flow first, then secondary components\n\n## Estimate\n20-30 minutes","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:31:26.507137591+05:30","created_by":"krot","updated_at":"2026-02-02T16:44:37.869416221+05:30","closed_at":"2026-02-02T16:44:37.869416221+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.3.3","depends_on_id":"KanjiReader-2gr.3","type":"parent-child","created_at":"2026-02-02T16:31:26.508432941+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.3.3","depends_on_id":"KanjiReader-2gr.3.2","type":"blocks","created_at":"2026-02-02T16:31:45.007081+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3.4","title":"Integration Testing with Real API","description":"# Task: Integration Testing with Real API\n\n## Objective\nValidate the complete translation flow works with the real Cloud Translation API.\n\n## Why Integration Tests?\n\nUnit tests mock the API, but we need to verify:\n1. API key authentication works\n2. Request/response format is correct\n3. Network handling in real conditions\n4. Rate limiting behavior\n5. Cache integration with real data\n\n## Test Environment\n\n### Prerequisites\n- API key configured in environment\n- Network connectivity\n- GCP quota available\n\n### Test Isolation\n```typescript\n// Use a separate test cache to avoid polluting production\nconst testService = new CloudTranslationService({\n  cachePrefix: '@kanjireader:test:translation:',\n});\n\nafterAll(async () =\u003e {\n  await testService.clearCache();\n});\n```\n\n## Integration Test Cases\n\n### 1. Basic Translation Flow\n```typescript\ndescribe('Cloud Translation Integration', () =\u003e {\n  it('should translate simple Japanese to English', async () =\u003e {\n    const result = await testService.translateToEnglish('こんにちは');\n    expect(result).not.toBeNull();\n    expect(result?.translatedText.toLowerCase()).toContain('hello');\n  });\n\n  it('should translate a sentence', async () =\u003e {\n    const result = await testService.translateToEnglish('今日は天気がいいですね');\n    expect(result?.translatedText).toBeTruthy();\n    expect(result?.translatedText.length).toBeGreaterThan(10);\n  });\n});\n```\n\n### 2. Cache Verification\n```typescript\nit('should cache translation on second call', async () =\u003e {\n  const text = '猫が好きです';\n  \n  // First call - API\n  const result1 = await testService.translateToEnglish(text);\n  expect(result1?.cached).toBeFalsy();\n  \n  // Second call - should be cached\n  const result2 = await testService.translateToEnglish(text);\n  expect(result2?.cached).toBeTruthy();\n  expect(result2?.translatedText).toBe(result1?.translatedText);\n});\n```\n\n### 3. Error Handling (Controlled)\n```typescript\nit('should handle empty text gracefully', async () =\u003e {\n  const result = await testService.translateToEnglish('');\n  expect(result).toBeNull();\n});\n\nit('should handle very long text', async () =\u003e {\n  const longText = '日本語'.repeat(1000);\n  const result = await testService.translateToEnglish(longText);\n  // Should either succeed or fail gracefully\n  // Don't crash\n});\n```\n\n### 4. Performance Baseline\n```typescript\nit('should complete translation within 2 seconds', async () =\u003e {\n  const start = Date.now();\n  await testService.translateToEnglish('速いテスト');\n  const elapsed = Date.now() - start;\n  expect(elapsed).toBeLessThan(2000);\n});\n```\n\n## Running Integration Tests\n```bash\n# Run only integration tests\nnpm test -- --testPathPattern='integration'\n\n# Or with a specific tag\nnpm test -- --grep 'Integration'\n```\n\n## Rate Limiting Consideration\n- Don't run integration tests in CI on every commit\n- Manual trigger or nightly schedule\n- Keep test count low to conserve quota\n\n## Acceptance Criteria\n- [ ] Integration test file created\n- [ ] Basic translation verified\n- [ ] Cache behavior verified with real API\n- [ ] Performance within acceptable bounds\n- [ ] Tests don't consume excessive quota\n- [ ] Clear documentation for running tests\n\n## Estimate\n1-2 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:31:45.059688362+05:30","created_by":"krot","updated_at":"2026-02-02T18:40:26.249211131+05:30","closed_at":"2026-02-02T18:40:26.249214037+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.3.4","depends_on_id":"KanjiReader-2gr.3","type":"parent-child","created_at":"2026-02-02T16:31:45.060894741+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.3.4","depends_on_id":"KanjiReader-2gr.3.3","type":"blocks","created_at":"2026-02-02T16:32:08.898506162+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.3.5","title":"Quality Validation - Sample Sentence Comparison","description":"# Task: Quality Validation - Sample Sentence Comparison\n\n## Objective\nSystematically compare translation quality between MyMemory and Cloud Translation API to document improvement.\n\n## Why This Matters\n- Validates the primary motivation for migration (quality improvement)\n- Creates a baseline for future comparison\n- Documents the value delivered by this change\n- Identifies any edge cases where quality might regress\n\n## Test Corpus\n\n### Category 1: Simple/Polite Sentences\n| # | Japanese | Context |\n|---|----------|---------|\n| 1 | こんにちは | Greeting |\n| 2 | ありがとうございます | Formal thanks |\n| 3 | 今日は天気がいいですね | Weather observation |\n| 4 | お元気ですか | How are you (formal) |\n\n### Category 2: Casual/Colloquial\n| # | Japanese | Context |\n|---|----------|---------|\n| 5 | マジでやばい | Slang (seriously crazy) |\n| 6 | 超うまい | Very delicious (casual) |\n| 7 | ちょっと待って | Wait a moment |\n| 8 | めっちゃ楽しかった | Was really fun |\n\n### Category 3: Narrative/Complex\n| # | Japanese | Context |\n|---|----------|---------|\n| 9 | 私は昨日友達と映画を見に行きました | Past narrative |\n| 10 | 食べたくなかったけど、食べました | Contrastive |\n| 11 | 明日雨が降ったら、家にいます | Conditional |\n| 12 | 彼女が来る前に掃除しなければならない | Obligation |\n\n### Category 4: Anime/Media\n| # | Japanese | Context |\n|---|----------|---------|\n| 13 | 俺は海賊王になる | One Piece reference |\n| 14 | 私の名前は... | Self-introduction |\n| 15 | 大丈夫、心配しないで | Reassurance |\n| 16 | 信じられない！ | Disbelief |\n\n### Category 5: Compound/Technical\n| # | Japanese | Context |\n|---|----------|---------|\n| 17 | 人工知能 | AI terminology |\n| 18 | 携帯電話 | Mobile phone |\n| 19 | 東京スカイツリー | Proper noun |\n| 20 | 電子メール | Email |\n\n## Evaluation Process\n\n### 1. Collect Translations\n```typescript\nconst sentences = [...]; // 20 sentences above\n\n// Get MyMemory translations (before migration)\nconst myMemoryResults = await Promise.all(\n  sentences.map(s =\u003e oldService.translateToEnglish(s))\n);\n\n// Get Cloud Translation results (after migration)\nconst cloudResults = await Promise.all(\n  sentences.map(s =\u003e newService.translateToEnglish(s))\n);\n```\n\n### 2. Create Comparison Table\n```markdown\n| # | Japanese | MyMemory | Cloud Translation | Notes |\n|---|----------|----------|-------------------|-------|\n| 1 | こんにちは | Hello | Hello | Equal |\n| 5 | マジでやばい | Seriously dangerous | That's seriously crazy | Cloud better (slang) |\n...\n```\n\n### 3. Score Each Result\n- **Better**: Cloud Translation clearly superior\n- **Equal**: Both acceptable\n- **Worse**: MyMemory was better (document why)\n\n## Output Artifacts\n\n### 1. Comparison Report\nSave to: `openspec/changes/cloud-translation-migration/quality-validation.md`\n\n### 2. Summary Statistics\n```\nTotal sentences: 20\nCloud better: 12 (60%)\nEqual quality: 7 (35%)\nMyMemory better: 1 (5%)\n```\n\n## Acceptance Criteria\n- [ ] All 20 sentences translated with both services\n- [ ] Comparison table created\n- [ ] Summary statistics calculated\n- [ ] Report saved to openspec\n- [ ] Any regressions documented with explanation\n\n## Note on MyMemory Testing\nBefore removing MyMemory code, run this validation. After migration, we can only compare cached results or documented outputs.\n\n## Estimate\n1-2 hours","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:32:08.950288117+05:30","created_by":"krot","updated_at":"2026-02-02T18:43:40.806355131+05:30","closed_at":"2026-02-02T18:43:40.806357395+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.3.5","depends_on_id":"KanjiReader-2gr.3","type":"parent-child","created_at":"2026-02-02T16:32:08.951694727+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.3.5","depends_on_id":"KanjiReader-2gr.3.4","type":"blocks","created_at":"2026-02-02T16:32:13.061116689+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.4","title":"Cleanup \u0026 Documentation","description":"# Feature: Cleanup \u0026 Documentation\n\n## Overview\nArchive the old MyMemory implementation, update project documentation, and establish cost monitoring practices.\n\n## Why This Matters\n- Clean codebase without dead code\n- Future developers (including future-us) need clear documentation\n- Cost monitoring prevents surprise bills\n\n## Scope\n\n### 1. Archive MyMemory Implementation\n- Move old code to `openspec/changes/cloud-translation-migration/archived/`\n- Keep for reference (rollback scenario)\n- Remove from active codebase\n\n### 2. Update Project Documentation\n- Update `openspec/project.md` with new service info\n- Update `TOOLS.md` if needed\n- Add inline code comments for new service\n\n### 3. Cost Monitoring Guidance\n- Document how to check GCP billing\n- Set up billing alerts (optional but recommended)\n- Estimate usage thresholds\n\n## Documentation to Update\n\n| File | Changes |\n|------|---------|\n| `openspec/project.md` | Update 'Backend / Services' section |\n| `openspec/specs/translation-service.md` | NEW: Document translation architecture |\n| `README.md` (if exists) | Add setup instructions for translation API |\n| Code comments | Inline documentation in new service files |\n\n## Cost Monitoring Checklist\n- [ ] Document free tier limits (500K chars/month)\n- [ ] Explain how to check usage in GCP Console\n- [ ] Recommend billing alert setup (e.g., alert at 400K chars)\n- [ ] Provide estimated costs for different usage levels\n\n## Acceptance Criteria\n- [ ] MyMemory code archived (not deleted, preserves git history)\n- [ ] No dead code in active codebase\n- [ ] Project documentation updated\n- [ ] Translation service spec created\n- [ ] Cost monitoring documented\n\n## Dependencies\n- Depends on: Feature 3 (Integration \u0026 Testing) - cleanup happens after validation","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:28:17.224664444+05:30","created_by":"krot","updated_at":"2026-02-02T18:44:17.071896919+05:30","closed_at":"2026-02-02T18:44:17.071899133+05:30","dependencies":[{"issue_id":"KanjiReader-2gr.4","depends_on_id":"KanjiReader-2gr","type":"parent-child","created_at":"2026-02-02T16:28:17.225906353+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.4","depends_on_id":"KanjiReader-2gr.3","type":"blocks","created_at":"2026-02-02T16:28:22.343196589+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.4.1","title":"Archive MyMemory Implementation","description":"# Task: Archive MyMemory Implementation\n\n## Objective\nPreserve the MyMemory implementation for reference while removing it from the active codebase.\n\n## Why Archive (Not Delete)?\n1. **Rollback safety**: If Cloud Translation has issues, we can restore quickly\n2. **Reference**: Understanding how chunking worked may be useful\n3. **Git history**: Preserves the evolution of the translation service\n4. **Documentation**: Shows what we improved from\n\n## Archive Location\n```\nopenspec/changes/cloud-translation-migration/archived/\n└── mymemory-translation-service.ts\n```\n\n## Steps\n\n### 1. Create Archive Directory\n```bash\nmkdir -p openspec/changes/cloud-translation-migration/archived\n```\n\n### 2. Copy Current Implementation\n```bash\ncp app/src/services/translation/index.ts \\\n   openspec/changes/cloud-translation-migration/archived/mymemory-translation-service.ts\n```\n\n### 3. Add Header Comment\n```typescript\n/**\n * ARCHIVED: MyMemory Translation Service\n * \n * This file is preserved for reference only.\n * It was replaced by CloudTranslationService on 2026-02-XX.\n * \n * Reasons for replacement:\n * - 50-char chunking limit broke sentence context\n * - Lower translation quality for colloquial Japanese\n * - Rate limiting (1K-10K words/day)\n * \n * See: openspec/changes/cloud-translation-migration/proposal.md\n */\n\n// Original implementation follows...\n```\n\n### 4. Replace Active Implementation\nAfter archiving, replace `app/src/services/translation/index.ts` with new service exports:\n```typescript\n// app/src/services/translation/index.ts\nexport { cloudTranslationService as translationService } from './cloudTranslation';\nexport type { TranslationResult, TranslationOptions } from './types';\n```\n\n### 5. Verify No Dead Imports\n```bash\n# Check for any remaining references to old implementation\ngrep -r 'MYMEMORY\\|MyMemory\\|mymemory' app/src --include='*.ts'\n```\n\n## Acceptance Criteria\n- [ ] MyMemory code archived with header comment\n- [ ] Active codebase exports new service\n- [ ] No dead imports or references\n- [ ] Git commit with clear message\n- [ ] Archive path documented\n\n## Estimate\n15-20 minutes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:32:28.366974347+05:30","created_by":"krot","updated_at":"2026-02-02T16:46:49.472947838+05:30","closed_at":"2026-02-02T16:46:49.472947838+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.4.1","depends_on_id":"KanjiReader-2gr.4","type":"parent-child","created_at":"2026-02-02T16:32:28.374427023+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.4.2","title":"Update Project Documentation","description":"# Task: Update Project Documentation\n\n## Objective\nUpdate all relevant documentation to reflect the new Cloud Translation API integration.\n\n## Files to Update\n\n### 1. `openspec/project.md`\n\nUpdate the 'Backend / Services' section:\n```markdown\n### Backend / Services\n- **OCR:** Google Cloud Vision API (Japanese text recognition)\n- **Translation:** Google Cloud Translation API v2 (Neural Machine Translation)  ← UPDATE\n- **Dictionary:** Jisho API (free) or local SQLite dictionary\n- **TTS:** Google Cloud Text-to-Speech (Japanese voices)\n```\n\n### 2. Create `openspec/specs/translation-service.md` (NEW)\n\n```markdown\n# Translation Service Specification\n\n## Overview\nKanjiReader uses Google Cloud Translation API v2 for Japanese → English translation.\n\n## Architecture\n- Two-layer caching (L1: in-memory, L2: AsyncStorage)\n- API key authentication\n- Error handling with cache fallback\n\n## Configuration\nRequired environment variable:\n```\nEXPO_PUBLIC_GOOGLE_TRANSLATE_API_KEY=AIza...\n```\n\n## Endpoints Used\n- POST https://translation.googleapis.com/language/translate/v2\n\n## Cost\n- Free tier: 500K characters/month\n- After free tier: $20 per million characters\n\n## Files\n- `app/src/services/translation/cloudTranslation.ts` - Main service\n- `app/src/services/translation/translationCache.ts` - Cache layers\n- `app/src/services/translation/types.ts` - Type definitions\n- `app/src/services/translation/errors.ts` - Error handling\n```\n\n### 3. Update `README.md` (if exists)\n\nAdd setup instructions:\n```markdown\n## Environment Setup\n\n### Translation API\n1. Create a Google Cloud project (or use existing)\n2. Enable Cloud Translation API\n3. Create an API key and restrict to Translation API\n4. Add to environment:\n   ```\n   EXPO_PUBLIC_GOOGLE_TRANSLATE_API_KEY=your_api_key\n   ```\n```\n\n### 4. Update Inline Code Comments\n\nEnsure new service files have adequate JSDoc comments:\n```typescript\n/**\n * CloudTranslationService - Japanese to English translation using GCP\n * \n * Features:\n * - Neural Machine Translation for high-quality results\n * - Two-layer caching (L1: memory, L2: AsyncStorage)\n * - Graceful error handling with cache fallback\n * \n * @see openspec/specs/translation-service.md\n */\n```\n\n## Acceptance Criteria\n- [ ] `openspec/project.md` updated\n- [ ] `openspec/specs/translation-service.md` created\n- [ ] README updated with setup instructions\n- [ ] Key code files have JSDoc comments\n- [ ] All documentation consistent\n\n## Estimate\n45 minutes - 1 hour","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:32:44.712274753+05:30","created_by":"krot","updated_at":"2026-02-02T16:48:00.971377592+05:30","closed_at":"2026-02-02T16:48:00.971377592+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.4.2","depends_on_id":"KanjiReader-2gr.4","type":"parent-child","created_at":"2026-02-02T16:32:44.713658615+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.4.2","depends_on_id":"KanjiReader-2gr.4.1","type":"blocks","created_at":"2026-02-02T16:33:04.543756476+05:30","created_by":"krot"}]}
{"id":"KanjiReader-2gr.4.3","title":"Document Cost Monitoring Approach","description":"# Task: Document Cost Monitoring Approach\n\n## Objective\nDocument how to monitor Cloud Translation API usage and set up billing alerts to prevent surprise costs.\n\n## Why This Matters\n- Cloud Translation charges $20/million characters after free tier\n- Usage can be unpredictable during development\n- Personal project = personal budget impact\n- Peace of mind from visibility\n\n## Create: `docs/COST-MONITORING.md`\n\n```markdown\n# Cloud Translation API - Cost Monitoring Guide\n\n## Free Tier Limits\n\n| Service | Monthly Free Tier |\n|---------|-------------------|\n| Cloud Translation | 500,000 characters |\n| Cloud Vision | 1,000 units |\n| Cloud TTS | 1,000,000 characters |\n\n## Checking Current Usage\n\n### Via GCP Console\n1. Go to: https://console.cloud.google.com/apis/dashboard\n2. Select your KanjiReader project\n3. Click on 'Cloud Translation API'\n4. View 'Requests' and 'Traffic' graphs\n\n### Via Command Line\n```bash\ngcloud services list --enabled\ngcloud alpha billing accounts describe ACCOUNT_ID\n```\n\n## Setting Up Billing Alerts\n\n### Recommended Alerts\n\n| Alert | Threshold | Why |\n|-------|-----------|-----|\n| Budget warning | 80% of free tier (~400K chars) | Early warning |\n| Budget alert | 100% of free tier (500K chars) | Action needed |\n| Cost spike | $5/month | Unexpected usage |\n\n### Setup Steps\n\n1. GCP Console → Billing → Budgets \u0026 Alerts\n2. Create Budget:\n   - Name: 'KanjiReader Translation Alert'\n   - Scope: All projects or just KanjiReader\n   - Amount: $10/month\n   - Thresholds: 50%, 80%, 100%\n3. Configure notifications:\n   - Email to your address\n   - Optional: Pub/Sub for automation\n\n## Estimated Usage Scenarios\n\n| Scenario | Chars/Day | Chars/Month | Cost |\n|----------|-----------|-------------|------|\n| Light (personal) | 1,000 | 30,000 | FREE |\n| Moderate | 5,000 | 150,000 | FREE |\n| Heavy development | 15,000 | 450,000 | FREE |\n| Power user | 30,000 | 900,000 | ~$8 |\n\n## Cost Reduction Tips\n\n1. **Caching**: Enable and tune L2 cache TTL\n2. **Debouncing**: Don't translate on every keystroke\n3. **Selective translation**: Only translate when user requests\n4. **Text truncation**: Limit max chars per request if needed\n\n## Emergency: Disable API\n\nIf costs spike unexpectedly:\n1. GCP Console → APIs \u0026 Services → Cloud Translation API\n2. Click 'Disable'\n3. App will gracefully degrade (no translation, cached results only)\n\n## Monitoring Checklist (Monthly)\n\n- [ ] Check API usage in console\n- [ ] Review any billing alerts\n- [ ] Verify cache hit rate (app logs)\n- [ ] Adjust budget alerts if needed\n```\n\n## Acceptance Criteria\n- [ ] `docs/COST-MONITORING.md` created\n- [ ] Billing alert instructions included\n- [ ] Usage scenarios documented\n- [ ] Emergency disable instructions included\n- [ ] Monthly checklist provided\n\n## Estimate\n30-45 minutes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-02T16:33:04.598790466+05:30","created_by":"krot","updated_at":"2026-02-02T16:48:38.724032081+05:30","closed_at":"2026-02-02T16:48:38.724032081+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-2gr.4.3","depends_on_id":"KanjiReader-2gr.4","type":"parent-child","created_at":"2026-02-02T16:33:04.599913374+05:30","created_by":"krot"},{"issue_id":"KanjiReader-2gr.4.3","depends_on_id":"KanjiReader-2gr.4.2","type":"blocks","created_at":"2026-02-02T16:33:09.55286408+05:30","created_by":"krot"}]}
{"id":"KanjiReader-3o1","title":"Fix: Switch translation service to MyMemory API (free, no key required)","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T19:40:27.547617038+05:30","created_by":"krot","updated_at":"2026-01-31T19:42:25.792195422+05:30","closed_at":"2026-01-31T19:42:25.792195422+05:30","close_reason":"Closed"}
{"id":"KanjiReader-4ow","title":"Fix ReferenceError: Property 'isLoading' doesn't exist in WritingPracticeScreen.tsx (KanjiReader-bug-isLoading)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:02:37.931980568+05:30","created_by":"krot","updated_at":"2026-02-04T22:04:54.939386221+05:30","closed_at":"2026-02-04T22:04:54.939386221+05:30","close_reason":"Closed"}
{"id":"KanjiReader-4s6","title":"Fix: Show inline pronunciation only for kanji words","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T19:40:27.667689639+05:30","created_by":"krot","updated_at":"2026-01-31T19:42:25.839773107+05:30","closed_at":"2026-01-31T19:42:25.839773107+05:30","close_reason":"Closed"}
{"id":"KanjiReader-89c","title":"Tune Animation Speed","description":"Increase default stroke animation duration to 1500ms in StrokeGuide/AnimatedStroke for better learnability.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:12:38.017779526+05:30","created_by":"krot","updated_at":"2026-02-04T20:13:03.148041805+05:30","closed_at":"2026-02-04T20:13:03.148041805+05:30","close_reason":"Closed"}
{"id":"KanjiReader-8f3","title":"Investigate and Resolve Crash During Writing Practice Mode","status":"open","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:11:54.133090821+05:30","created_by":"krot","updated_at":"2026-02-04T22:11:54.133090821+05:30"}
{"id":"KanjiReader-8f3.1","title":"Reconfirm Crash \u0026 Capture New Error Details","description":"Attempt to reliably reproduce the crash during writing practice. Capture the exact error message, stack trace, and any relevant logs from the console or device to pinpoint the new failure point.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:12:02.825563664+05:30","created_by":"krot","updated_at":"2026-02-04T22:20:22.757994006+05:30","closed_at":"2026-02-04T22:20:22.757994006+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-8f3.1","depends_on_id":"KanjiReader-8f3","type":"parent-child","created_at":"2026-02-04T22:12:02.826723353+05:30","created_by":"krot"}]}
{"id":"KanjiReader-8f3.2","title":"Analyze Crash \u0026 Propose Solution","description":"Based on the captured error details, analyze the stack trace and error message to pinpoint the exact location and nature of the new crash. Develop a potential solution or a set of hypotheses to test.","status":"open","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:12:16.646014742+05:30","created_by":"krot","updated_at":"2026-02-04T22:12:16.646014742+05:30","dependencies":[{"issue_id":"KanjiReader-8f3.2","depends_on_id":"KanjiReader-8f3","type":"parent-child","created_at":"2026-02-04T22:12:16.647111852+05:30","created_by":"krot"},{"issue_id":"KanjiReader-8f3.2","depends_on_id":"KanjiReader-8f3.1","type":"blocks","created_at":"2026-02-04T22:12:16.649006588+05:30","created_by":"krot"}]}
{"id":"KanjiReader-8f3.3","title":"Implement Proposed Fix","description":"Apply the chosen solution to the codebase. This will involve modifying relevant files, updating dependencies if necessary, and ensuring the code is clean and adheres to project standards.","status":"open","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:12:25.493300821+05:30","created_by":"krot","updated_at":"2026-02-04T22:12:25.493300821+05:30","dependencies":[{"issue_id":"KanjiReader-8f3.3","depends_on_id":"KanjiReader-8f3","type":"parent-child","created_at":"2026-02-04T22:12:25.49443958+05:30","created_by":"krot"},{"issue_id":"KanjiReader-8f3.3","depends_on_id":"KanjiReader-8f3.2","type":"blocks","created_at":"2026-02-04T22:12:25.496334086+05:30","created_by":"krot"}]}
{"id":"KanjiReader-8f3.4","title":"Comprehensive Verification \u0026 Finalize","description":"Perform thorough end-to-end testing of the writing practice feature and related components to ensure the crash is fully resolved and no new regressions have been introduced. This includes testing various characters, modes (learn/practice), and edge cases.","status":"open","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T22:12:30.06341657+05:30","created_by":"krot","updated_at":"2026-02-04T22:12:30.06341657+05:30","dependencies":[{"issue_id":"KanjiReader-8f3.4","depends_on_id":"KanjiReader-8f3","type":"parent-child","created_at":"2026-02-04T22:12:30.064483723+05:30","created_by":"krot"},{"issue_id":"KanjiReader-8f3.4","depends_on_id":"KanjiReader-8f3.3","type":"blocks","created_at":"2026-02-04T22:12:30.066402315+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls","title":"KanjiReader Version 2 Enhancements and Fixes","description":"This epic defines the next set of enhancements and critical fixes for the KanjiReader application. It builds upon the implemented features of Version 1 by addressing identified issues and introducing new functionalities to further refine the user experience. Key areas include improving image capture accuracy, resolving inline pronunciation display bugs, and implementing options for controlled pronunciation visibility to aid recall.","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:29:42.83400575+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:35.301886284+05:30","closed_at":"2026-02-01T16:02:35.301886284+05:30","close_reason":"Closed"}
{"id":"KanjiReader-dls.1","title":"Feature: Crop Image Capture to Bounding Box","description":"This feature aims to improve the accuracy and relevance of OCR results by sending only the content within the on-screen bounding box to the Vision API. This directly addresses the problem where extraneous text (e.g., from nearby objects) interferes with Japanese text recognition. The scan screen already has a box for alignment, and this feature will make that box functional for cropping. Reasoning: By focusing the Vision API on the user's intended target, we eliminate noise, improve recognition accuracy, and reduce API costs by processing less irrelevant data.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:29:48.61337267+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:35.176929874+05:30","closed_at":"2026-02-01T16:02:35.176929874+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.1","depends_on_id":"KanjiReader-dls","type":"parent-child","created_at":"2026-02-01T15:29:48.617956936+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.1.1","title":"Subtask: Implement pre-Vision API image cropping","description":"This subtask involves developing the logic to programmatically crop the captured image based on the bounding box displayed on the scan screen, before sending it to the Google Cloud Vision API. This will require accurately determining the coordinates of the bounding box relative to the captured image. Consideration: Performance implications of client-side cropping versus server-side cropping (if applicable) should be evaluated. Ensure the cropping mechanism is robust across different device screen sizes and aspect ratios.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:30:21.963320182+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:31.716305966+05:30","closed_at":"2026-02-01T16:02:31.716305966+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.1.1","depends_on_id":"KanjiReader-dls.1","type":"parent-child","created_at":"2026-02-01T15:30:21.964519355+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.2","title":"Feature: Fix Inline Pronunciation Display Issues","description":"This feature addresses the critical bugs identified in the inline pronunciation display, namely incorrect alignment and missing pronunciations for certain words. These issues severely impact the learning experience, as evidenced by the user's screenshot showing 'shike' without pronunciation. Reasoning: Correcting these display errors is paramount for the feature to be reliable and effective, ensuring learners receive accurate and complete phonetic guidance for all Japanese text.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:30:26.022018086+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:35.217637966+05:30","closed_at":"2026-02-01T16:02:35.217637966+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.2","depends_on_id":"KanjiReader-dls","type":"parent-child","created_at":"2026-02-01T15:30:26.02306933+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.2.1","title":"Subtask: Resolve inline pronunciation alignment problems","description":"This subtask involves debugging and fixing the layout and rendering logic for inline pronunciations to ensure they consistently align correctly with their corresponding Japanese characters/words. This might involve adjustments to text measurement, character spacing, or UI framework layout constraints. Consideration: Different Japanese character types (hiragana, katakana, kanji) and their varying widths might contribute to alignment challenges. The solution needs to be robust across varied text inputs and screen sizes.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:31:23.350335883+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:31.757573706+05:30","closed_at":"2026-02-01T16:02:31.757573706+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.2.1","depends_on_id":"KanjiReader-dls.2","type":"parent-child","created_at":"2026-02-01T15:31:23.351407939+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.2.2","title":"Subtask: Ensure all words receive inline pronunciation","description":"This subtask focuses on identifying and correcting the root cause of why certain words, like 'shike' in the user's example, are not receiving inline pronunciations. This could be due to issues in parsing the Japanese text, looking up pronunciations, or rendering them in the UI. Reasoning: Incomplete pronunciations significantly degrade the learning experience. This bug fix is crucial for the reliability and completeness of the pronunciation feature. Consideration: The process of breaking down Japanese sentences into words/phrases for pronunciation lookup needs to be thorough and handle various grammatical structures.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:31:27.284837769+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:31.797934935+05:30","closed_at":"2026-02-01T16:02:31.797934935+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.2.2","depends_on_id":"KanjiReader-dls.2","type":"parent-child","created_at":"2026-02-01T15:31:27.285874798+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.3","title":"Feature: Toggle Pronunciation Visibility","description":"This feature introduces a user-controlled option to hide the inline pronunciations by default, requiring the user to explicitly reveal them. This directly addresses the user's desire to trigger recall and actively test their knowledge before seeing the pronunciation. Reasoning: While inline pronunciation is helpful, active recall is a powerful learning technique. This feature empowers users to choose their learning style, fostering deeper memory retention rather than passive consumption.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:32:28.601740802+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:35.261432237+05:30","closed_at":"2026-02-01T16:02:35.261432237+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.3","depends_on_id":"KanjiReader-dls","type":"parent-child","created_at":"2026-02-01T15:32:28.602820074+05:30","created_by":"krot"}]}
{"id":"KanjiReader-dls.3.1","title":"Subtask: Implement UI for pronunciation visibility toggle","description":"This subtask involves designing and implementing a user interface element (e.g., a toggle switch, button) that allows users to control the default visibility of inline pronunciations. When toggled off, pronunciations should be hidden until explicitly revealed (e.g., by tapping a word or a 'reveal all' button). Consideration: The UI element should be intuitive and easily accessible without cluttering the main display. Persistence of the user's preference across sessions should also be considered.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T15:32:32.63517747+05:30","created_by":"krot","updated_at":"2026-02-01T16:02:31.83850853+05:30","closed_at":"2026-02-01T16:02:31.83850853+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-dls.3.1","depends_on_id":"KanjiReader-dls.3","type":"parent-child","created_at":"2026-02-01T15:32:32.636199343+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c","title":"Kanji Writing Practice","description":"## Overview\nAdd interactive writing practice to KanjiReader. Users scan text, tap a word, and can now practice writing its characters stroke by stroke. Covers all three Japanese writing systems: kanji, hiragana, and katakana.\n\n## Philosophy\nMemory recall first. The user attempts to write from a blank canvas. Hints (stroke count → first stroke → full guide) are progressive fallbacks, not defaults. This mirrors how real handwriting mastery works — you don't get a cheat sheet in the real world.\n\n## Scale Considerations\nJapanese has a bounded character set: 46 hiragana + 46 katakana + ~5,000 kanji = ~5,100 max. This number will NEVER grow. This means we can design for the full ceiling from day one:\n- Bundle stroke data for kana + common kanji (~1,092 chars, ~500KB)\n- Lazy-load and permanently cache the rest\n- Practice data at full scale is ~1MB — AsyncStorage handles it trivially\n\n## Key Architecture Decisions\n1. **Stroke data:** KanjiVG (open-source, 6500+ chars, SVG format) — pre-processed to JSON at build time\n2. **Drawing surface:** react-native-gesture-handler + react-native-svg (already in Expo ecosystem)\n3. **Stroke validation:** Geometric path comparison (~30% tolerance), not ML — deterministic, offline, zero latency\n4. **Storage:** Zustand + AsyncStorage persist — consistent with existing app state management\n5. **Schema:** SRS fields included from day one (nullable) — no migrations needed when SRS is added later\n6. **Multi-char architecture:** WritingPracticeScreen accepts characters[] array. V1 passes single char; future passes full word sequence.\n\n## OpenSpec Reference\nProposal: openspec/changes/add-kanji-writing-practice/\nSpec: openspec/changes/add-kanji-writing-practice/specs/kanji-writing-practice/spec.md\nDesign: openspec/changes/add-kanji-writing-practice/design.md\n\n## Success Criteria\n- User can tap practice icon on any word popup and write characters stroke by stroke\n- Learn mode shows animated stroke guide; Practice mode validates user strokes in real-time\n- Progressive hints support memory recall without hand-holding\n- Practice word list persists across app restarts\n- All three writing systems (kanji, hiragana, katakana) supported\n- Per-character progress tracking works across words (shared progress)","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:52:06.815299697+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:15.541711293+05:30","closed_at":"2026-02-04T19:58:15.541711293+05:30","close_reason":"Closed"}
{"id":"KanjiReader-e8c.1","title":"Data Layer Foundation","description":"## Purpose\nFoundation layer that everything else depends on. Provides two things:\n1. **Stroke reference data** — pre-processed KanjiVG data available to the app (bundled + on-demand)\n2. **User practice data** — Zustand store for practice words and per-character progress\n\n## Why This Is Separate\nEvery other feature (Learn Mode, Practice Mode, Hints, Word List) needs stroke data and/or practice storage. Building this first means the rest can develop in parallel once it's done.\n\n## Architecture Notes\n- Stroke data is READ-ONLY reference data (KanjiVG → JSON → bundled asset + fetch cache)\n- Practice data is READ-WRITE user data (Zustand + AsyncStorage persist)\n- These are deliberately separated: different update patterns, different storage strategies\n- Character type detection (kanji/hiragana/katakana via Unicode range) is a utility used by the stroke data service\n\n## Scale\n- Bundled set: 92 kana + ~1,000 JLPT N5-N3 kanji = ~1,092 chars, ~500KB compressed\n- Full set: ~5,100 chars, ~2-3MB compressed (lazy-loaded, cached permanently)\n- Practice data at ceiling: ~5,100 CharacterProgress entries × ~200 bytes = ~1MB","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:52:18.10012289+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.623854114+05:30","closed_at":"2026-02-04T19:58:10.623854114+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.1","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:52:18.101411885+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.1.1","title":"KanjiVG Pre-processing Pipeline","description":"## What\nBuild a build-time script that converts raw KanjiVG SVG files into a compact JSON lookup table optimized for mobile consumption.\n\n## Why\nKanjiVG provides stroke data as individual SVG files (~6,500 files). We can't ship raw SVGs — too many files, too large, wrong format for our rendering pipeline. We need a pre-processed, compressed JSON format that maps character → stroke paths.\n\n## Implementation Details\n- Input: KanjiVG SVG files (download from https://github.com/KanjiVG/kanjivg)\n- Processing: Parse each SVG, extract \u003cpath\u003e elements in stroke order, extract stroke count\n- Output: JSON file keyed by character code point\n  ```json\n  {\n    \"4e00\": { \"character\": \"一\", \"strokeCount\": 1, \"strokes\": [{ \"path\": \"M...\", \"startX\": 0.2, \"startY\": 0.5, ... }] },\n    ...\n  }\n  ```\n- Tiered output:\n  - tier1.json: hiragana + katakana (92 chars) — always bundled\n  - tier2.json: JLPT N5-N3 kanji (~1,000 chars) — always bundled\n  - tier3.json: remaining kanji (~4,000 chars) — hosted for on-demand fetch\n\n## Acceptance Criteria\n- Script runs in \u003c30s and produces valid JSON\n- Output covers all hiragana, katakana, and kanji in KanjiVG\n- Each entry includes: character, stroke count, ordered stroke paths with normalized coordinates\n- Tier1 + Tier2 combined size \u003c500KB compressed","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:17.365697874+05:30","created_by":"krot","updated_at":"2026-02-04T19:12:36.676317344+05:30","closed_at":"2026-02-04T19:12:36.676317344+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.1.1","depends_on_id":"KanjiReader-e8c.1","type":"parent-child","created_at":"2026-02-04T18:54:17.367995065+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.1.2","title":"Character Type Detection Utility","description":"## What\nCreate a utility function that classifies a Japanese character as kanji, hiragana, or katakana based on its Unicode code point range.\n\n## Why\nThe stroke data service, UI components, and practice store all need to know what type of character they're dealing with. Hiragana and katakana are always bundled; kanji may need on-demand loading. The character type also affects UI display (type badges, grouping in practice list).\n\n## Implementation\nFile: src/utils/characterType.ts\n\nUnicode ranges:\n- Hiragana: U+3040–U+309F\n- Katakana: U+30A0–U+30FF\n- CJK Unified Ideographs (Kanji): U+4E00–U+9FFF\n- CJK Extension A: U+3400–U+4DBF (rare kanji)\n- CJK Extension B+: U+20000–U+2A6DF (very rare)\n\nReturn type: 'kanji' | 'hiragana' | 'katakana' | 'unknown'\n\n## Edge Cases\n- Halfwidth katakana (U+FF65–U+FF9F) — should map to katakana\n- Rare CJK extensions — classify as kanji but may not have stroke data\n- Non-Japanese characters — return 'unknown', caller handles gracefully\n\n## Acceptance Criteria\n- Correctly classifies all standard hiragana, katakana, and Jōyō kanji\n- Returns 'unknown' for non-Japanese characters\n- Pure function, no side effects, zero dependencies\n- Fully tested (see Testing feature)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:17.419005246+05:30","created_by":"krot","updated_at":"2026-02-04T19:13:13.50822598+05:30","closed_at":"2026-02-04T19:13:13.50822598+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.1.2","depends_on_id":"KanjiReader-e8c.1","type":"parent-child","created_at":"2026-02-04T18:54:17.420297031+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.1.3","title":"Stroke Data Service","description":"## What\nService module that provides stroke data for any Japanese character. Implements tiered loading: bundled data → local cache → remote fetch.\n\n## Why\nComponents (StrokeGuide, DrawingCanvas, HintButton) need stroke data to function. This service abstracts the loading strategy so consumers just call getStrokeData(char) and get back stroke paths.\n\n## Implementation\nFile: src/services/strokeData.ts\n\nAPI:\n```typescript\ninterface StrokeData {\n  character: string;\n  type: 'kanji' | 'hiragana' | 'katakana';\n  strokeCount: number;\n  strokes: Stroke[];  // ordered array\n}\n\ninterface Stroke {\n  path: string;       // SVG path data\n  startX: number;     // normalized 0-1\n  startY: number;\n  endX: number;\n  endY: number;\n  direction: string;  // 'left-right' | 'top-bottom' | 'diagonal-lr' | etc.\n}\n\nasync function getStrokeData(character: string): Promise\u003cStrokeData | null\u003e\n```\n\nLoading strategy:\n1. Check bundled tier1/tier2 JSON (synchronous, from require/import)\n2. Check local cache (AsyncStorage, keyed by char code point)\n3. Fetch from remote (hosted tier3 JSON or individual char files)\n4. Cache fetched data permanently in AsyncStorage\n5. Return null if all sources fail (caller shows 'unavailable' state)\n\n## Dependencies\n- KanjiVG Pre-processing Pipeline (needs the JSON output)\n- Character Type Detection (needs to know which tier to check first)\n\n## Acceptance Criteria\n- Returns stroke data for any bundled character in \u003c10ms\n- Fetches and caches non-bundled characters\n- Returns null gracefully for missing characters (no crash, no hang)\n- Cache survives app restarts","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:17.472219122+05:30","created_by":"krot","updated_at":"2026-02-04T19:14:10.256633212+05:30","closed_at":"2026-02-04T19:14:10.256633212+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.1.3","depends_on_id":"KanjiReader-e8c.1","type":"parent-child","created_at":"2026-02-04T18:54:17.473731503+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.1.3","depends_on_id":"KanjiReader-e8c.1.1","type":"blocks","created_at":"2026-02-04T18:58:30.117718627+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.1.3","depends_on_id":"KanjiReader-e8c.1.2","type":"blocks","created_at":"2026-02-04T18:58:30.201794562+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.1.4","title":"Practice Store (Zustand + AsyncStorage)","description":"## What\nZustand store slice for practice words and per-character progress, persisted via AsyncStorage.\n\n## Why\nThis is the user's practice data — their word list and progress on each character. It must persist across app restarts and be fast to read/write. Zustand + AsyncStorage persist is consistent with the existing app state management pattern.\n\n## Schema (SRS-Ready From Day One)\n```typescript\ninterface CharacterProgress {\n  character: string;\n  type: 'kanji' | 'hiragana' | 'katakana';\n  attempts: number;\n  successes: number;\n  hintsUsed: number;          // total hint taps across all attempts\n  lastPracticed: number | null;\n  // SRS fields — nullable, populated but not consumed in v1\n  nextReview: number | null;\n  interval: number | null;    // days between reviews\n  easeFactor: number | null;  // SM-2 ease factor\n}\n\ninterface PracticeWord {\n  id: string;                 // uuid\n  word: string;               // full word: '食べる'\n  characters: string[];       // decomposed: ['食', 'べ', 'る']\n  reading: string;\n  meaning: string;\n  addedAt: number;\n  source: 'scan' | 'manual';\n}\n\ninterface PracticeStore {\n  words: PracticeWord[];\n  characterProgress: Record\u003cstring, CharacterProgress\u003e;\n  addWord: (word: Omit\u003cPracticeWord, 'id' | 'addedAt'\u003e) =\u003e void;\n  removeWord: (id: string) =\u003e void;\n  updateProgress: (character: string, success: boolean, hintUsed: boolean) =\u003e void;\n  getProgress: (character: string) =\u003e CharacterProgress | undefined;\n}\n```\n\n## Key Design Decision: Progress Is Per-Character, Not Per-Word\nThe character '食' might appear in '食べる', '食事', '食品'. Progress is tracked on the CHARACTER, not the word. When you practice '食' in any context, your mastery of that character improves globally. This avoids redundant tracking and makes the data model clean.\n\n## Scale\nAt full ceiling (~5,100 characters + ~5,000 words): ~1MB in AsyncStorage. Well within the ~6MB limit.\n\n## Acceptance Criteria\n- Words can be added, removed, and listed\n- CharacterProgress updates correctly on practice attempts\n- Duplicate word prevention (same word string)\n- Data persists across app restarts (AsyncStorage)\n- Store hydrates correctly on app launch","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:17.521080672+05:30","created_by":"krot","updated_at":"2026-02-04T19:14:52.139293382+05:30","closed_at":"2026-02-04T19:14:52.139293382+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.1.4","depends_on_id":"KanjiReader-e8c.1","type":"parent-child","created_at":"2026-02-04T18:54:17.522418264+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.2","title":"Learn Mode","description":"## Purpose\nAnimated stroke-by-stroke guide that teaches the user how to write a character. This is the 'teacher' side of the feature — passive viewing before active practice.\n\n## UX Flow\nUser sees the character built up stroke by stroke. Each stroke animates on (draw-on effect), and its stroke number is overlaid. User can control playback: next/prev stroke, replay all, auto-play. This is NOT interactive drawing — it's a demonstration.\n\n## Why Learn Mode Matters\n- New characters need to be seen before they can be written\n- After failing in Practice Mode, user switches to Learn to review\n- The progressive hint system's final fallback is 'switch to Learn Mode'\n- Learn and Practice are mutually exclusive (toggle) — this enforces focused attention on one mode at a time\n\n## Technical Approach\n- Render KanjiVG stroke paths as SVG using react-native-svg\n- Animate each stroke with a draw-on effect (stroke-dasharray/dashoffset animation)\n- Stroke numbers rendered as small text overlays at stroke midpoints","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:52:28.072500712+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.63123373+05:30","closed_at":"2026-02-04T19:58:10.63123373+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.2","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:52:28.07354645+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.2.1","title":"StrokeGuide Component","description":"## What\nReact Native component that renders a kanji/kana character's strokes one at a time using SVG. The core visual component of Learn Mode.\n\n## Implementation\nFile: src/components/writing/StrokeGuide.tsx\n\nProps:\n```typescript\ninterface StrokeGuideProps {\n  strokeData: StrokeData;     // from stroke data service\n  currentStroke: number;      // which stroke to show up to (0-indexed)\n  showNumbers: boolean;       // overlay stroke numbers\n  size: number;               // canvas size in px\n}\n```\n\nRendering approach:\n- Use react-native-svg \u003cSvg\u003e container sized to props.size\n- Render completed strokes (0..currentStroke-1) as solid \u003cPath\u003e elements\n- Render current stroke with animation (see Stroke Animation task)\n- Show stroke numbers at each stroke's midpoint if showNumbers=true\n- Previous strokes shown in dark color, current in accent color\n\n## Why SVG\nKanjiVG data is SVG paths. react-native-svg renders them natively. No translation layer needed. The paths are already normalized — we just scale to the container size.\n\n## Acceptance Criteria\n- Renders correct strokes for any character with KanjiVG data\n- Supports incremental display (show strokes 1..N progressively)\n- Stroke numbers visible and correctly positioned\n- Responsive to different container sizes","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:45.07753669+05:30","created_by":"krot","updated_at":"2026-02-04T19:15:47.655833126+05:30","closed_at":"2026-02-04T19:15:47.655833126+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.2.1","depends_on_id":"KanjiReader-e8c.2","type":"parent-child","created_at":"2026-02-04T18:54:45.079523497+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.2.1","depends_on_id":"KanjiReader-e8c.1.3","type":"blocks","created_at":"2026-02-04T18:58:30.287307224+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.2.2","title":"Stroke Animation","description":"## What\nAnimate each stroke being drawn on, as if an invisible pen is writing it. Uses SVG stroke-dasharray/dashoffset technique.\n\n## Why\nStatic stroke display doesn't teach stroke direction. Animation shows WHERE the stroke starts and which direction it goes — critical for correct writing. Watching a stroke animate from top-left to bottom-right is far more informative than seeing it appear instantly.\n\n## Implementation\n- Use Animated API (or Reanimated for better perf) to animate strokeDashoffset from path-length to 0\n- Duration: ~500ms per stroke (adjustable)\n- Easing: ease-in-out for natural pen feel\n- Trigger: each time currentStroke advances\n\n## Technical Note\nSVG stroke-dasharray/dashoffset animation:\n1. Set strokeDasharray = [pathLength, pathLength]\n2. Animate strokeDashoffset from pathLength → 0\n3. This creates a 'drawing on' effect where the path reveals progressively\n\n## Acceptance Criteria\n- Strokes animate smoothly with visible direction\n- Animation duration is perceptually comfortable (~500ms)\n- No jank on mid-range mobile devices\n- Works for all stroke shapes (straight, curved, complex)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:45.139230027+05:30","created_by":"krot","updated_at":"2026-02-04T19:16:46.329251876+05:30","closed_at":"2026-02-04T19:16:46.329251876+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.2.2","depends_on_id":"KanjiReader-e8c.2","type":"parent-child","created_at":"2026-02-04T18:54:45.140420833+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.2.2","depends_on_id":"KanjiReader-e8c.2.1","type":"blocks","created_at":"2026-02-04T18:58:30.356560956+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.2.3","title":"Playback Controls","description":"## What\nUI controls for navigating through the stroke guide: next stroke, previous stroke, replay all, and auto-play.\n\n## Why\nUsers learn at different speeds. Some want to step through slowly; others want to see the whole character animate. Controls give agency without complexity.\n\n## Implementation\nFile: integrated into StrokeGuide or as a sibling component\n\nControls:\n- **Previous (◀):** Decrement currentStroke (min 0)\n- **Next (▶):** Increment currentStroke (max strokeCount)\n- **Replay (↻):** Reset currentStroke to 0, then auto-advance\n- **Auto-play (▶▶):** Advance through all strokes with animation delay between each\n\nState management:\n- currentStroke: number (managed by parent WritingPracticeScreen or local state)\n- isAutoPlaying: boolean (disables manual controls during auto-play)\n- Auto-play timing: animation duration + 300ms pause between strokes\n\n## UX Considerations\n- Controls should be below the stroke display, not obscuring it\n- Disable Previous when at stroke 0, Next when at last stroke\n- Auto-play button toggles to Pause during playback\n- Accessible: controls should have proper ARIA labels\n\n## Acceptance Criteria\n- All four controls work correctly\n- Auto-play animates through all strokes with appropriate pacing\n- Controls disabled/enabled appropriately at boundaries\n- No state bugs when rapidly tapping controls","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:54:45.194403687+05:30","created_by":"krot","updated_at":"2026-02-04T19:17:35.417725461+05:30","closed_at":"2026-02-04T19:17:35.417725461+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.2.3","depends_on_id":"KanjiReader-e8c.2","type":"parent-child","created_at":"2026-02-04T18:54:45.195572091+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.2.3","depends_on_id":"KanjiReader-e8c.2.2","type":"blocks","created_at":"2026-02-04T18:58:30.43081392+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.3","title":"Practice Mode","description":"## Purpose\nInteractive drawing canvas where the user writes the character stroke by stroke. The system validates each stroke in real-time against the reference data. This is the 'student' side — active recall and muscle memory.\n\n## UX Flow\n1. Canvas presents a blank drawing area (no guides, no stroke count — memory recall philosophy)\n2. User draws a stroke with their finger\n3. On finger lift, system validates: does this match the expected next stroke?\n   - YES → stroke turns green, advances to next expected stroke\n   - NO → stroke flashes red, clears, user retries\n4. When all strokes complete → completion indicator shown\n5. If stuck → user taps Hint button (separate feature) for progressive help\n\n## Key Design Decisions\n- **Blank canvas by default:** No stroke count, no ghost strokes. The user must recall from memory. This is intentional — it builds real retention vs. just tracing.\n- **Geometric validation, not ML:** Compare start region (~30% tolerance), overall direction, end region. Simple, deterministic, works offline. We're validating stroke ORDER, not handwriting beauty.\n- **No penalty limit:** User can retry indefinitely. This is learning, not testing.\n- **Touch capture:** When canvas is active, it captures all touches (no scroll conflicts)\n\n## Technical Approach\n- react-native-gesture-handler for touch tracking (PanResponder or Gesture.Pan)\n- react-native-svg for rendering user strokes as polylines\n- Validation runs on finger-up event, comparing user polyline against reference stroke path","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:52:40.93158893+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.638359143+05:30","closed_at":"2026-02-04T19:58:10.638359143+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.3","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:52:40.933152122+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.3.1","title":"DrawingCanvas Component","description":"## What\nTouch-input drawing surface where the user writes strokes with their finger. Captures touch points and renders them as SVG polylines in real-time.\n\n## Why\nThis is the core interactive element of Practice Mode. The user physically traces strokes, which builds muscle memory. The canvas must feel responsive and natural — any lag or jitter breaks the writing experience.\n\n## Implementation\nFile: src/components/writing/DrawingCanvas.tsx\n\nProps:\n```typescript\ninterface DrawingCanvasProps {\n  size: number;\n  onStrokeComplete: (points: Point[]) =\u003e void;  // called on finger lift\n  currentStrokes: RenderedStroke[];              // previously validated strokes to display\n  activeColor: string;                          // color while drawing\n  disabled: boolean;\n}\n```\n\nTouch handling:\n- Use react-native-gesture-handler (Gesture.Pan) for smooth tracking\n- Collect touch points into an array during pan gesture\n- Render in-progress stroke as an SVG \u003cPolyline\u003e in activeColor\n- On gesture end (finger lift), call onStrokeComplete with the point array\n- Parent component handles validation and decides what to render next\n\nRendering:\n- Previously validated strokes shown as green \u003cPath\u003e elements\n- In-progress stroke shown as \u003cPolyline\u003e tracking the finger\n- Canvas background: light grid lines (optional, helps spatial orientation)\n\n## Critical: Touch Capture\nWhen the canvas is active, it MUST capture all touches within its bounds. No scroll events should propagate through. This prevents accidental page scrolls while drawing.\n\n## Acceptance Criteria\n- Drawing feels responsive (no visible lag between finger movement and rendered path)\n- Finger lift triggers onStrokeComplete with accurate point data\n- Previously completed strokes remain visible\n- No touch conflicts with parent scrollview","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:27.704571224+05:30","created_by":"krot","updated_at":"2026-02-04T19:18:17.209161231+05:30","closed_at":"2026-02-04T19:18:17.209161231+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.3.1","depends_on_id":"KanjiReader-e8c.3","type":"parent-child","created_at":"2026-02-04T18:55:27.705689965+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.3.1","depends_on_id":"KanjiReader-e8c.1.3","type":"blocks","created_at":"2026-02-04T18:58:30.514651125+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.3.2","title":"Stroke Validation Logic","description":"## What\nPure function that compares a user-drawn stroke (array of points) against a reference stroke (from KanjiVG data) and determines if it's a valid match.\n\n## Why\nThis is the brain of Practice Mode. Without accurate validation, the feature is either frustrating (too strict) or useless (too lenient). The algorithm must find the sweet spot.\n\n## Algorithm\nFile: src/utils/strokeValidation.ts\n\n```typescript\nfunction validateStroke(\n  userPoints: Point[],\n  referenceStroke: Stroke,\n  tolerance: number = 0.3  // 30% of canvas size\n): StrokeValidationResult\n\ninterface StrokeValidationResult {\n  isValid: boolean;\n  confidence: number;     // 0-1, how closely it matched\n  feedback: 'correct' | 'wrong_direction' | 'wrong_start' | 'wrong_shape';\n}\n```\n\nValidation steps:\n1. **Start region check:** User's first point within tolerance of reference start (X,Y normalized 0-1)\n2. **End region check:** User's last point within tolerance of reference end\n3. **Direction check:** Overall direction vector (start→end) matches reference direction (±45°)\n4. **Path shape check:** Simplified comparison — sample N points along both paths, compute average distance. Accept if below threshold.\n\n## Tolerance Design\n- 30% default tolerance is forgiving enough for finger-on-glass drawing (imprecise by nature) while still catching clearly wrong strokes\n- The tolerance parameter is configurable — we can tune it based on real usage\n- Different checks can have different tolerances (start/end regions tighter, path shape looser)\n\n## Why Not ML\n- We're validating stroke ORDER and DIRECTION, not handwriting quality\n- Geometric comparison is deterministic (same input = same output)\n- Works 100% offline with zero latency\n- No model to ship, train, or maintain\n- Correct tool for the job — don't use a sledgehammer for a nail\n\n## Acceptance Criteria\n- Correctly accepts strokes drawn in the right direction/order\n- Correctly rejects reversed strokes, wrong-order strokes, random scribbles\n- Confidence score provides useful gradient (not just binary)\n- Feedback type helps user understand what went wrong\n- Pure function, fully testable, no side effects","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:27.758497796+05:30","created_by":"krot","updated_at":"2026-02-04T19:19:03.560578804+05:30","closed_at":"2026-02-04T19:19:03.560578804+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.3.2","depends_on_id":"KanjiReader-e8c.3","type":"parent-child","created_at":"2026-02-04T18:55:27.759833237+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.3.2","depends_on_id":"KanjiReader-e8c.1.3","type":"blocks","created_at":"2026-02-04T18:58:30.593187116+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.3.2","depends_on_id":"KanjiReader-e8c.3.1","type":"blocks","created_at":"2026-02-04T18:58:30.665600673+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.3.3","title":"Visual Feedback System","description":"## What\nVisual indicators that show the user whether their stroke was correct or incorrect. Green for correct, red flash for wrong.\n\n## Why\nImmediate feedback is essential for learning. The user needs to know within milliseconds whether their stroke was right. Delayed or ambiguous feedback breaks the learning loop.\n\n## Implementation\n- **Correct stroke:** User's drawn stroke is replaced with the clean reference stroke path rendered in green. Smooth transition (fade/morph) from user's rough polyline to clean path.\n- **Wrong stroke:** User's stroke flashes red briefly (~500ms), then fades out/clears. The canvas returns to its previous state, ready for retry.\n- **Completion:** When all strokes are done, brief celebration animation (subtle — maybe a green checkmark or the full character pulses)\n\n## UX Subtlety\nThe transition from user's rough stroke to the clean reference stroke on success serves two purposes:\n1. Confirms correctness\n2. Shows the 'ideal' version — teaching by example even during practice\n\n## Acceptance Criteria\n- Correct strokes clearly indicated (green, smooth transition)\n- Wrong strokes clearly indicated (red flash, auto-clear)\n- Completion state clearly shown\n- Animations are subtle and fast (don't slow down the practice flow)\n- No visual artifacts or flickering","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:27.807291463+05:30","created_by":"krot","updated_at":"2026-02-04T19:19:45.650128266+05:30","closed_at":"2026-02-04T19:19:45.650128266+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.3.3","depends_on_id":"KanjiReader-e8c.3","type":"parent-child","created_at":"2026-02-04T18:55:27.808773169+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.3.3","depends_on_id":"KanjiReader-e8c.3.2","type":"blocks","created_at":"2026-02-04T18:58:30.739697692+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.3.4","title":"Stroke Lifecycle Management","description":"## What\nOrchestration logic that manages the flow through strokes: tracking which stroke is expected next, handling validation results, advancing state, and managing retries and the clear-canvas action.\n\n## Why\nIndividual components (DrawingCanvas, StrokeValidation, VisualFeedback) handle their own concerns. This task wires them together into a coherent state machine.\n\n## State Machine\n```\nIDLE (no strokes drawn)\n  → user draws → VALIDATING\n    → valid → ADVANCE (show green, increment expected stroke)\n      → more strokes remaining → IDLE (next stroke)\n      → all strokes done → COMPLETE\n    → invalid → FEEDBACK (show red flash)\n      → auto-clear → IDLE (same stroke, retry)\n\nCOMPLETE → update CharacterProgress → show completion UI\n\nCLEAR_CANVAS (user action) → reset to IDLE at stroke 0\n```\n\n## Implementation\n- Expected stroke index: tracks which reference stroke we're comparing against\n- Validated strokes array: accumulates correct strokes for display\n- On validation success: push to validated array, increment index\n- On validation failure: show feedback, keep index the same\n- On clear: reset both arrays and index\n- On complete: call practiceStore.updateProgress(character, true, hintWasUsed)\n\n## Acceptance Criteria\n- Correct stroke flow: draw → validate → advance or retry\n- State never gets stuck or desynchronized\n- Clear canvas resets everything cleanly\n- Completion triggers progress update\n- Handles rapid input without race conditions","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:27.857522001+05:30","created_by":"krot","updated_at":"2026-02-04T19:20:28.441015779+05:30","closed_at":"2026-02-04T19:20:28.441015779+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.3.4","depends_on_id":"KanjiReader-e8c.3","type":"parent-child","created_at":"2026-02-04T18:55:27.858779184+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.3.4","depends_on_id":"KanjiReader-e8c.3.3","type":"blocks","created_at":"2026-02-04T18:58:30.807663139+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.4","title":"Progressive Hint System","description":"## Purpose\nBridges the gap between 'I have no idea' and 'let me watch the full guide.' Instead of immediately showing the answer, hints escalate progressively — giving the user's memory a chance to recall before revealing more.\n\n## Philosophy (Critical — This Is the Pedagogical Core)\nReal-world kanji writing doesn't come with hints. When you're filling out a form in Japanese, nobody tells you the stroke count. The goal is to build RECALL — the ability to write from memory. Hints are a learning scaffold, not a permanent crutch.\n\nThe escalation mirrors good teaching:\n1. 'How many strokes?' — a gentle nudge that might be enough\n2. 'Here's how it starts' — seeing the first stroke often triggers recall of the rest\n3. 'Let me show you the whole thing' — full demonstration, then try again\n\n## UX Flow\n- During Practice Mode, a Hint button is available (but not prominent)\n- Tap 1: Shows stroke count (e.g., '8 strokes')\n- Tap 2: Shows first stroke as a ghost overlay on the canvas\n- Tap 3: Prompts user to switch to Learn Mode for the full guide\n- After Learn Mode review, user switches back to Practice and retries\n\n## Tracking\n- Hint usage is tracked per character in CharacterProgress\n- Future SRS system will use hint data: characters needing hints get shorter review intervals\n- This is why we track it from day one even though SRS isn't implemented yet","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:52:53.326646544+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.644966715+05:30","closed_at":"2026-02-04T19:58:10.644966715+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.4","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:52:53.32774863+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.4.1","title":"HintButton Component","description":"## What\nA button component that manages the progressive hint state. Each tap reveals the next level of help. Visually subtle — present but not prominent, because the goal is for users to NOT need it.\n\n## Implementation\nFile: src/components/writing/HintButton.tsx\n\nProps:\n```typescript\ninterface HintButtonProps {\n  strokeData: StrokeData;\n  currentHintLevel: number;   // 0 = no hints, 1-3 = progressive\n  onHintUsed: (level: number) =\u003e void;\n  onSwitchToLearn: () =\u003e void; // callback for level 3\n}\n```\n\nBehavior:\n- Renders as a small '?' or lightbulb icon\n- Tap increments hint level, triggers onHintUsed callback\n- Parent component responds to hint level to show/hide hint UI\n- At level 3, triggers onSwitchToLearn instead of further increment\n\n## Visual Design\n- Small, placed in the bottom-right or as part of the action bar\n- NOT a prominent CTA — this is a fallback, not a feature to promote\n- Badge or indicator showing current hint level after first use\n- Disabled during Learn Mode (hints only make sense during Practice)\n\n## Acceptance Criteria\n- Taps cycle through hint levels 1 → 2 → 3\n- Level 3 triggers learn mode switch callback\n- Callback fires on each level change (for tracking)\n- Button is not visually prominent\n- Disabled/hidden when not in Practice Mode","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:58.102126441+05:30","created_by":"krot","updated_at":"2026-02-04T19:21:10.763434072+05:30","closed_at":"2026-02-04T19:21:10.763434072+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.4.1","depends_on_id":"KanjiReader-e8c.4","type":"parent-child","created_at":"2026-02-04T18:55:58.103341104+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.4.1","depends_on_id":"KanjiReader-e8c.3.1","type":"blocks","created_at":"2026-02-04T18:58:30.886081368+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.4.1","depends_on_id":"KanjiReader-e8c.3.2","type":"blocks","created_at":"2026-02-04T18:58:30.952287769+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.4.2","title":"Hint Level Implementation","description":"## What\nImplement the three progressive hint levels that reveal information in the Practice Mode canvas.\n\n## Hint Levels\n\n### Level 1: Stroke Count\nDisplay the total number of strokes for the character. Shown as a small text badge near the canvas edge (e.g., '8 strokes').\n\nWhy this helps: Knowing the stroke count gives structural information without revealing the actual strokes. For a character with 3 strokes vs 12, your approach is very different. This is often enough to trigger memory recall.\n\n### Level 2: First Stroke Ghost\nOverlay the first stroke of the reference character as a semi-transparent ghost on the canvas. The user can see where to start and the first stroke's direction.\n\nWhy this helps: The first stroke is the 'anchor' — once you see it, the rest often follows from muscle memory. This is like seeing the first letter of a word you've forgotten — it triggers the rest.\n\n### Level 3: Learn Mode Prompt\nDisplay a message: 'Need more help? Switch to Learn Mode to see all strokes.' with a button to switch.\n\nWhy this works: Rather than revealing all strokes on the Practice canvas (which defeats the purpose), we redirect to the dedicated Learn Mode where the full guide lives. After reviewing, the user switches back to Practice and retries.\n\n## Implementation\n- Level 1: Render Text component with strokeData.strokeCount\n- Level 2: Render the first stroke from strokeData.strokes[0] as a semi-transparent (opacity ~0.3) SVG Path\n- Level 3: Render a prompt UI with switch-to-learn CTA\n\n## Acceptance Criteria\n- Each level reveals exactly the specified information\n- Level 2 ghost stroke is clearly distinguishable from user-drawn strokes (opacity/color)\n- Level 3 prompt navigates to Learn Mode when tapped\n- Levels are additive — level 2 still shows the stroke count from level 1","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:58.167243596+05:30","created_by":"krot","updated_at":"2026-02-04T19:22:01.751294806+05:30","closed_at":"2026-02-04T19:22:01.751294806+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.4.2","depends_on_id":"KanjiReader-e8c.4","type":"parent-child","created_at":"2026-02-04T18:55:58.168542899+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.4.2","depends_on_id":"KanjiReader-e8c.4.1","type":"blocks","created_at":"2026-02-04T18:58:31.013675239+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.4.3","title":"Hint Usage Tracking","description":"## What\nTrack when hints are used per character, stored in CharacterProgress. This data is captured for future SRS weighting.\n\n## Why\nCharacters where the user needs hints are characters they haven't memorized yet. When SRS is implemented, hint-heavy characters should have shorter review intervals (more frequent practice). Capturing this data now means we don't lose history when SRS is added later.\n\n## Implementation\n- When any hint level is triggered, call practiceStore.updateProgress with hintUsed=true\n- CharacterProgress.hintsUsed increments (total count across all attempts)\n- When practice completes, the completion call also records whether hints were used in this session\n- Future: SRS algorithm reads hintsUsed and attempts to compute an ease factor\n\n## Data Impact\n- Adds hintsUsed field to CharacterProgress (already in schema design)\n- No additional storage overhead (just an integer per character)\n\n## Acceptance Criteria\n- Hint usage correctly increments in CharacterProgress\n- Data persists across app restarts\n- Hints used during a failed attempt are still tracked (learning is learning, even if incomplete)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:55:58.227568044+05:30","created_by":"krot","updated_at":"2026-02-04T19:22:24.517807159+05:30","closed_at":"2026-02-04T19:22:24.517807159+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.4.3","depends_on_id":"KanjiReader-e8c.4","type":"parent-child","created_at":"2026-02-04T18:55:58.229425741+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.4.3","depends_on_id":"KanjiReader-e8c.4.2","type":"blocks","created_at":"2026-02-04T18:58:31.086081242+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.4.3","depends_on_id":"KanjiReader-e8c.1.4","type":"blocks","created_at":"2026-02-04T18:58:31.145487989+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.5","title":"Writing Practice Screen","description":"## Purpose\nThe main screen that hosts Learn Mode, Practice Mode, and the mode toggle. This is the container — it composes the child components and manages the state transitions between modes.\n\n## UX Flow\n- Screen receives character data (character, type, reading, meaning) via navigation params\n- Displays character info header at top (what you're practicing)\n- Learn/Practice toggle controls which mode is visible (mutually exclusive)\n- 'Add to Practice List' button saves the word for future practice\n- Accepts characters[] array param — v1 uses single element, future supports sequential multi-char writing\n\n## Architecture Note: characters[] Array\nThe screen is designed to accept an array of characters even though v1 only passes one. This is intentional forward-planning:\n- V1: User taps '食' from word popup → screen receives ['食']\n- Future: User taps '食べる' → screen receives ['食', 'べ', 'る'] and shows a stepper\n- No screen refactoring needed — just add the stepper UI later\n\n## Layout\n- Top: Character info (character, reading, meaning, type badge)\n- Middle: Learn/Practice toggle (segmented control or tab)\n- Center: Active mode content (StrokeGuide or DrawingCanvas)\n- Bottom: Actions (Add to Practice List, hint button during Practice)","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:53:04.281596214+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.651659869+05:30","closed_at":"2026-02-04T19:58:10.651659869+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.5","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:53:04.282657393+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.5.1","title":"Screen Layout with Learn/Practice Toggle","description":"## What\nMain screen component that hosts Learn Mode and Practice Mode as mutually exclusive views, controlled by a toggle.\n\n## Implementation\nFile: src/screens/WritingPracticeScreen.tsx\n\nNavigation params:\n```typescript\ntype WritingPracticeParams = {\n  characters: string[];    // v1: single element, future: multi-char\n  reading: string;\n  meaning: string;\n  source: 'popup' | 'practiceList';\n}\n```\n\nLayout structure:\n- Screen loads stroke data for the first character via strokeDataService\n- Top section: Character info header\n- Toggle: Segmented control or tab bar (Learn | Practice)\n- Content area: conditionally renders StrokeGuide OR DrawingCanvas\n- Bottom action bar: Hint button (Practice only), Add to Practice List\n\nState management:\n- activeMode: 'learn' | 'practice'\n- Switching to Learn clears any in-progress practice drawing\n- Switching to Practice resets hint level to 0\n\n## Architecture: characters[] Array\nThe screen accepts an array even though v1 always passes a single element. This is the forward-planning hook:\n- V1: characters=['食'], render practice for that one character\n- Future: characters=['食','べ','る'], add a stepper/progress bar showing which character you're on\n\nNo stepper UI needed now — just accept the array and use characters[0].\n\n## Acceptance Criteria\n- Toggle switches between Learn and Practice cleanly\n- Mode switch clears in-progress state appropriately\n- Screen loads stroke data on mount\n- Loading and error states handled (spinner while loading, message if data unavailable)\n- Works for kanji, hiragana, and katakana characters","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:56:32.922309278+05:30","created_by":"krot","updated_at":"2026-02-04T19:24:08.546993775+05:30","closed_at":"2026-02-04T19:24:08.546993775+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.5.1","depends_on_id":"KanjiReader-e8c.5","type":"parent-child","created_at":"2026-02-04T18:56:32.923910171+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.1","depends_on_id":"KanjiReader-e8c.2.1","type":"blocks","created_at":"2026-02-04T18:58:31.210656629+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.1","depends_on_id":"KanjiReader-e8c.3.1","type":"blocks","created_at":"2026-02-04T18:58:31.293498142+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.1","depends_on_id":"KanjiReader-e8c.1.3","type":"blocks","created_at":"2026-02-04T18:58:31.367342856+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.5.2","title":"Character Info Header","description":"## What\nHeader component displaying the character being practiced, its type (kanji/hiragana/katakana), reading, and meaning.\n\n## Why\nContext matters during practice. The user should always know WHAT they're practicing and what it means. The header anchors the practice session.\n\n## Implementation\nFile: src/components/writing/CharacterInfoHeader.tsx\n\nDisplay:\n- Large character display (e.g., 食)\n- Type badge (e.g., 'Kanji' in a colored chip)\n- Reading in hiragana (e.g., た.べる)\n- English meaning (e.g., 'to eat')\n\n## Design Consideration\nThe character display serves double duty:\n- In Learn Mode: reference for what you're learning\n- In Practice Mode: the 'prompt' — this is what you need to write from memory\n- Should be large enough to see clearly but not so large it dominates the screen\n\n## Acceptance Criteria\n- Shows character, type badge, reading, and meaning\n- Type badge color-coded (kanji=blue, hiragana=green, katakana=orange or similar)\n- Responsive layout — works in both portrait and landscape","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:56:32.990025889+05:30","created_by":"krot","updated_at":"2026-02-04T19:24:46.763146547+05:30","closed_at":"2026-02-04T19:24:46.763146547+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.5.2","depends_on_id":"KanjiReader-e8c.5","type":"parent-child","created_at":"2026-02-04T18:56:32.99184804+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.2","depends_on_id":"KanjiReader-e8c.5.1","type":"blocks","created_at":"2026-02-04T18:58:31.4410558+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.5.3","title":"Navigation: Word Popup → Practice Screen","description":"## What\nWire up navigation from the existing word detail popup to the new WritingPracticeScreen.\n\n## Why\nThis is the primary entry point for the feature — user scans text, taps a word, sees the popup, taps the practice icon. The navigation must pass all required data cleanly.\n\n## Implementation\n- Add WritingPracticeScreen to the React Navigation stack\n- In the word popup component, the practice icon's onPress navigates to WritingPracticeScreen\n- Pass params: characters (decomposed from the word), reading, meaning, source='popup'\n- Characters decomposition: split the word string into individual characters\n\n## Consideration: Which Character(s) to Practice?\nFor V1, when user taps the practice icon from a word like '食べる':\n- Option A: Practice just the character they tapped on → need to know which char was tapped\n- Option B: Practice the first kanji in the word → simpler\n- Option C: Navigate with all characters, let user pick on the practice screen\n\nRecommendation: Option C (pass all characters, screen handles selection). This is the most flexible and aligns with the characters[] architecture.\n\n## Acceptance Criteria\n- Practice icon in popup navigates to WritingPracticeScreen\n- All required params passed correctly\n- Back navigation returns to the popup/results screen\n- No navigation stack issues (double-push, stale state)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:56:33.043580166+05:30","created_by":"krot","updated_at":"2026-02-04T19:26:24.29414816+05:30","closed_at":"2026-02-04T19:26:24.29414816+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.5.3","depends_on_id":"KanjiReader-e8c.5","type":"parent-child","created_at":"2026-02-04T18:56:33.04502272+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.3","depends_on_id":"KanjiReader-e8c.5.1","type":"blocks","created_at":"2026-02-04T18:58:31.517520857+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.5.4","title":"Add to Practice List Action","description":"## What\nButton on WritingPracticeScreen that saves the current word to the practice list.\n\n## Implementation\n- Button in the bottom action bar: 'Add to Practice List'\n- On tap: call practiceStore.addWord({ word, characters, reading, meaning, source })\n- Show confirmation toast/snackbar\n- If word already exists in list: show 'Already in your practice list' instead\n- Button state: changes to 'Added ✓' after saving (prevents double-add in same session)\n\n## Why Source Tracking Matters\nRecording source='scan' tells us this word came from real-world text scanning. Future analytics could show: 'You've scanned 200 unique words from real Japanese text!' — motivating for learners.\n\n## Acceptance Criteria\n- Word saved to practice store on tap\n- Duplicate prevention (same word string)\n- Visual confirmation of save\n- Button state reflects whether word is already saved","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:56:33.109266524+05:30","created_by":"krot","updated_at":"2026-02-04T19:26:24.498862516+05:30","closed_at":"2026-02-04T19:26:24.498862516+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.5.4","depends_on_id":"KanjiReader-e8c.5","type":"parent-child","created_at":"2026-02-04T18:56:33.117527254+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.4","depends_on_id":"KanjiReader-e8c.5.1","type":"blocks","created_at":"2026-02-04T18:58:31.589347866+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.5.4","depends_on_id":"KanjiReader-e8c.1.4","type":"blocks","created_at":"2026-02-04T18:58:31.663782725+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.6","title":"Practice Word List","description":"## Purpose\nPersistent list of words the user has saved for practice. This is what makes the feature sticky — users don't need to re-scan text every time they want to practice writing. They build a personal vocabulary list over time.\n\n## UX Flow\n- Accessible from main app navigation (tab or menu item) — always one tap away\n- Shows all saved words with kanji, reading, and meaning\n- Tapping a word navigates to WritingPracticeScreen for that word\n- Swipe-to-delete or edit mode for managing the list\n- Source tracking: each word knows if it came from a scan or was added manually (future: manual add screen)\n\n## Scale Considerations\n- At maximum, a user might save all ~5,000 kanji + associated words\n- Even at that scale, the list is \u003c1MB in AsyncStorage\n- No pagination needed — FlatList with virtualization handles it\n- No server sync needed — local-only storage is sufficient for a single user\n\n## Future Extensions (Architected For, Not Built)\n- SRS-based review scheduling (which word to practice next)\n- Progress indicators per word (how well do you know each character)\n- Manual word addition (type a word without scanning)\n- Export/import practice list","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:53:15.490690257+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:05.267889439+05:30","closed_at":"2026-02-04T19:42:05.267889439+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.6","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:53:15.491840934+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.6.1","title":"PracticeListScreen","description":"## What\nScreen that displays all saved practice words as a scrollable list.\n\n## Implementation\nFile: src/screens/PracticeListScreen.tsx\n\n- FlatList (virtualized) rendering practice words from practiceStore\n- Each row shows: kanji characters, reading (hiragana), meaning (english)\n- Tap a row → navigate to WritingPracticeScreen for that word\n- Empty state: illustration/message ('Scan text and add words to start practicing!')\n\n## Grouping / Organization (V1: Simple)\nFor V1, just a flat chronological list (most recently added first).\nFuture options (architected for but not built):\n- Group by character type (kanji/hiragana/katakana sections)\n- Sort by mastery (least practiced first — useful for SRS)\n- Search/filter\n\nThe store schema supports all these future groupings because we store character type and progress data.\n\n## Performance\nEven at max scale (~5,000 words), FlatList with virtualization handles this easily. No pagination or lazy loading needed for the list itself.\n\n## Acceptance Criteria\n- Displays all saved practice words\n- Tapping a word navigates to practice screen with correct data\n- Empty state shown when no words saved\n- List scrolls smoothly even with hundreds of items","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:02.573050313+05:30","created_by":"krot","updated_at":"2026-02-04T19:27:45.248289386+05:30","closed_at":"2026-02-04T19:27:45.248289386+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.6.1","depends_on_id":"KanjiReader-e8c.6","type":"parent-child","created_at":"2026-02-04T18:57:02.574720768+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.6.1","depends_on_id":"KanjiReader-e8c.1.4","type":"blocks","created_at":"2026-02-04T18:58:31.747407529+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.6.2","title":"Word Management (Delete/Edit)","description":"## What\nAllow users to remove words from their practice list. Keep it simple — swipe-to-delete or a delete button per row.\n\n## Why\nUsers need to manage their list. Maybe they added a word by mistake, or they've fully mastered it and want to declutter. Without delete, the list only grows.\n\n## Implementation\nOptions (pick one):\n- **Swipe-to-delete:** react-native-gesture-handler Swipeable component. Swipe left reveals red delete button.\n- **Edit mode:** Toggle that shows delete (−) icons on each row, iOS-style.\n\nRecommendation: Swipe-to-delete for V1 — simpler, no mode management.\n\n- Confirm before delete? For V1, skip confirmation (low stakes, words can be re-added). Future: undo toast.\n- Deleting a word does NOT delete its CharacterProgress — progress is per-character, not per-word.\n\n## Acceptance Criteria\n- User can delete any word from the list\n- Deletion removes from store and updates UI immediately\n- CharacterProgress for the word's characters is preserved\n- Smooth animation on delete","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:02.674298888+05:30","created_by":"krot","updated_at":"2026-02-04T19:27:59.831054907+05:30","closed_at":"2026-02-04T19:27:59.831054907+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.6.2","depends_on_id":"KanjiReader-e8c.6","type":"parent-child","created_at":"2026-02-04T18:57:02.676568455+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.6.2","depends_on_id":"KanjiReader-e8c.6.1","type":"blocks","created_at":"2026-02-04T18:58:31.84243948+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.6.3","title":"Main Navigation Entry Point","description":"## What\nAdd PracticeListScreen to the main app navigation so users can access their practice list without going through the scan flow.\n\n## Why\nThe whole point of the practice list is that users can practice anytime without re-scanning. If the list is only reachable through scan → popup → ..., it defeats the purpose. It needs to be a first-class navigation destination.\n\n## Implementation\n- Add to the main tab bar / drawer navigation (depends on current app nav structure)\n- Icon: pencil/writing icon (✏️ or similar)\n- Label: 'Practice' or 'Writing'\n- Position: after the main Scan tab\n\n## Consideration\nThis elevates writing practice to a top-level feature alongside scanning. It signals to the user that the app is not just for reading — it's for writing too. The navigation structure reflects the product direction.\n\n## Acceptance Criteria\n- Practice List accessible from main navigation in one tap\n- Navigation icon and label are clear\n- Active tab indicator works correctly\n- Deep linking considerations: can we navigate directly to a practice word? (future, not required for v1)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:02.757283682+05:30","created_by":"krot","updated_at":"2026-02-04T19:40:37.466798037+05:30","closed_at":"2026-02-04T19:40:37.466798037+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.6.3","depends_on_id":"KanjiReader-e8c.6","type":"parent-child","created_at":"2026-02-04T18:57:02.759180826+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.6.3","depends_on_id":"KanjiReader-e8c.6.1","type":"blocks","created_at":"2026-02-04T18:58:31.936287122+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.6.4","title":"Navigation: Practice List → Practice Screen","description":"## What\nWire up navigation from tapping a word in the Practice List to WritingPracticeScreen.\n\n## Implementation\n- On row tap in PracticeListScreen: navigate to WritingPracticeScreen\n- Pass params: characters (from PracticeWord.characters), reading, meaning, source='practiceList'\n- Back navigation returns to PracticeListScreen\n\n## Note\nThis reuses the SAME WritingPracticeScreen that the word popup navigates to. The screen doesn't need to know where the user came from — it just receives character data and renders.\n\n## Acceptance Criteria\n- Tapping a practice list word opens the practice screen\n- Correct data passed\n- Back navigation returns to list, not to scan screen","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:02.851672058+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:01.437919466+05:30","closed_at":"2026-02-04T19:42:01.437919466+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.6.4","depends_on_id":"KanjiReader-e8c.6","type":"parent-child","created_at":"2026-02-04T18:57:02.861410043+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.6.4","depends_on_id":"KanjiReader-e8c.6.1","type":"blocks","created_at":"2026-02-04T18:58:32.02034251+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.6.4","depends_on_id":"KanjiReader-e8c.5.1","type":"blocks","created_at":"2026-02-04T18:58:32.095332219+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.7","title":"Integration \u0026 Edge Cases","description":"## Purpose\nWire everything together: modify the existing word popup to include the practice icon, configure React Navigation for the new screens, and handle edge cases gracefully.\n\n## Why This Is Separate\nThe core components (Learn Mode, Practice Mode, Hint System, Word List) are built independently. This feature is the glue — it connects them to the existing app and handles the cases where things go wrong.\n\n## Key Integration Points\n1. **Word popup** — existing component in the OCR results view. Needs a new practice writing icon that triggers navigation to WritingPracticeScreen. Must pass character data correctly.\n2. **React Navigation** — new screens (WritingPracticeScreen, PracticeListScreen) need to be registered. Practice List needs a main navigation entry point.\n3. **Progress tracking** — CharacterProgress updates must fire on practice completion/failure.\n\n## Edge Cases to Handle\n- Kanji not in KanjiVG: gracefully show 'stroke data unavailable', disable practice for that char\n- Network failure during on-demand fetch: show error, suggest trying later, don't crash\n- Character already in practice list: prevent duplicates, show 'already saved'\n- Empty practice list: show empty state with guidance ('Scan text and add words to practice')","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:53:26.225702075+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:05.31229773+05:30","closed_at":"2026-02-04T19:42:05.31229773+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.7","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:53:26.22680306+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.7.1","title":"Word Popup Practice Icon","description":"## What\nAdd a practice writing icon to the existing word detail popup component. This is the user's first touchpoint with the writing practice feature.\n\n## Implementation\n- Locate the existing word popup component (in src/components/ — the one that shows when user taps a word in OCR results)\n- Add a new icon button: pencil/writing icon\n- Position: alongside existing popup actions (pronunciation, meaning, etc.)\n- onPress: navigate to WritingPracticeScreen with the word's data\n\n## Design Consideration\nThe icon should be discoverable but not dominant. The popup's primary function is still showing pronunciation/meaning. The practice icon is an additional action — like a bookmark icon in a browser tab.\n\n## Acceptance Criteria\n- Icon visible in the word popup\n- Tapping icon navigates correctly\n- Icon visually consistent with existing popup actions\n- Does not break existing popup functionality","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:24.769028377+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:01.481114231+05:30","closed_at":"2026-02-04T19:42:01.481114231+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.7.1","depends_on_id":"KanjiReader-e8c.7","type":"parent-child","created_at":"2026-02-04T18:57:24.770951521+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.7.1","depends_on_id":"KanjiReader-e8c.5.3","type":"blocks","created_at":"2026-02-04T18:58:32.164297268+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.7.2","title":"React Navigation Configuration","description":"## What\nRegister all new screens in the React Navigation configuration and set up the navigation graph.\n\n## Implementation\nNew screens to register:\n1. WritingPracticeScreen — in the main stack (accessible from both popup and practice list)\n2. PracticeListScreen — in the main tab/drawer navigator\n\nNavigation type params to define:\n```typescript\ntype RootStackParamList = {\n  // ... existing screens\n  WritingPractice: WritingPracticeParams;\n  PracticeList: undefined;\n}\n```\n\n## Navigation Architecture\n- WritingPracticeScreen is a stack screen (pushed on top of current view)\n- PracticeListScreen is a tab/drawer destination (top-level navigation)\n- Both can navigate TO WritingPracticeScreen, but via different stacks — ensure back navigation is correct in both cases\n\n## Acceptance Criteria\n- Both new screens registered and navigable\n- TypeScript navigation params correctly typed\n- Back navigation works correctly from both entry points\n- No navigation stack leaks (screens not cleaned up)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:24.836229603+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:01.52766006+05:30","closed_at":"2026-02-04T19:42:01.52766006+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.7.2","depends_on_id":"KanjiReader-e8c.7","type":"parent-child","created_at":"2026-02-04T18:57:24.837636581+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.7.2","depends_on_id":"KanjiReader-e8c.5.1","type":"blocks","created_at":"2026-02-04T18:58:32.250674868+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.7.2","depends_on_id":"KanjiReader-e8c.6.1","type":"blocks","created_at":"2026-02-04T18:58:32.315338855+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.7.3","title":"Edge Case Handling","description":"## What\nHandle all the 'what if' scenarios gracefully so the app never crashes or leaves the user confused.\n\n## Edge Cases\n\n### Missing Stroke Data\n- Character not in KanjiVG (rare kanji, unusual characters)\n- Network failure during on-demand fetch\n- Handling: Show 'Stroke data unavailable for this character' message, disable practice for that specific character, don't crash, don't show broken UI\n\n### Duplicate Words\n- User adds a word that's already in their practice list\n- Handling: Prevent duplicate, show 'Already in your practice list'\n\n### Empty States\n- Practice list is empty (new user or all words deleted)\n- Handling: Show friendly empty state with CTA ('Scan some text to get started!')\n\n### Character Progress Edge Cases\n- Character exists in multiple words (e.g., '食' in '食べる' and '食事')\n- Handling: Already handled by architecture — CharacterProgress is per-character, shared across words\n\n### Performance\n- Very complex kanji with 20+ strokes\n- Handling: Should work fine with SVG rendering, but worth testing. If perf issues, limit animation complexity.\n\n## Acceptance Criteria\n- App never crashes on missing data\n- User always sees a meaningful message when something is unavailable\n- Duplicate prevention works\n- Empty states are friendly and actionable","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:57:24.907962811+05:30","created_by":"krot","updated_at":"2026-02-04T19:42:01.569343118+05:30","closed_at":"2026-02-04T19:42:01.569343118+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.7.3","depends_on_id":"KanjiReader-e8c.7","type":"parent-child","created_at":"2026-02-04T18:57:24.909129485+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.7.3","depends_on_id":"KanjiReader-e8c.1.3","type":"blocks","created_at":"2026-02-04T18:58:32.387739049+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.7.3","depends_on_id":"KanjiReader-e8c.1.4","type":"blocks","created_at":"2026-02-04T18:58:32.450489307+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8","title":"Testing","description":"## Purpose\nComprehensive test coverage for the writing practice feature. Tests validate correctness of the core algorithms (stroke validation, character type detection), data persistence (practice store), and the full user flow.\n\n## Testing Strategy\n- **Unit tests** for pure logic: stroke validation algorithm, character type detection, store operations\n- **Component tests** for interactive UI: DrawingCanvas touch handling, StrokeGuide rendering\n- **Integration test** for the full flow: scan → popup → practice → save → practice list → re-practice\n\n## Why These Specific Tests Matter\n- Stroke validation is the heart of Practice Mode. If it's too strict, users get frustrated. If it's too lenient, they don't learn. Unit tests pin down the tolerance behavior.\n- Practice store persistence is critical — losing a user's practice list would be terrible UX. Tests verify AsyncStorage round-trips.\n- Character type detection seems trivial (Unicode ranges) but edge cases exist (rare kanji, extended katakana). Tests catch these.\n- The full flow integration test catches wiring bugs that unit tests miss.","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:53:34.999176435+05:30","created_by":"krot","updated_at":"2026-02-04T19:58:10.658493188+05:30","closed_at":"2026-02-04T19:58:10.658493188+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8","depends_on_id":"KanjiReader-e8c","type":"parent-child","created_at":"2026-02-04T18:53:35.000610888+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8.1","title":"Stroke Validation Unit Tests","description":"## What\nUnit tests for the stroke validation algorithm — the most critical pure logic in the feature.\n\n## Why This Is the Highest Priority Test\nIf stroke validation is wrong, the entire Practice Mode is broken. Too strict = frustrating. Too lenient = no learning. These tests pin down the behavior.\n\n## Test Cases\n- Correct stroke (matching direction, start, end) → isValid=true\n- Reversed stroke (drawn right-to-left when should be left-to-right) → isValid=false\n- Wrong start position → feedback='wrong_start'\n- Wrong direction → feedback='wrong_direction'\n- Random scribble → isValid=false\n- Stroke at edge of tolerance (just barely passing) → isValid=true with lower confidence\n- Stroke just outside tolerance → isValid=false\n- Curved strokes (hooks, turns) → tests with realistic kanji stroke shapes\n- Very short stroke (dot) → should work for kanji radicals that are dots\n- Very long stroke → should work for sweeping strokes\n\n## Implementation\nFile: src/utils/__tests__/strokeValidation.test.ts\nUse Jest. Create mock stroke data for predictable testing.\n\n## Acceptance Criteria\n- All test cases pass\n- Coverage: \u003e90% of validateStroke function\n- Edge cases for tolerance boundaries tested\n- Tests are readable and serve as documentation for the algorithm","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:58:01.539095483+05:30","created_by":"krot","updated_at":"2026-02-04T19:43:11.832403335+05:30","closed_at":"2026-02-04T19:43:11.832403335+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8.1","depends_on_id":"KanjiReader-e8c.8","type":"parent-child","created_at":"2026-02-04T18:58:01.54025264+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.1","depends_on_id":"KanjiReader-e8c.3.2","type":"blocks","created_at":"2026-02-04T18:58:32.535959892+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8.2","title":"Practice Store Unit Tests","description":"## What\nUnit tests for the Zustand practice store: word management and progress tracking.\n\n## Test Cases\n\n### Word Management\n- Add a word → appears in store\n- Add duplicate word → rejected, store unchanged\n- Remove a word → removed from store, CharacterProgress preserved\n- Add word from scan → source='scan' recorded\n- Word decomposition → characters array correctly split\n\n### Progress Tracking\n- First practice attempt → CharacterProgress created with attempts=1\n- Successful practice → successes incremented\n- Failed practice → attempts incremented but not successes\n- Hint used → hintsUsed incremented\n- Same character in different words → shared progress\n- Progress survives simulated app restart (AsyncStorage mock)\n\n### Store Hydration\n- Store loads correctly from AsyncStorage on init\n- Corrupt/missing AsyncStorage data → store initializes with defaults\n\n## Implementation\nFile: src/stores/__tests__/practiceStore.test.ts\nMock AsyncStorage for persistence tests.\n\n## Acceptance Criteria\n- All CRUD operations tested\n- Progress tracking edge cases covered\n- Persistence round-trip verified\n- No flaky tests (deterministic, no timing dependencies)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:58:01.609031862+05:30","created_by":"krot","updated_at":"2026-02-04T19:44:11.798908673+05:30","closed_at":"2026-02-04T19:44:11.798908673+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8.2","depends_on_id":"KanjiReader-e8c.8","type":"parent-child","created_at":"2026-02-04T18:58:01.610981297+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.2","depends_on_id":"KanjiReader-e8c.1.4","type":"blocks","created_at":"2026-02-04T18:58:32.605378128+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8.3","title":"Character Type Detection Tests","description":"## What\nUnit tests for the character type detection utility.\n\n## Test Cases\n- Standard hiragana (あ, い, う, ん) → 'hiragana'\n- Standard katakana (ア, イ, ウ, ン) → 'katakana'\n- Common kanji (食, 日, 本, 語) → 'kanji'\n- Rare kanji (CJK Extension A) → 'kanji'\n- Halfwidth katakana → 'katakana'\n- Latin characters (a, B, 1) → 'unknown'\n- Emoji → 'unknown'\n- Empty string → handled gracefully\n\n## Implementation\nFile: src/utils/__tests__/characterType.test.ts\n\n## Acceptance Criteria\n- All Unicode ranges correctly classified\n- Edge cases for range boundaries tested\n- Unknown characters handled without error","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:58:01.671988709+05:30","created_by":"krot","updated_at":"2026-02-04T19:46:57.90166983+05:30","closed_at":"2026-02-04T19:46:57.90166983+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8.3","depends_on_id":"KanjiReader-e8c.8","type":"parent-child","created_at":"2026-02-04T18:58:01.674224956+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.3","depends_on_id":"KanjiReader-e8c.1.2","type":"blocks","created_at":"2026-02-04T18:58:32.682732919+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8.4","title":"DrawingCanvas Component Tests","description":"## What\nComponent tests for the DrawingCanvas — verifying touch input creates paths and stroke completion callback fires.\n\n## Test Cases\n- Touch start + move + end → onStrokeComplete called with point array\n- Multiple sequential strokes → each triggers separate onStrokeComplete\n- Previously validated strokes rendered correctly\n- Disabled state → touches ignored\n- Rapid touch input → no race conditions or missed points\n\n## Implementation\nFile: src/components/writing/__tests__/DrawingCanvas.test.tsx\nUse React Native Testing Library. May need to mock gesture handler events.\n\n## Note on Complexity\nTesting touch-based drawing is inherently harder than testing pure functions. Focus on:\n1. Callback contract (onStrokeComplete fires with correct data)\n2. Rendering (validated strokes visible, canvas clears properly)\n3. State management (disabled prop respected)\n\nDon't try to visually verify stroke rendering in tests — that's what manual QA is for.\n\n## Acceptance Criteria\n- Touch lifecycle correctly triggers callbacks\n- Props (currentStrokes, disabled) affect behavior correctly\n- No test flakiness from gesture handler mocking","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:58:01.742457495+05:30","created_by":"krot","updated_at":"2026-02-04T19:53:04.94716557+05:30","closed_at":"2026-02-04T19:53:04.94716557+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8.4","depends_on_id":"KanjiReader-e8c.8","type":"parent-child","created_at":"2026-02-04T18:58:01.744257056+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.4","depends_on_id":"KanjiReader-e8c.3.1","type":"blocks","created_at":"2026-02-04T18:58:32.768250553+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.8.5","title":"Integration Test: Full Flow","description":"## What\nEnd-to-end integration test covering the full user journey: scan result → word popup → practice icon → practice screen → practice character → save to list → view list → re-practice.\n\n## Why\nUnit tests verify individual pieces. This test verifies they all wire together correctly. Integration bugs (wrong navigation params, missing store connections, broken data flow) only surface here.\n\n## Test Flow\n1. Render word popup with test data\n2. Tap practice icon → verify WritingPracticeScreen rendered\n3. Verify character info header shows correct data\n4. Toggle to Learn Mode → verify StrokeGuide rendered\n5. Toggle to Practice Mode → verify DrawingCanvas rendered\n6. Simulate stroke completion → verify progress updated\n7. Tap 'Add to Practice List' → verify word in store\n8. Navigate to PracticeListScreen → verify word appears\n9. Tap word in list → verify WritingPracticeScreen re-renders with same data\n\n## Implementation\nFile: src/__tests__/writingPracticeFlow.test.tsx\nUse React Native Testing Library with navigation container setup.\n\n## Practical Note\nThis is a complex test. It may need mock navigation, mock stroke data, and careful async handling. If it becomes too brittle, break into smaller integration tests (popup→screen, screen→store, list→screen).\n\n## Acceptance Criteria\n- Full flow executes without errors\n- Data passes correctly between all components\n- Store state reflects user actions\n- Navigation stack is correct at each step","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T18:58:01.81284663+05:30","created_by":"krot","updated_at":"2026-02-04T19:57:12.196515382+05:30","closed_at":"2026-02-04T19:57:12.196515382+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.8.5","depends_on_id":"KanjiReader-e8c.8","type":"parent-child","created_at":"2026-02-04T18:58:01.814137229+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.5","depends_on_id":"KanjiReader-e8c.7.1","type":"blocks","created_at":"2026-02-04T18:58:32.835020602+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.5","depends_on_id":"KanjiReader-e8c.7.2","type":"blocks","created_at":"2026-02-04T18:58:32.90573575+05:30","created_by":"krot"},{"issue_id":"KanjiReader-e8c.8.5","depends_on_id":"KanjiReader-e8c.6.1","type":"blocks","created_at":"2026-02-04T18:58:32.972393306+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.refine","title":"Kanji Writing Refinements","description":"Improvements to Epic 8c based on user feedback (2026-02-04): Multi-char nav and Auto-save.","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:27:00.233414916+05:30","created_by":"krot","updated_at":"2026-02-04T21:59:22.547851253+05:30","closed_at":"2026-02-04T21:59:22.547851253+05:30","close_reason":"Closed"}
{"id":"KanjiReader-e8c.refine.1","title":"Multi-Character Navigation","description":"Allow cycling through all characters in a scanned word (e.g. Techo -\u003e Te, Cho). Update WritingPracticeScreen to use activeCharIndex and add UI controls.","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:27:00.278046046+05:30","created_by":"krot","updated_at":"2026-02-04T21:59:16.46753841+05:30","closed_at":"2026-02-04T21:59:16.46753841+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.refine.1","depends_on_id":"KanjiReader-e8c.refine","type":"parent-child","created_at":"2026-02-04T20:27:00.27949086+05:30","created_by":"krot"}]}
{"id":"KanjiReader-e8c.refine.2","title":"Auto-Save to Practice List","description":"Remove manual Add button. Automatically save word to practice list on screen mount (idempotent).","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:27:00.324505606+05:30","created_by":"krot","updated_at":"2026-02-04T21:59:11.737723313+05:30","closed_at":"2026-02-04T21:59:11.737723313+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-e8c.refine.2","depends_on_id":"KanjiReader-e8c.refine","type":"parent-child","created_at":"2026-02-04T20:27:00.325507915+05:30","created_by":"krot"}]}
{"id":"KanjiReader-gar","title":"Display the complete English translation of the extracted text.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:23:26.201566657+05:30","created_by":"krot","updated_at":"2026-01-31T19:28:33.728154128+05:30","closed_at":"2026-01-31T19:28:33.728154128+05:30","close_reason":"Closed"}
{"id":"KanjiReader-kke","title":"Add Root Gesture Handler","description":"Wrap App.tsx content in GestureHandlerRootView to prevent crashes with GestureDetector.","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:12:37.980526622+05:30","created_by":"krot","updated_at":"2026-02-04T20:13:16.515564184+05:30","closed_at":"2026-02-04T20:13:16.515564184+05:30","close_reason":"Closed"}
{"id":"KanjiReader-lqc","title":"KanjiReader V2 Enhancements Proposal","description":"This epic represents the full proposal for version 2 enhancements of the KanjiReader application. It aims to address the limitations identified in the MVP and significantly improve the user's learning experience by enhancing contextual understanding, pronunciation, translation, and word interaction. This proposal covers features such as inline English pronunciation, full sentence audio playback, complete English translation display, and interactive word pop-ups. Each child bead will detail specific features and their subtasks, including dependencies and implementation considerations. The overarching goal is to make the KanjiReader a more effective and intuitive tool for learning Japanese.","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:20.804902139+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:44.2008145+05:30","closed_at":"2026-01-31T19:29:44.2008145+05:30","close_reason":"Closed"}
{"id":"KanjiReader-lqc.1","title":"Feature: Enhanced Pronunciation Display","description":"This feature aims to improve the learning experience by providing immediate English pronunciations for Japanese text directly within the display. This addresses the MVP's problem where pronunciation was not readily available, making quick reference difficult and defeating the purpose of the word cards. Inline display helps maintain context while learning pronunciation. Future considerations may include customizable display options (e.g., romaji, hiragana pronunciation).","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:25.88833965+05:30","created_by":"krot","updated_at":"2026-01-31T19:26:20.349305335+05:30","closed_at":"2026-01-31T19:26:20.349305335+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.1","depends_on_id":"KanjiReader-lqc","type":"parent-child","created_at":"2026-01-31T18:53:25.889442687+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.1.1","title":"Subtask: Implement inline pronunciation display logic","description":"This subtask involves the core implementation to modify the UI components to render English pronunciations directly beneath or alongside their corresponding Japanese words/phrases. It will require parsing the Japanese text, potentially using a library to get phonetic readings if not provided by OCR, and integrating this data into the display logic. This is crucial for fixing the MVP's lack of pronunciation context. Reasoning: Direct, inline pronunciation significantly reduces cognitive load compared to tapping cards, addressing user feedback about losing context.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:29.684747379+05:30","created_by":"krot","updated_at":"2026-01-31T19:26:20.26104133+05:30","closed_at":"2026-01-31T19:26:20.26104133+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.1.1","depends_on_id":"KanjiReader-lqc.1","type":"parent-child","created_at":"2026-01-31T18:53:29.68689367+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.1.2","title":"Subtask: Ensure pronunciation alignment and readability","description":"This subtask focuses on the UI/UX aspects of the inline pronunciation. It involves ensuring that the English pronunciations are correctly aligned with their Japanese counterparts, are legible, and do not disrupt the overall text flow. This will require careful CSS/styling adjustments (for web-based or similar UI frameworks) or layout management in React Native. Consideration: Different font sizes or styling might be needed for Japanese and English text to maintain clarity. This is essential for a polished user experience.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:32.546966871+05:30","created_by":"krot","updated_at":"2026-01-31T19:26:20.304896043+05:30","closed_at":"2026-01-31T19:26:20.304896043+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.1.2","depends_on_id":"KanjiReader-lqc.1","type":"parent-child","created_at":"2026-01-31T18:53:32.548058126+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.2","title":"Feature: Full Sentence Audio Playback","description":"This feature addresses the user's need to listen to the entire extracted Japanese text, solving the problem of losing context when only individual words can be pronounced. By providing a speaker button for full sentences, the user can grasp the complete auditory flow and intonation, which is crucial for language learning. This enhances the overall comprehension and learning experience. Consideration: Selection of a high-quality and natural-sounding Japanese TTS service is paramount for effective learning.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:36.449910632+05:30","created_by":"krot","updated_at":"2026-01-31T19:27:22.007616954+05:30","closed_at":"2026-01-31T19:27:22.007616954+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.2","depends_on_id":"KanjiReader-lqc","type":"parent-child","created_at":"2026-01-31T18:53:36.451001456+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.2.1","title":"Subtask: Integrate Japanese TTS service","description":"This subtask involves researching, selecting, and integrating a suitable Japanese Text-to-Speech (TTS) service into the application. The service should provide natural-sounding Japanese pronunciation and ideally support various speaking styles or voices. This is a foundational piece for enabling full sentence audio. Reasoning: A robust TTS integration is critical for accurate pronunciation and an authentic listening experience, directly addressing the user's need to hear the entire text.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:39.821731786+05:30","created_by":"krot","updated_at":"2026-01-31T19:27:21.861408655+05:30","closed_at":"2026-01-31T19:27:21.861408655+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.2.1","depends_on_id":"KanjiReader-lqc.2","type":"parent-child","created_at":"2026-01-31T18:53:39.823005758+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.2.2","title":"Subtask: Develop speaker button UI element","description":"This subtask focuses on designing and implementing the user interface for the speaker button. It should be visually distinct and intuitive, placed strategically at the end of the extracted Japanese text. This includes handling its states (e.g., playing, paused, loading). Consideration: The button should be easily discoverable and aesthetically consistent with the app's overall design. Clear visual feedback during audio playback is important.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:53:42.586985036+05:30","created_by":"krot","updated_at":"2026-01-31T19:27:21.914694333+05:30","closed_at":"2026-01-31T19:27:21.914694333+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.2.2","depends_on_id":"KanjiReader-lqc.2","type":"parent-child","created_at":"2026-01-31T18:53:42.588056152+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.2.3","title":"Subtask: Implement full sentence audio playback functionality","description":"This subtask involves connecting the developed speaker button to the integrated TTS service and implementing the logic to play the entire extracted Japanese sentence. This includes handling playback controls (play/pause), error handling for TTS service failures, and ensuring a smooth user experience. Reasoning: This directly fulfills the user's request for full sentence audio, improving context and listening comprehension. It also completes the core functionality of this feature.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:54:39.094870962+05:30","created_by":"krot","updated_at":"2026-01-31T19:27:21.965308254+05:30","closed_at":"2026-01-31T19:27:21.965308254+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.2.3","depends_on_id":"KanjiReader-lqc.2","type":"parent-child","created_at":"2026-01-31T18:54:39.095990511+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.3","title":"Feature: Full English Translation","description":"This feature aims to provide a complete English translation of the extracted Japanese text, addressing the user's need for comprehensive understanding of the entire sentence/passage. This is vital for learners to fully grasp the meaning and context, especially when individual word translations might be ambiguous or incorrect. It acts as a definitive reference for the learned Japanese text. Consideration: Accuracy and naturalness of the translation service are critical for user trust and effective learning. The UI must clearly differentiate between the original text, pronunciation, and translation.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:54:42.919788443+05:30","created_by":"krot","updated_at":"2026-01-31T19:28:33.671770297+05:30","closed_at":"2026-01-31T19:28:33.671770297+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.3","depends_on_id":"KanjiReader-lqc","type":"parent-child","created_at":"2026-01-31T18:54:42.921656646+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.3.1","title":"Subtask: Integrate Japanese-to-English translation service","description":"This subtask involves selecting and integrating a reliable Japanese-to-English translation service. The service should be capable of translating full sentences and ideally provide contextual translations rather than just literal word-for-word. This is the backbone of the full translation feature. Reasoning: An accurate translation service is fundamental for users to verify their understanding of the Japanese text and learn the nuances of sentence structure. It directly addresses the problem of contextual meaning loss.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:54:47.499565994+05:30","created_by":"krot","updated_at":"2026-01-31T19:28:33.559905236+05:30","closed_at":"2026-01-31T19:28:33.559905236+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.3.1","depends_on_id":"KanjiReader-lqc.3","type":"parent-child","created_at":"2026-01-31T18:54:47.500671296+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.3.2","title":"Subtask: Display full English translation in UI","description":"This subtask focuses on implementing the user interface to display the complete English translation. It should be positioned logically, specifically below the Japanese text and its inline pronunciations, for easy comparison and readability. Consideration: The UI design should clearly distinguish the translation from other text elements, perhaps using different styling or a dedicated section. Ensure responsiveness across different screen sizes. This completes the visual presentation of the translation feature.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:54:49.997300329+05:30","created_by":"krot","updated_at":"2026-01-31T19:28:33.612305325+05:30","closed_at":"2026-01-31T19:28:33.612305325+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.3.2","depends_on_id":"KanjiReader-lqc.3","type":"parent-child","created_at":"2026-01-31T18:54:49.998313425+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.4","title":"Feature: Contextual Word Interaction","description":"This feature aims to provide in-depth information about individual Japanese words within their sentence context, directly addressing the MVP's limitation where word meanings were often incorrect out of context. By allowing users to tap on a word and see a contextual pop-up, it facilitates deeper learning and understanding of vocabulary in real-world usage. This makes the word-level learning more effective and reduces ambiguity. Consideration: The source of contextual word meanings (e.g., advanced dictionary API, local database, or a linguistic parsing service) is a key decision for accuracy.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:55:47.820767904+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.378333845+05:30","closed_at":"2026-01-31T19:29:36.378333845+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.4","depends_on_id":"KanjiReader-lqc","type":"parent-child","created_at":"2026-01-31T18:55:47.821822098+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.4.1","title":"Subtask: Develop pop-up UI component for word details","description":"This subtask involves designing and implementing the user interface for the interactive word pop-up. The pop-up should be visually appealing, user-friendly, and capable of displaying various pieces of information about a word (e.g., definition, part of speech, context-specific meaning). Consideration: Ensure the pop-up does not obstruct the main text unnecessarily and is easily dismissible. Responsiveness and accessibility should also be key design factors.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:55:52.061161435+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.191539061+05:30","closed_at":"2026-01-31T19:29:36.191539061+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.4.1","depends_on_id":"KanjiReader-lqc.4","type":"parent-child","created_at":"2026-01-31T18:55:52.062230699+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.4.2","title":"Subtask: Implement word tap recognition and pop-up trigger","description":"This subtask focuses on implementing the logic to detect when a user taps on an individual Japanese word within the displayed text and subsequently trigger the word detail pop-up. This involves accurate word boundary detection and handling tap events. Reasoning: This is the primary user interaction for this feature, enabling on-demand contextual learning. Accurate word selection is critical for a good user experience.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:55:54.991132074+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.238086755+05:30","closed_at":"2026-01-31T19:29:36.238086755+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.4.2","depends_on_id":"KanjiReader-lqc.4","type":"parent-child","created_at":"2026-01-31T18:55:54.992622539+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.4.3","title":"Subtask: Fetch and display contextual word meaning","description":"This crucial subtask involves implementing the backend logic to fetch the meaning of the tapped Japanese word, specifically considering its context within the sentence. This will likely require integration with a more advanced dictionary API that supports contextual lookup or a linguistic parsing engine. Reasoning: This directly solves the core problem of incorrect word meanings when taken out of context, providing highly relevant and accurate information to the user. Consideration: Caching mechanisms might be needed to optimize API calls and reduce latency.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:56:05.67116022+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.294979935+05:30","closed_at":"2026-01-31T19:29:36.294979935+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.4.3","depends_on_id":"KanjiReader-lqc.4","type":"parent-child","created_at":"2026-01-31T18:56:05.676643229+05:30","created_by":"krot"}]}
{"id":"KanjiReader-lqc.4.4","title":"Subtask: (Optional) Include example sentences/grammar in pop-up","description":"This optional subtask would involve enhancing the word detail pop-up to include example sentences demonstrating the word's usage and/or relevant grammatical explanations. This would provide richer context and deeper learning opportunities. Reasoning: While not critical for the initial release, this significantly boosts the learning value of the feature by providing more comprehensive information. Consideration: This would likely require additional API integrations for examples and grammar rules, or a sophisticated local database. This can be prioritized for a later iteration.","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-01-31T18:56:09.059686735+05:30","created_by":"krot","updated_at":"2026-01-31T19:29:36.33737102+05:30","closed_at":"2026-01-31T19:29:36.33737102+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-lqc.4.4","depends_on_id":"KanjiReader-lqc.4","type":"parent-child","created_at":"2026-01-31T18:56:09.060867391+05:30","created_by":"krot"}]}
{"id":"KanjiReader-spe","title":"Fix Reanimated Threading Crash in AnimatedStroke","description":"Import runOnJS from react-native-reanimated and wrap onAnimationComplete callback in AnimatedStroke.tsx to prevent UI thread crashes.","status":"closed","priority":1,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-04T20:12:37.943822422+05:30","created_by":"krot","updated_at":"2026-02-04T20:13:03.138519893+05:30","closed_at":"2026-02-04T20:13:03.138519893+05:30","close_reason":"Closed"}
{"id":"KanjiReader-zwg","title":"KanjiReader App Enhancements v1.0","description":"# Epic: KanjiReader App Enhancements v1.0\n\n### Overarching Goals \u0026 Vision:\nThis epic, \"KanjiReader App Enhancements v1.0,\" represents a crucial step in evolving the KanjiReader application from a functional proof-of-concept into a polished, user-friendly, and highly effective learning tool. Our long-term vision for KanjiReader is to be the go-to mobile application for Japanese language learners to quickly and accurately decipher handwritten or printed Kanji, providing clear pronunciation, meaning, and contextual usage. This epic directly contributes to that vision by addressing core user experience and accuracy issues that, if left unaddressed, would hinder user adoption and satisfaction.\n\n### Justification \u0026 Intentions (for future self):\nRemember, future Rei, the primary goal here is to refine the application's core usability. We've received critical user feedback (from Avinash) highlighting areas where the current display hinders rather than helps the learning process. The current spacing makes text hard to read, the lack of audio control is frustrating, and inaccurate word segmentation leads to confusion. By tackling these, we're not just fixing bugs; we're significantly improving the app's pedagogical value and overall polish. We want users to feel empowered, not frustrated, by the way information is presented.\n\n### Key Considerations \u0026 Background:\n*   **User Feedback Driven:** These enhancements are a direct response to practical user experience issues identified during initial usage. This ensures we're building features that genuinely solve problems.\n*   **Technical Debt Prevention:** Addressing word segmentation accuracy now, especially concerning morphological boundaries, is vital. Incorrect segmentation can propagate errors throughout the learning process and undermine user trust in the app's reliability. It’s an investment in the app's data integrity and accuracy.\n*   **UI/UX Polish:** The spacing refinements are about achieving a professional and intuitive user interface. Small details in UI make a big difference in perceived quality and ease of use. A 'compact view' offers personalization and caters to different learning preferences.\n*   **Scalability for Future Features:** Establishing robust segmentation logic now will make it easier to build more advanced features later, such as interactive vocabulary lists or grammar explanations that rely on correctly parsed text.\n\n### How it serves the over-arching goals:\nThis epic serves to solidify the foundation of KanjiReader's utility. Without clear, readable text and reliable segmentation, the OCR and dictionary lookup features, no matter how accurate, lose their impact. By making the output more digestible and controllable, we enable learners to focus on the content itself rather than struggling with the presentation. This directly supports the goal of being an intuitive and reliable tool for Japanese learners.\n\n## Included Enhancements (from Openspec):\n\n### Spacing Refinement\n*   **Problem:** Excessive spacing between pronunciation/in-context text, and specifically huge gaps between morphemes in the 'Full text with pronunciation' view, creating a choppy and unnatural appearance.\n*   **Proposed Solution:** Implement CSS/style adjustments (margin, padding, line-height, letter-spacing) to reduce visual space, targeting inter-morpheme spacing for natural flow. Consider a 'compact view' toggle for minimal spacing.\n*   **Acceptance Criteria:** Minimized spacing without compromising clarity; layout consistency; elimination of excessive spaces in main components; natural flow in full text with pronunciation view; optional compact view toggle with further minimized spacing.\n\n## Audio Playback Controls\n*   **Problem:** No stop mechanism for audio playback, causing potential frustration and disorientation.\n*   **Proposed Solution:** Add a pause/stop button directly at the audio player's bar, ensuring immediate stop when interacted with. Implement hover elements for pause/play functionality within two taps of any UI component.\n*   **Acceptance Criteria:** Hover element for playback initiation within two taps; visible and interactive stop icon; user recording progress retained on navigation.\n\n## Improved Word Segmentation\n*   **Problem:** Incorrect splitting of conjugated verbs at morphological boundaries (e.g., '感じた' into '感じ' and 'た'), leading to grammatically incorrect and hard-to-read displays.\n*   **Proposed Solution:** Implement logic to correctly join verb stems with auxiliary endings and other common morphological units during display. This involves post-processing OCR output or refining morphological analysis.\n*   **Acceptance Criteria:** All word components correctly separate and link for proper meanings; phrases maintain clarity and grammatical correctness; segmentation verified by tests matching pre-established dictionaries/morphological analysis; conjugated Japanese verbs displayed as single, correctly formed words; segmentation prioritizes readability/grammatical correctness over strict morpheme-by-morpheme display.\n","status":"closed","priority":2,"issue_type":"epic","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:04:26.851001545+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:20.142249619+05:30","closed_at":"2026-02-02T13:04:20.142249619+05:30","close_reason":"Closed"}
{"id":"KanjiReader-zwg.1","title":"Spacing Refinement","description":"# Feature: Spacing Refinement\n\n### Problem:\nThe current display of pronunciation and in-context text within the KanjiReader app exhibits excessive spacing. This leads to a visually cluttered interface, making it difficult for users to quickly parse information and creating a less aesthetic user experience. Specifically, in the 'Full text with pronunciation' view, there are huge gaps between each morpheme (e.g., 'わたし は なに を し た の か それとも'), making the text appear choppy and unnatural. This hinders readability and the natural flow of Japanese text, especially for learners who rely on clear visual presentation.\n\n### Proposed Solution:\nImplement precise CSS/style adjustments to reduce the visual space between text elements. This effort will specifically target pronunciation guides and in-context sentence examples, as well as critically address inter-morpheme spacing. The objective is to create a more compact, natural-flowing, and readable layout without compromising clarity. This may involve fine-tuning `margin`, `padding`, `line-height`, or `letter-spacing` properties in the relevant UI components. Furthermore, consider introducing a 'compact view' toggle option for users who prefer an even more minimal spacing, allowing for personalized display preferences.\n\n### Acceptance Criteria:\n1.  **Minimized Spacing:** Spacing between pronunciation and reading must be minimized without detriment to meaning or clarity.\n2.  **Layout Consistency:** The overall layout and integrity of the display should not significantly change on screens that show both kanji and pronunciation parts together.\n3.  **Elimination of Excessive Spaces:** All excessive spaces, particularly in prominent text components like headers, sidebars, and the main content area, must be eliminated.\n4.  **Natural Flow (Default View):** The default display of the full text with pronunciation should exhibit a natural flow with significantly reduced inter-morpheme spacing, effectively avoiding the previously observed excessive visual gaps.\n5.  **Compact View Toggle (If Implemented):** If a compact view toggle is introduced, it must function correctly, effectively switching between default and a compact layout where spacing is further minimized.\n6.  **Readability:** The changes must enhance overall readability and reduce visual clutter for the user.\n\n### Background, Reasoning, and Considerations (for future self):\nFuture Rei, remember that this bead is crucial for user satisfaction and learning efficacy. Avinash's feedback directly highlighted the visual fatigue caused by current spacing. Our previous iterations resulted in text that looked more like individual blocks than fluid sentences. The 'compact view' idea stems from the understanding that different learners have different preferences for visual density. By giving users control, we cater to a wider audience. This isn't just about aesthetics; it's about improving cognitive load for learners. Reducing inter-morpheme gaps helps in perceiving words and phrases as cohesive units, which is fundamental to language acquisition. This foundational UI improvement will make subsequent enhancements more impactful. This work is a direct contribution to the parent epic's goal of a polished, user-friendly, and effective learning tool.\n","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:05:41.713040543+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.419435669+05:30","closed_at":"2026-02-02T13:04:19.419435669+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1","depends_on_id":"KanjiReader-zwg","type":"parent-child","created_at":"2026-02-01T22:05:41.71410427+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.1.1","title":"Analyze current CSS/styling for text spacing","description":"## Task: Analyze Current CSS/Styling\n\n### Objective:\nConduct a thorough analysis of the existing CSS and styling rules that govern text spacing in the KanjiReader app, specifically targeting:\n- Pronunciation guides (furigana/romaji)\n- In-context sentence examples\n- Inter-morpheme spacing in the 'Full text with pronunciation' view\n\n### Background (for future self):\nBefore making any changes, we need to understand the current state. This task establishes a baseline and identifies exactly which CSS properties (margin, padding, line-height, letter-spacing) are responsible for the excessive spacing.\n\n### Deliverables:\n1. Document listing all relevant CSS selectors/rules affecting text spacing\n2. Screenshots/annotations showing current spacing issues\n3. Recommendations for which properties to adjust\n\n### Acceptance Criteria:\n- All CSS rules affecting text spacing are identified and documented\n- Root causes of excessive spacing are clearly understood","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:11:11.877704536+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.17568142+05:30","closed_at":"2026-02-02T13:04:19.17568142+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1.1","depends_on_id":"KanjiReader-zwg.1","type":"parent-child","created_at":"2026-02-01T22:11:11.878732206+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.1.2","title":"Implement inter-morpheme spacing adjustments","description":"## Task: Implement Inter-Morpheme Spacing Adjustments\n\n### Objective:\nReduce the excessive gaps between morphemes in the 'Full text with pronunciation' view to create a more natural, readable text flow.\n\n### Background (for future self):\nThe screenshot showed text like 'わたし は なに を し た の か' with huge gaps between each morpheme. This makes reading feel choppy and unnatural. We need to tighten these spaces so the text flows like natural Japanese sentences while still maintaining visual separation for learning purposes.\n\n### Technical Approach:\n- Identify the React Native/CSS components rendering morpheme tokens\n- Adjust margin/padding between tokens\n- Ensure changes don't break layout on different screen sizes\n- Consider using flexbox gap properties for consistent spacing\n\n### Acceptance Criteria:\n- Inter-morpheme spacing is visually reduced\n- Text flows naturally without appearing cramped\n- Changes are consistent across all views displaying tokenized text\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.1.1 (CSS analysis must be complete first)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:11:23.284981052+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.225541401+05:30","closed_at":"2026-02-02T13:04:19.225541401+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1.2","depends_on_id":"KanjiReader-zwg.1","type":"parent-child","created_at":"2026-02-01T22:11:23.286100768+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.2","depends_on_id":"KanjiReader-zwg.1.1","type":"blocks","created_at":"2026-02-01T22:11:23.287663519+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.1.3","title":"Implement pronunciation guide spacing adjustments","description":"## Task: Implement Pronunciation Guide Spacing Adjustments\n\n### Objective:\nReduce excessive spacing around pronunciation guides (romaji/readings) displayed alongside kanji/words in the results view.\n\n### Background (for future self):\nThe screenshot showed spacing around '(soretomo)' that was unnecessarily large, visually distancing the pronunciation from the word it describes. This disconnect makes it harder for learners to associate the reading with the kanji.\n\n### Technical Approach:\n- Target CSS for pronunciation/reading display components\n- Reduce vertical and horizontal margins/padding around pronunciation text\n- Maintain enough separation for clarity, but improve visual association with the main word\n- Test with different word lengths and pronunciation lengths\n\n### Acceptance Criteria:\n- Pronunciation guides appear visually connected to their corresponding words\n- Spacing is consistent regardless of word/pronunciation length\n- Readability is maintained or improved\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.1.1 (CSS analysis must be complete first)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:11:32.879997763+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.273689166+05:30","closed_at":"2026-02-02T13:04:19.273689166+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1.3","depends_on_id":"KanjiReader-zwg.1","type":"parent-child","created_at":"2026-02-01T22:11:32.881064007+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.3","depends_on_id":"KanjiReader-zwg.1.1","type":"blocks","created_at":"2026-02-01T22:11:32.882614935+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.1.4","title":"Create compact view toggle UI","description":"## Task: Create Compact View Toggle UI\n\n### Objective:\nDesign and implement a user-accessible toggle that allows switching between 'default' and 'compact' display modes for text spacing.\n\n### Background (for future self):\nDifferent learners have different preferences for visual density. Some prefer more spacing for easier reading, while others want maximum information density. A toggle gives users control over their learning experience and demonstrates responsiveness to user needs.\n\n### Technical Approach:\n- Add a toggle switch/button in the settings or directly in the results view\n- Store user preference in app state/storage\n- Apply 'compact' CSS class when enabled, further reducing spacing\n- Ensure toggle state persists across app sessions\n\n### UI Considerations:\n- Toggle should be easily discoverable but not intrusive\n- Clear labeling: 'Compact View' or 'Dense Mode'\n- Consider adding a visual preview of the difference\n\n### Acceptance Criteria:\n- Toggle is visible and functional in the UI\n- Switching modes immediately updates the text display\n- User preference persists across sessions\n- Both modes provide readable, well-formatted text\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.1.2, KanjiReader-zwg.1.3 (base spacing adjustments should be implemented first)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:11:43.791447584+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.320896603+05:30","closed_at":"2026-02-02T13:04:19.320896603+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1.4","depends_on_id":"KanjiReader-zwg.1","type":"parent-child","created_at":"2026-02-01T22:11:43.792481246+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.4","depends_on_id":"KanjiReader-zwg.1.2","type":"blocks","created_at":"2026-02-01T22:11:43.794180968+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.4","depends_on_id":"KanjiReader-zwg.1.3","type":"blocks","created_at":"2026-02-01T22:11:43.79578632+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.1.5","title":"Test spacing changes across screen sizes","description":"## Task: Test Spacing Changes Across Screen Sizes\n\n### Objective:\nVerify that all spacing adjustments work correctly across different device screen sizes and orientations.\n\n### Background (for future self):\nReact Native apps run on a variety of devices with different screen dimensions. Spacing that looks good on one device might look cramped or excessive on another. This testing task ensures our changes provide a consistent, quality experience everywhere.\n\n### Testing Scope:\n- Small phones (iPhone SE, small Android devices)\n- Standard phones (iPhone 14, Pixel 7)\n- Large phones/phablets (iPhone Pro Max, Samsung Ultra)\n- Tablets (iPad, Android tablets)\n- Both portrait and landscape orientations\n\n### Test Cases:\n1. Verify inter-morpheme spacing looks natural on all sizes\n2. Verify pronunciation guides are correctly associated with words\n3. Verify compact view toggle works and provides meaningful difference\n4. Check for text overflow or truncation issues\n5. Verify scrolling behavior with new spacing\n\n### Acceptance Criteria:\n- No visual regressions on any tested device size\n- Text remains readable and well-formatted across all sizes\n- Compact view provides consistent experience across devices\n\n### Dependencies:\n- Depends on: All spacing implementation tasks (KanjiReader-zwg.1.2, KanjiReader-zwg.1.3, KanjiReader-zwg.1.4)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:11:54.905943072+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.371631298+05:30","closed_at":"2026-02-02T13:04:19.371631298+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.1.5","depends_on_id":"KanjiReader-zwg.1","type":"parent-child","created_at":"2026-02-01T22:11:54.906983176+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.5","depends_on_id":"KanjiReader-zwg.1.2","type":"blocks","created_at":"2026-02-01T22:11:54.908710742+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.5","depends_on_id":"KanjiReader-zwg.1.3","type":"blocks","created_at":"2026-02-01T22:11:54.910402278+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.1.5","depends_on_id":"KanjiReader-zwg.1.4","type":"blocks","created_at":"2026-02-01T22:11:54.912061804+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.2","title":"Audio Playback Control","description":"# Feature: Audio Playback Control\n\n### Problem:\nAudio playback currently lacks any stop mechanism once initiated, leading to potential user frustration and disorientation. Users are unable to pause or stop audio playback at will, which can disrupt their learning flow, especially when they need to concentrate, take notes, or navigate to other sections of the app. This is an oversight that compromises user control over their interactive experience with the application.\n\n### Proposed Solution:\nImplement a clear and accessible pause/stop button directly within the audio player's bar or near the audio initiation point. This button should allow for immediate cessation of audio playback upon interaction. Additionally, consider integrating a hover-activated control mechanism, allowing users to quickly and intuitively stop or pause audio within two taps of any UI component that triggers playback.\n\n### Acceptance Criteria:\n1.  **Stop Button:** A dedicated pause/stop button must be visibly present and functional in the audio player's UI.\n2.  **Immediate Control:** Interaction with the pause/stop button must result in the immediate cessation of audio playback.\n3.  **Hover/Tap Interaction (If Implemented):** If a hover-activated control is implemented, a hover element must appear within two taps of any UI component that initiates playback, offering a clear option to stop or pause.\n4.  **UI Feedback:** The stop icon or control should visually indicate the audio's current playing state (e.g., play/pause toggle).\n5.  **Progress Retention:** Users' learning progress or recording status shall not be lost when they navigate away from a page or stop audio playback, ensuring continuity.\n\n### Background:\nThe lack of a stop mechanism in audio playback has become pervasive due to auto-play features that typically start playing when landing on a webpage without user's knowledge or control; this can create confusion and frustration for users. While there are several workarounds available, each offering their own shortcomings like inability to easily recall or stop if not kept at the forefront of mind. Our proposal aims to tackle such issues by introducing an obvious 'Stop Button' directly beneath the audio player’s bar, ensuring immediate audio interruption when interacted with.  \n\n### Reasoning:\nIn a digital environment, information is often spread out across various pages and sections; without visual cues directing one to pause or stop an ongoing piece of content, navigation might get complicated and confusing. This proposal aims at rectifying such misconceptions through the introduction of this control enhancement feature which ensures users have immediate control over their audio playback experience, thus eliminating potential frustrations that could stem from auto-play features.  \n\n### Considerations:\nThe Stop Button's positioning directly under the UI would be beneficial as it can offer instant accessibility without overloading the user interface with unnecessary controls. The 'Stop' icon should also communicate itself clearly, indicating to users when audio is playing and what will happen on a tap of this icon (pause or stop the sound).  \n    \n### Contributing To Goals:\nThis feature enhancement directly contributes to improving the efficiency and user experience of the parent epic \"KanjiReader App Enhancements v1.0\" by providing an immediate control over the audio playback, increasing interaction with the UI interface thereby strengthening overall app usability in a user’s day-to-day activities within the app itself.\n","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:08:59.533256133+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.711187959+05:30","closed_at":"2026-02-02T13:04:19.711187959+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.2","depends_on_id":"KanjiReader-zwg","type":"parent-child","created_at":"2026-02-01T22:08:59.534384836+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.2.1","title":"Design pause/stop button UI","description":"## Task: Design Pause/Stop Button UI\n\n### Objective:\nDesign a clear, intuitive pause/stop button for the audio player that integrates seamlessly with the existing UI.\n\n### Background (for future self):\nCurrently, once audio starts playing, users have no way to stop it. This is a fundamental UX oversight. The solution needs to be obvious and immediately accessible - users shouldn't have to hunt for a stop button when audio is playing unexpectedly.\n\n### Design Requirements:\n- Button must be prominently visible when audio is playing\n- Use universally recognized pause/stop iconography\n- Button should indicate current audio state (playing/paused/stopped)\n- Placement should be near the audio initiation point (speaker icon)\n- Consider animation to draw attention when audio starts\n\n### Deliverables:\n1. UI mockup/design for the pause/stop button\n2. State diagram showing button appearance in different states\n3. Placement recommendations within existing UI\n\n### Acceptance Criteria:\n- Design is approved and documented\n- Button design is consistent with app's visual language\n- Button states (play/pause/stop) are visually distinct","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:12:05.789164451+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.519683787+05:30","closed_at":"2026-02-02T13:04:19.519683787+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.2.1","depends_on_id":"KanjiReader-zwg.2","type":"parent-child","created_at":"2026-02-01T22:12:05.790203503+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.2.2","title":"Implement audio stop functionality","description":"## Task: Implement Audio Stop Functionality\n\n### Objective:\nImplement the core functionality to stop/pause audio playback when the user interacts with the stop button.\n\n### Background (for future self):\nThis is the core technical implementation task. We need to hook into the existing audio playback system (likely using expo-av or react-native-sound) and add stop/pause capabilities.\n\n### Technical Approach:\n- Identify the current audio playback implementation\n- Add state management for audio playback status (playing/paused/stopped)\n- Implement stopAsync() or pauseAsync() methods on user interaction\n- Ensure audio resources are properly released when stopped\n- Handle edge cases (stopping when already stopped, rapid play/stop cycles)\n\n### Code Considerations:\n- Use proper async/await patterns for audio control\n- Implement error handling for playback failures\n- Consider adding a global audio manager if multiple audio sources exist\n\n### Acceptance Criteria:\n- Tapping stop immediately halts audio playback\n- Audio state is correctly tracked and reflected in UI\n- No memory leaks from unreleased audio resources\n- Works consistently across iOS and Android\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.2.1 (UI design should be finalized first)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:12:17.079814547+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.568574845+05:30","closed_at":"2026-02-02T13:04:19.568574845+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.2.2","depends_on_id":"KanjiReader-zwg.2","type":"parent-child","created_at":"2026-02-01T22:12:17.080883316+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.2.2","depends_on_id":"KanjiReader-zwg.2.1","type":"blocks","created_at":"2026-02-01T22:12:17.082560405+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.2.3","title":"Integrate stop button with UI","description":"## Task: Integrate Stop Button with UI\n\n### Objective:\nImplement the designed pause/stop button into the app's UI and connect it to the audio stop functionality.\n\n### Background (for future self):\nThis task bridges the design (KanjiReader-zwg.2.1) and implementation (KanjiReader-zwg.2.2) tasks. It involves creating the actual React Native components and wiring them to the audio control logic.\n\n### Technical Approach:\n- Create React Native component for the stop button\n- Implement state-based rendering (show different icons for play/pause/stop states)\n- Add touch handlers that trigger audio stop/pause functions\n- Add appropriate animations/transitions for state changes\n- Ensure button is accessible (proper hit area, accessibility labels)\n\n### UI Integration Points:\n- Near the existing speaker/audio icon in results view\n- Possibly in a floating audio control bar if audio is playing\n\n### Acceptance Criteria:\n- Button appears in the correct location per design\n- Button correctly reflects audio playback state\n- Tapping button successfully stops/pauses audio\n- Button is accessible and has appropriate touch targets\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.2.1 (UI design), KanjiReader-zwg.2.2 (audio functionality)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:12:27.34625852+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.617730287+05:30","closed_at":"2026-02-02T13:04:19.617730287+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.2.3","depends_on_id":"KanjiReader-zwg.2","type":"parent-child","created_at":"2026-02-01T22:12:27.347470161+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.2.3","depends_on_id":"KanjiReader-zwg.2.1","type":"blocks","created_at":"2026-02-01T22:12:27.349326041+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.2.3","depends_on_id":"KanjiReader-zwg.2.2","type":"blocks","created_at":"2026-02-01T22:12:27.351129341+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.2.4","title":"Verify audio state persistence on navigation","description":"## Task: Verify Audio State Persistence on Navigation\n\n### Objective:\nEnsure that users' audio playback state and any recording progress is properly handled when navigating away from a page.\n\n### Background (for future self):\nOne of the acceptance criteria from the openspec states: 'Users' recording progress shall not lose when they navigate away from the page, ensuring continuity throughout their learning experience.' This task verifies that behavior is correct.\n\n### Test Scenarios:\n1. Audio playing → Navigate away → Return: What happens?\n2. Audio paused → Navigate away → Return: Is pause state preserved?\n3. If there's any recording feature: Is progress saved?\n4. Background/foreground app transitions: How does audio behave?\n\n### Technical Considerations:\n- May need to implement audio session management\n- Consider whether audio should continue in background or pause\n- State persistence might require local storage or context management\n\n### Acceptance Criteria:\n- Audio behavior on navigation is intentional and documented\n- No unexpected audio continuation after leaving a screen\n- Any user progress is preserved as per design decisions\n- App handles background/foreground transitions gracefully\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.2.3 (full audio control integration)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:12:39.255332335+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.664571727+05:30","closed_at":"2026-02-02T13:04:19.664571727+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.2.4","depends_on_id":"KanjiReader-zwg.2","type":"parent-child","created_at":"2026-02-01T22:12:39.256463112+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.2.4","depends_on_id":"KanjiReader-zwg.2.3","type":"blocks","created_at":"2026-02-01T22:12:39.258325145+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3","title":"Improved Word Segmentation","description":"# Feature: Improved Word Segmentation\n\n### Problem:\nThe current app struggles with accurate word segmentation for complex Japanese text. While basic words like '感じ' (to perceive) are handled correctly, conjugated verbs are incorrectly split at morphological boundaries. Examples include:\n- '感じた' split into '感じ' and 'た'\n- '思い出して' split into '思い出し' and 'て'\n- '書こう' split into '書こ' and 'う'\n\nThis results in grammatically incorrect and visually fragmented displays, significantly hindering readability and comprehension for Japanese language learners. The core issue is that the current tokenization/segmentation logic treats each morpheme as a separate display unit, which is technically correct but pedagogically unhelpful.\n\n### Proposed Solution:\nImplement intelligent post-processing logic that correctly joins verb stems with their auxiliary endings and other morphologically linked units during display. This solution will involve:\n1. **Dictionary Lookup Enhancement:** Cross-reference segmented tokens against a dictionary of common verb conjugations and compound forms.\n2. **Morphological Analysis Refinement:** Improve the morphological analysis step to recognize when adjacent morphemes should be displayed as a single unit.\n3. **Post-OCR Processing:** Apply rules to rejoin incorrectly split conjugated verbs and other grammatical units after initial OCR processing.\n\nThe goal is to prioritize readability and grammatical correctness for the learner, even if it means deviating from a strict morpheme-by-morpheme split in the display.\n\n### Acceptance Criteria:\n1. **Correct Separation \u0026 Linking:** All word components should correctly separate and link together for their proper meanings.\n2. **Maintained Context:** Phrases that are split up will maintain their correct pronunciation, meaning, and grammatical context.\n3. **Robustness Testing:** The improvement in segmentation can be verified with sets of tests involving various sentence structure inputs to test its robustness. These segmentations must match pre-established dictionaries or have good morphological analysis results (e.g., correct verb stems and auxiliaries joining).\n4. **Single-Word Display:** Conjugated Japanese verbs and other morphologically linked units (e.g., verb stems and auxiliary endings) must be displayed as single, correctly formed words (e.g., '感じた' instead of '感じ た').\n5. **Readability Priority:** The segmentation should prioritize readability and grammatical correctness for the learner, even if it means deviating from a strict morpheme-by-morpheme split in the display.\n\n### Background \u0026 Reasoning (for future self):\nFuture Rei, this is arguably the most technically challenging enhancement in this epic, but also the most impactful for learning efficacy. Avinash specifically pointed out the '感じた' → '感じ' + 'た' split issue. Remember that Japanese learners, especially beginners, rely heavily on seeing words as cohesive units to build vocabulary and grammar intuition. By fragmenting conjugated verbs, we're inadvertently teaching incorrect word boundaries.\n\nThis solution not only mitigates OCR errors but also assists in preserving more accurate and meaningful contextual relevance, thereby improving user experience overall. This feature contributes to the goals of enhancing communication understanding among learners, particularly for those who are studying Japanese language with its complex morphological structures.\n\n### Considerations:\n- **Performance:** The post-processing logic must be efficient to avoid noticeable delays in displaying results.\n- **Edge Cases:** Japanese has many irregular conjugations and compound forms; a comprehensive rule set or dictionary is needed.\n- **Trade-offs:** In some cases, a strict morpheme split might be pedagogically useful (e.g., for advanced learners studying grammar). Consider whether to offer a toggle for \"detailed view\" in the future.\n- **Testing:** A robust test suite with diverse sentence structures is essential to validate segmentation accuracy.\n\n### Contributing to Parent Epic Goals:\nThis feature directly addresses one of the core user experience issues identified in the \"KanjiReader App Enhancements v1.0\" epic. By ensuring that displayed text is grammatically correct and readable, we significantly improve the app's pedagogical value and user trust. This is foundational work that makes the OCR and dictionary lookup features truly useful for learners.\n","status":"closed","priority":2,"issue_type":"feature","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:10:54.195598133+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:20.043242732+05:30","closed_at":"2026-02-02T13:04:20.043242732+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3","depends_on_id":"KanjiReader-zwg","type":"parent-child","created_at":"2026-02-01T22:10:54.196706266+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3.1","title":"Analyze current tokenization/segmentation logic","description":"## Task: Analyze Current Tokenization/Segmentation Logic\n\n### Objective:\nConduct a thorough analysis of how the app currently tokenizes and segments Japanese text to understand where and why incorrect splits occur.\n\n### Background (for future self):\nBefore we can fix the segmentation, we need to understand the current implementation. Is tokenization happening during OCR? Is there a separate NLP step? What libraries are being used (if any)? This analysis will inform our solution approach.\n\n### Investigation Areas:\n1. OCR pipeline: Does Google Cloud Vision return tokenized text or raw text?\n2. Post-OCR processing: Is there any existing segmentation logic?\n3. Dictionary lookup: How are individual tokens matched to dictionary entries?\n4. Display rendering: At what point are tokens separated for display?\n\n### Specific Questions to Answer:\n- Where does '感じた' get split into '感じ' and 'た'?\n- Is this split coming from OCR, a tokenizer library, or our own code?\n- What data structure represents tokenized text?\n\n### Deliverables:\n1. Documentation of current text processing pipeline\n2. Identification of the exact point where incorrect segmentation occurs\n3. Recommendations for where to implement fixes\n\n### Acceptance Criteria:\n- Current tokenization flow is fully documented\n- Root cause of incorrect segmentation is identified\n- Clear path forward for implementing fixes is defined","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:12:50.927054099+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.803817727+05:30","closed_at":"2026-02-02T13:04:19.803817727+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3.1","depends_on_id":"KanjiReader-zwg.3","type":"parent-child","created_at":"2026-02-01T22:12:50.928572275+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3.2","title":"Research morphological joining rules for Japanese verbs","description":"## Task: Research Morphological Joining Rules for Japanese Verbs\n\n### Objective:\nCompile a comprehensive set of rules for when Japanese morphemes should be joined for display purposes, focusing on verb conjugations.\n\n### Background (for future self):\nJapanese verb conjugation follows predictable patterns. 'た' (past tense), 'て' (te-form), 'ない' (negative), 'う' (volitional), etc., are auxiliary endings that should generally be displayed attached to their verb stems. We need to codify these rules.\n\n### Research Areas:\n1. Verb conjugation patterns (godan, ichidan, irregular)\n2. Common auxiliary endings and their joining behavior\n3. Compound verbs and their segmentation\n4. Adjective conjugations (i-adjectives, na-adjectives)\n5. Edge cases and exceptions\n\n### Example Rules to Define:\n- Verb stem + た → Join (感じ + た → 感じた)\n- Verb stem + て → Join (思い出し + て → 思い出して)\n- Verb stem + う/よう → Join (書こ + う → 書こう)\n- Verb stem + ない → Join (食べ + ない → 食べない)\n\n### Deliverables:\n1. Documented list of morpheme joining rules\n2. Categorization by verb type and conjugation pattern\n3. List of known exceptions and edge cases\n\n### Acceptance Criteria:\n- Rules cover common verb conjugation patterns\n- Rules are validated against Japanese grammar references\n- Edge cases are identified and documented\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.3.1 (understanding current logic helps prioritize rules)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:13:06.906420272+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.85097078+05:30","closed_at":"2026-02-02T13:04:19.85097078+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3.2","depends_on_id":"KanjiReader-zwg.3","type":"parent-child","created_at":"2026-02-01T22:13:06.907495403+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.2","depends_on_id":"KanjiReader-zwg.3.1","type":"blocks","created_at":"2026-02-01T22:13:06.909384657+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3.3","title":"Implement post-processing morpheme joining logic","description":"## Task: Implement Post-Processing Morpheme Joining Logic\n\n### Objective:\nImplement the core algorithm that joins incorrectly split morphemes based on the researched rules.\n\n### Background (for future self):\nThis is the main implementation task. Based on our analysis and research, we'll implement logic that takes the tokenized text and intelligently joins tokens that should be displayed as single words.\n\n### Technical Approach:\n1. Create a function that takes an array of tokens as input\n2. Iterate through tokens, checking if adjacent tokens should be joined\n3. Apply joining rules based on token types (verb stem, auxiliary, particle, etc.)\n4. Return the corrected token array for display\n\n### Pseudocode Concept:\n```\nfunction joinMorphemes(tokens):\n  result = []\n  i = 0\n  while i \u003c tokens.length:\n    if shouldJoin(tokens[i], tokens[i+1]):\n      result.push(tokens[i] + tokens[i+1])\n      i += 2\n    else:\n      result.push(tokens[i])\n      i += 1\n  return result\n```\n\n### Implementation Considerations:\n- Tokens may need part-of-speech tagging to determine join eligibility\n- Consider using existing Japanese NLP libraries (kuromoji, etc.) if available\n- Performance: joining should be fast enough for real-time display\n- Handle multi-token joins (e.g., verb + auxiliary + particle sequences)\n\n### Acceptance Criteria:\n- '感じた' displays as '感じた' not '感じ た'\n- '思い出して' displays as '思い出して' not '思い出し て'\n- '書こう' displays as '書こう' not '書こ う'\n- Other common conjugations are correctly joined\n- No false positives (tokens that shouldn't be joined aren't joined)\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.3.1 (analysis), KanjiReader-zwg.3.2 (rules research)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:13:18.995210567+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.89770714+05:30","closed_at":"2026-02-02T13:04:19.89770714+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3.3","depends_on_id":"KanjiReader-zwg.3","type":"parent-child","created_at":"2026-02-01T22:13:18.996728634+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.3","depends_on_id":"KanjiReader-zwg.3.1","type":"blocks","created_at":"2026-02-01T22:13:18.999497867+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.3","depends_on_id":"KanjiReader-zwg.3.2","type":"blocks","created_at":"2026-02-01T22:13:19.002473203+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3.4","title":"Create segmentation validation suite","description":"## Task: Create Segmentation Validation Test Suite\n\n### Objective:\nCreate a comprehensive test suite to validate that segmentation improvements work correctly across a variety of sentence structures.\n\n### Background (for future self):\nThe acceptance criteria specifically require: 'The improvement in segmentation can be verified with sets of tests involving various sentence structure inputs.' This task ensures we have robust testing to catch regressions and validate correctness.\n\n### Test Categories:\n1. **Basic verb conjugations:**\n   - 食べた, 飲んだ, 行った (ta-form)\n   - 食べて, 飲んで, 行って (te-form)\n   - 食べよう, 飲もう, 行こう (volitional)\n   - 食べない, 飲まない, 行かない (negative)\n\n2. **Compound verbs:**\n   - 思い出す, 走り出す, 飛び込む\n\n3. **Adjective conjugations:**\n   - 高かった, 静かだった\n\n4. **Complex sentences:**\n   - Multiple conjugated verbs in sequence\n   - Nested clauses\n\n5. **Edge cases:**\n   - Irregular verbs (する, くる)\n   - Potential forms\n   - Causative/passive forms\n\n### Deliverables:\n1. Test file with comprehensive test cases\n2. Expected output for each test case\n3. Automated test runner (if applicable)\n\n### Acceptance Criteria:\n- Test suite covers all common conjugation patterns\n- Tests are automated and can be run as part of CI/CD\n- All tests pass with the implemented joining logic\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.3.3 (implementation must exist to test)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:13:31.112734362+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.947324881+05:30","closed_at":"2026-02-02T13:04:19.947324881+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3.4","depends_on_id":"KanjiReader-zwg.3","type":"parent-child","created_at":"2026-02-01T22:13:31.113854208+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.4","depends_on_id":"KanjiReader-zwg.3.3","type":"blocks","created_at":"2026-02-01T22:13:31.115869773+05:30","created_by":"krot"}]}
{"id":"KanjiReader-zwg.3.5","title":"Integration testing with real OCR output","description":"## Task: Integration Testing with Real OCR Output\n\n### Objective:\nTest the improved segmentation logic with actual OCR output from Google Cloud Vision to ensure it works correctly in the real app context.\n\n### Background (for future self):\nUnit tests with predefined inputs are important, but the real test is how the logic performs with actual OCR output. OCR can introduce its own quirks (misrecognitions, unexpected tokenization), and we need to ensure our improvements handle these gracefully.\n\n### Testing Approach:\n1. Capture several real OCR outputs from the app (using existing test images)\n2. Run the improved segmentation logic on these outputs\n3. Manually verify the results are correct\n4. Document any edge cases or failures\n\n### Test Images to Use:\n- The original screenshot Avinash provided\n- Additional handwritten Japanese samples\n- Printed Japanese text samples\n- Mixed content (kanji, hiragana, katakana)\n\n### Acceptance Criteria:\n- Segmentation works correctly with actual OCR output\n- No regressions compared to previous behavior (except intentional fixes)\n- Edge cases from real OCR are handled or documented\n- Performance is acceptable (no noticeable delays)\n\n### Dependencies:\n- Depends on: KanjiReader-zwg.3.3 (implementation), KanjiReader-zwg.3.4 (unit tests)","status":"closed","priority":2,"issue_type":"task","owner":"8983708+avinash-lodhi@users.noreply.github.com","created_at":"2026-02-01T22:13:42.482109183+05:30","created_by":"krot","updated_at":"2026-02-02T13:04:19.994403983+05:30","closed_at":"2026-02-02T13:04:19.994403983+05:30","close_reason":"Closed","dependencies":[{"issue_id":"KanjiReader-zwg.3.5","depends_on_id":"KanjiReader-zwg.3","type":"parent-child","created_at":"2026-02-01T22:13:42.483600087+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.5","depends_on_id":"KanjiReader-zwg.3.3","type":"blocks","created_at":"2026-02-01T22:13:42.48664163+05:30","created_by":"krot"},{"issue_id":"KanjiReader-zwg.3.5","depends_on_id":"KanjiReader-zwg.3.4","type":"blocks","created_at":"2026-02-01T22:13:42.489658515+05:30","created_by":"krot"}]}
